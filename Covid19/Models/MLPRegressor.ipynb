{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sqlalchemy as sa\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "engine = sa.create_engine('oracle://\"MHaleta\":trankvilisator@localhost:1521/xe', max_identifier_length=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"\"\"\n",
    "    select\n",
    "        c.\"Date\",\n",
    "        c.\"Total_Cases\",\n",
    "        c.\"New_Cases\",\n",
    "        m.\"Retail_and_Recreation\"*1.0/100,\n",
    "        m.\"Grocery_and_Pharmacy\"*1.0/100,\n",
    "        m.\"Parks\"*1.0/100,\n",
    "        m.\"Transit_Stations\"*1.0/100,\n",
    "        m.\"Workplaces\"*1.0/100,\n",
    "        m.\"Residentials\"*1.0/100\n",
    "    from \"Covid19_data\" c left join \"Movements_Changes_from_Baseline\" m\n",
    "    on c.\"Date\" = m.\"Date\"\n",
    "    where\n",
    "        c.\"ISO3_Code\" = 'UKR'\n",
    "        and m.\"Region\" is null\n",
    "        and m.\"Workplaces\" is not null\n",
    "        and c.\"Date\" >= '01.05.2020'\n",
    "    order by c.\"Date\"\n",
    "\"\"\"\n",
    "df = pd.read_sql(query, engine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "beta = df.New_Cases.values[1:]/df.Total_Cases.values[:-1]\n",
    "features = np.concatenate((df.iloc[:-1, 3:].values, np.ones((len(beta), 1))), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(165,)\n",
      "(165, 7)\n"
     ]
    }
   ],
   "source": [
    "print(beta.shape)\n",
    "print(features.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.0506399 , 0.04399264, 0.03508772, 0.02968129, 0.03835552,\n",
       "       0.0384557 , 0.0368125 , 0.03628038, 0.03548606, 0.02731092])"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "beta[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "beta_sh = 100*beta[1:]\n",
    "features_sh = np.concatenate((100*np.vstack(beta[:-1]), features[:-1]), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(164,)\n",
      "(164, 8)\n"
     ]
    }
   ],
   "source": [
    "print(beta_sh.shape)\n",
    "print(features_sh.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def outliers_filter(x):\n",
    "    from numpy import quantile\n",
    "    \n",
    "    Q1, Q3 = quantile(x, [0.25, 0.75])\n",
    "    IQR = Q3 - Q1\n",
    "    \n",
    "    filtr = (x <= 0)|(x < Q1-1.5*IQR)|(x > Q3+1.5*IQR)\n",
    "    \n",
    "    return filtr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "beta.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "beta_sh, features_sh = beta_sh[~outliers_filter(beta_sh)], features_sh[~outliers_filter(beta_sh)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neural_network import MLPRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test = features_sh[:int(0.67*features_sh.shape[0])], features_sh[int(0.67*features_sh.shape[0]):]\n",
    "y_train, y_test = beta_sh[:int(0.67*len(beta_sh))], beta_sh[int(0.67*len(beta_sh)):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([4.39926387, 3.50877193, 2.96812911, 3.83555171, 3.84557039,\n",
       "       3.68125046, 3.62803804, 3.54860639, 2.73109244, 2.39647239,\n",
       "       2.50889347, 2.56925419, 2.86697928, 3.04673976, 2.42468362,\n",
       "       1.77683014, 1.39664804, 1.87539733, 2.47529901, 2.24297168,\n",
       "       2.14413341, 1.97278912, 1.2341561 , 1.59566957, 1.48721275,\n",
       "       2.17758503, 1.91671879, 1.72285301, 2.01689364, 1.43629605,\n",
       "       1.36598367, 1.98438784, 2.3687709 , 2.1762229 , 2.11831767,\n",
       "       1.8292223 , 1.71487833, 1.43470978, 1.88469271, 2.42768049,\n",
       "       2.3495012 , 2.53083723, 2.12417229, 2.10566861, 2.09368123,\n",
       "       2.33403128, 2.49443341, 2.70381352, 2.40395609, 2.05163992,\n",
       "       1.86269147, 2.23678204, 2.4688764 , 2.54780335, 2.77194561,\n",
       "       2.30561568, 2.17995959, 1.50295473, 1.61822683, 1.49772184,\n",
       "       1.97564336, 1.90903742, 1.95453671, 1.72619922, 1.11958763,\n",
       "       1.15001121, 1.62678654, 1.60669655, 1.59885991, 1.5371904 ,\n",
       "       1.283046  , 1.14347639, 1.17857869, 1.52635519, 1.52498786,\n",
       "       1.43299973, 1.47911428, 1.2579374 , 1.10635261, 1.13122552,\n",
       "       1.3778546 , 1.40339372, 1.57151865, 1.76050173, 1.4390965 ,\n",
       "       1.24442937, 1.39971975, 1.53511078, 1.77078864, 1.5844405 ,\n",
       "       1.67706485, 1.56496285, 1.37179914, 1.45028568, 1.71249949,\n",
       "       1.74592661, 1.89173003, 1.90260794, 1.50344828, 1.24522848,\n",
       "       1.41293605, 1.72411719, 1.88295406, 2.01068029, 2.10192098,\n",
       "       1.82458565, 1.602522  , 1.74100409, 2.08289212])"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(features, beta, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 1.64989748\n",
      "Iteration 2, loss = 1.64914769\n",
      "Iteration 3, loss = 1.64839805\n",
      "Iteration 4, loss = 1.64764855\n",
      "Iteration 5, loss = 1.64689902\n",
      "Iteration 6, loss = 1.64614892\n",
      "Iteration 7, loss = 1.64539815\n",
      "Iteration 8, loss = 1.64464749\n",
      "Iteration 9, loss = 1.64389695\n",
      "Iteration 10, loss = 1.64314655\n",
      "Iteration 11, loss = 1.64239628\n",
      "Iteration 12, loss = 1.64164448\n",
      "Iteration 13, loss = 1.64089102\n",
      "Iteration 14, loss = 1.64013757\n",
      "Iteration 15, loss = 1.63938416\n",
      "Iteration 16, loss = 1.63863083\n",
      "Iteration 17, loss = 1.63787760\n",
      "Iteration 18, loss = 1.63712450\n",
      "Iteration 19, loss = 1.63637159\n",
      "Iteration 20, loss = 1.63561882\n",
      "Iteration 21, loss = 1.63486622\n",
      "Iteration 22, loss = 1.63411377\n",
      "Iteration 23, loss = 1.63336150\n",
      "Iteration 24, loss = 1.63260825\n",
      "Iteration 25, loss = 1.63185390\n",
      "Iteration 26, loss = 1.63109961\n",
      "Iteration 27, loss = 1.63034540\n",
      "Iteration 28, loss = 1.62959129\n",
      "Iteration 29, loss = 1.62883603\n",
      "Iteration 30, loss = 1.62808046\n",
      "Iteration 31, loss = 1.62732313\n",
      "Iteration 32, loss = 1.62656562\n",
      "Iteration 33, loss = 1.62580808\n",
      "Iteration 34, loss = 1.62505055\n",
      "Iteration 35, loss = 1.62429306\n",
      "Iteration 36, loss = 1.62353509\n",
      "Iteration 37, loss = 1.62277646\n",
      "Iteration 38, loss = 1.62201776\n",
      "Iteration 39, loss = 1.62125901\n",
      "Iteration 40, loss = 1.62050031\n",
      "Iteration 41, loss = 1.61974094\n",
      "Iteration 42, loss = 1.61898147\n",
      "Iteration 43, loss = 1.61822196\n",
      "Iteration 44, loss = 1.61746242\n",
      "Iteration 45, loss = 1.61670297\n",
      "Iteration 46, loss = 1.61594387\n",
      "Iteration 47, loss = 1.61518424\n",
      "Iteration 48, loss = 1.61442242\n",
      "Iteration 49, loss = 1.61365880\n",
      "Iteration 50, loss = 1.61289446\n",
      "Iteration 51, loss = 1.61212908\n",
      "Iteration 52, loss = 1.61136323\n",
      "Iteration 53, loss = 1.61059692\n",
      "Iteration 54, loss = 1.60983058\n",
      "Iteration 55, loss = 1.60906422\n",
      "Iteration 56, loss = 1.60829758\n",
      "Iteration 57, loss = 1.60753071\n",
      "Iteration 58, loss = 1.60676388\n",
      "Iteration 59, loss = 1.60599715\n",
      "Iteration 60, loss = 1.60523053\n",
      "Iteration 61, loss = 1.60446395\n",
      "Iteration 62, loss = 1.60369566\n",
      "Iteration 63, loss = 1.60292736\n",
      "Iteration 64, loss = 1.60215908\n",
      "Iteration 65, loss = 1.60139061\n",
      "Iteration 66, loss = 1.60062215\n",
      "Iteration 67, loss = 1.59985380\n",
      "Iteration 68, loss = 1.59908559\n",
      "Iteration 69, loss = 1.59831755\n",
      "Iteration 70, loss = 1.59754970\n",
      "Iteration 71, loss = 1.59678206\n",
      "Iteration 72, loss = 1.59601466\n",
      "Iteration 73, loss = 1.59524750\n",
      "Iteration 74, loss = 1.59448019\n",
      "Iteration 75, loss = 1.59371307\n",
      "Iteration 76, loss = 1.59294620\n",
      "Iteration 77, loss = 1.59217956\n",
      "Iteration 78, loss = 1.59141299\n",
      "Iteration 79, loss = 1.59064668\n",
      "Iteration 80, loss = 1.58988064\n",
      "Iteration 81, loss = 1.58911488\n",
      "Iteration 82, loss = 1.58834945\n",
      "Iteration 83, loss = 1.58758434\n",
      "Iteration 84, loss = 1.58681954\n",
      "Iteration 85, loss = 1.58605505\n",
      "Iteration 86, loss = 1.58529087\n",
      "Iteration 87, loss = 1.58452701\n",
      "Iteration 88, loss = 1.58376348\n",
      "Iteration 89, loss = 1.58300026\n",
      "Iteration 90, loss = 1.58223729\n",
      "Iteration 91, loss = 1.58147262\n",
      "Iteration 92, loss = 1.58070794\n",
      "Iteration 93, loss = 1.57994342\n",
      "Iteration 94, loss = 1.57917907\n",
      "Iteration 95, loss = 1.57841491\n",
      "Iteration 96, loss = 1.57765097\n",
      "Iteration 97, loss = 1.57688724\n",
      "Iteration 98, loss = 1.57612375\n",
      "Iteration 99, loss = 1.57536051\n",
      "Iteration 100, loss = 1.57459670\n",
      "Iteration 101, loss = 1.57383283\n",
      "Iteration 102, loss = 1.57306916\n",
      "Iteration 103, loss = 1.57230568\n",
      "Iteration 104, loss = 1.57154242\n",
      "Iteration 105, loss = 1.57077797\n",
      "Iteration 106, loss = 1.57001155\n",
      "Iteration 107, loss = 1.56924400\n",
      "Iteration 108, loss = 1.56847639\n",
      "Iteration 109, loss = 1.56770982\n",
      "Iteration 110, loss = 1.56694308\n",
      "Iteration 111, loss = 1.56617604\n",
      "Iteration 112, loss = 1.56540799\n",
      "Iteration 113, loss = 1.56463948\n",
      "Iteration 114, loss = 1.56387100\n",
      "Iteration 115, loss = 1.56310258\n",
      "Iteration 116, loss = 1.56233426\n",
      "Iteration 117, loss = 1.56156601\n",
      "Iteration 118, loss = 1.56079643\n",
      "Iteration 119, loss = 1.56002574\n",
      "Iteration 120, loss = 1.55925526\n",
      "Iteration 121, loss = 1.55848461\n",
      "Iteration 122, loss = 1.55771403\n",
      "Iteration 123, loss = 1.55694355\n",
      "Iteration 124, loss = 1.55617329\n",
      "Iteration 125, loss = 1.55540357\n",
      "Iteration 126, loss = 1.55463505\n",
      "Iteration 127, loss = 1.55386528\n",
      "Iteration 128, loss = 1.55309469\n",
      "Iteration 129, loss = 1.55232414\n",
      "Iteration 130, loss = 1.55155374\n",
      "Iteration 131, loss = 1.55078353\n",
      "Iteration 132, loss = 1.55001343\n",
      "Iteration 133, loss = 1.54924355\n",
      "Iteration 134, loss = 1.54847391\n",
      "Iteration 135, loss = 1.54770453\n",
      "Iteration 136, loss = 1.54693300\n",
      "Iteration 137, loss = 1.54616152\n",
      "Iteration 138, loss = 1.54539014\n",
      "Iteration 139, loss = 1.54461890\n",
      "Iteration 140, loss = 1.54384746\n",
      "Iteration 141, loss = 1.54307611\n",
      "Iteration 142, loss = 1.54230828\n",
      "Iteration 143, loss = 1.54154191\n",
      "Iteration 144, loss = 1.54077516\n",
      "Iteration 145, loss = 1.54000700\n",
      "Iteration 146, loss = 1.53923915\n",
      "Iteration 147, loss = 1.53847154\n",
      "Iteration 148, loss = 1.53770103\n",
      "Iteration 149, loss = 1.53693060\n",
      "Iteration 150, loss = 1.53616030\n",
      "Iteration 151, loss = 1.53539015\n",
      "Iteration 152, loss = 1.53461937\n",
      "Iteration 153, loss = 1.53384620\n",
      "Iteration 154, loss = 1.53307300\n",
      "Iteration 155, loss = 1.53229968\n",
      "Iteration 156, loss = 1.53152396\n",
      "Iteration 157, loss = 1.53074706\n",
      "Iteration 158, loss = 1.52997004\n",
      "Iteration 159, loss = 1.52919009\n",
      "Iteration 160, loss = 1.52840920\n",
      "Iteration 161, loss = 1.52762766\n",
      "Iteration 162, loss = 1.52684312\n",
      "Iteration 163, loss = 1.52605733\n",
      "Iteration 164, loss = 1.52526811\n",
      "Iteration 165, loss = 1.52447806\n",
      "Iteration 166, loss = 1.52368313\n",
      "Iteration 167, loss = 1.52288600\n",
      "Iteration 168, loss = 1.52208741\n",
      "Iteration 169, loss = 1.52128787\n",
      "Iteration 170, loss = 1.52048785\n",
      "Iteration 171, loss = 1.51968749\n",
      "Iteration 172, loss = 1.51888689\n",
      "Iteration 173, loss = 1.51808654\n",
      "Iteration 174, loss = 1.51728692\n",
      "Iteration 175, loss = 1.51648651\n",
      "Iteration 176, loss = 1.51568543\n",
      "Iteration 177, loss = 1.51488446\n",
      "Iteration 178, loss = 1.51408366\n",
      "Iteration 179, loss = 1.51328308\n",
      "Iteration 180, loss = 1.51248279\n",
      "Iteration 181, loss = 1.51168285\n",
      "Iteration 182, loss = 1.51088125\n",
      "Iteration 183, loss = 1.51007460\n",
      "Iteration 184, loss = 1.50926540\n",
      "Iteration 185, loss = 1.50845575\n",
      "Iteration 186, loss = 1.50764589\n",
      "Iteration 187, loss = 1.50683588\n",
      "Iteration 188, loss = 1.50602303\n",
      "Iteration 189, loss = 1.50521009\n",
      "Iteration 190, loss = 1.50439890\n",
      "Iteration 191, loss = 1.50358788\n",
      "Iteration 192, loss = 1.50277708\n",
      "Iteration 193, loss = 1.50196674\n",
      "Iteration 194, loss = 1.50115692\n",
      "Iteration 195, loss = 1.50034750\n",
      "Iteration 196, loss = 1.49953853\n",
      "Iteration 197, loss = 1.49872849\n",
      "Iteration 198, loss = 1.49791681\n",
      "Iteration 199, loss = 1.49710538\n",
      "Iteration 200, loss = 1.49629414\n",
      "Iteration 201, loss = 1.49548324\n",
      "Iteration 202, loss = 1.49467272\n",
      "Iteration 203, loss = 1.49386262\n",
      "Iteration 204, loss = 1.49305251\n",
      "Iteration 205, loss = 1.49224076\n",
      "Iteration 206, loss = 1.49142769\n",
      "Iteration 207, loss = 1.49061483\n",
      "Iteration 208, loss = 1.48980214\n",
      "Iteration 209, loss = 1.48898976\n",
      "Iteration 210, loss = 1.48817773\n",
      "Iteration 211, loss = 1.48736608\n",
      "Iteration 212, loss = 1.48655486\n",
      "Iteration 213, loss = 1.48574408\n",
      "Iteration 214, loss = 1.48493378\n",
      "Iteration 215, loss = 1.48412398\n",
      "Iteration 216, loss = 1.48331470\n",
      "Iteration 217, loss = 1.48250468\n",
      "Iteration 218, loss = 1.48169279\n",
      "Iteration 219, loss = 1.48088119\n",
      "Iteration 220, loss = 1.48006992\n",
      "Iteration 221, loss = 1.47925903\n",
      "Iteration 222, loss = 1.47844835\n",
      "Iteration 223, loss = 1.47763803\n",
      "Iteration 224, loss = 1.47682519\n",
      "Iteration 225, loss = 1.47601259\n",
      "Iteration 226, loss = 1.47520028\n",
      "Iteration 227, loss = 1.47438830\n",
      "Iteration 228, loss = 1.47357664\n",
      "Iteration 229, loss = 1.47276487\n",
      "Iteration 230, loss = 1.47195266\n",
      "Iteration 231, loss = 1.47113926\n",
      "Iteration 232, loss = 1.47032615\n",
      "Iteration 233, loss = 1.46951001\n",
      "Iteration 234, loss = 1.46869173\n",
      "Iteration 235, loss = 1.46787334\n",
      "Iteration 236, loss = 1.46705494\n",
      "Iteration 237, loss = 1.46623660\n",
      "Iteration 238, loss = 1.46541839\n",
      "Iteration 239, loss = 1.46460038\n",
      "Iteration 240, loss = 1.46378242\n",
      "Iteration 241, loss = 1.46296446\n",
      "Iteration 242, loss = 1.46214680\n",
      "Iteration 243, loss = 1.46132842\n",
      "Iteration 244, loss = 1.46050902\n",
      "Iteration 245, loss = 1.45969065\n",
      "Iteration 246, loss = 1.45887261\n",
      "Iteration 247, loss = 1.45805497\n",
      "Iteration 248, loss = 1.45723771\n",
      "Iteration 249, loss = 1.45642108\n",
      "Iteration 250, loss = 1.45560239\n",
      "Iteration 251, loss = 1.45478247\n",
      "Iteration 252, loss = 1.45396385\n",
      "Iteration 253, loss = 1.45314591\n",
      "Iteration 254, loss = 1.45232838\n",
      "Iteration 255, loss = 1.45151129\n",
      "Iteration 256, loss = 1.45069468\n",
      "Iteration 257, loss = 1.44987856\n",
      "Iteration 258, loss = 1.44906297\n",
      "Iteration 259, loss = 1.44824791\n",
      "Iteration 260, loss = 1.44743339\n",
      "Iteration 261, loss = 1.44661944\n",
      "Iteration 262, loss = 1.44580616\n",
      "Iteration 263, loss = 1.44499379\n",
      "Iteration 264, loss = 1.44418171\n",
      "Iteration 265, loss = 1.44336868\n",
      "Iteration 266, loss = 1.44255615\n",
      "Iteration 267, loss = 1.44174405\n",
      "Iteration 268, loss = 1.44093245\n",
      "Iteration 269, loss = 1.44012138\n",
      "Iteration 270, loss = 1.43931084\n",
      "Iteration 271, loss = 1.43850085\n",
      "Iteration 272, loss = 1.43769128\n",
      "Iteration 273, loss = 1.43688227\n",
      "Iteration 274, loss = 1.43607383\n",
      "Iteration 275, loss = 1.43526594\n",
      "Iteration 276, loss = 1.43445863\n",
      "Iteration 277, loss = 1.43365190\n",
      "Iteration 278, loss = 1.43284574\n",
      "Iteration 279, loss = 1.43204017\n",
      "Iteration 280, loss = 1.43123517\n",
      "Iteration 281, loss = 1.43043076\n",
      "Iteration 282, loss = 1.42962693\n",
      "Iteration 283, loss = 1.42882369\n",
      "Iteration 284, loss = 1.42802104\n",
      "Iteration 285, loss = 1.42721919\n",
      "Iteration 286, loss = 1.42641836\n",
      "Iteration 287, loss = 1.42561791\n",
      "Iteration 288, loss = 1.42481756\n",
      "Iteration 289, loss = 1.42401815\n",
      "Iteration 290, loss = 1.42321835\n",
      "Iteration 291, loss = 1.42241902\n",
      "Iteration 292, loss = 1.42162020\n",
      "Iteration 293, loss = 1.42082189\n",
      "Iteration 294, loss = 1.42002410\n",
      "Iteration 295, loss = 1.41922682\n",
      "Iteration 296, loss = 1.41843008\n",
      "Iteration 297, loss = 1.41763387\n",
      "Iteration 298, loss = 1.41683819\n",
      "Iteration 299, loss = 1.41604305\n",
      "Iteration 300, loss = 1.41524855\n",
      "Iteration 301, loss = 1.41445514\n",
      "Iteration 302, loss = 1.41366232\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 303, loss = 1.41286881\n",
      "Iteration 304, loss = 1.41207216\n",
      "Iteration 305, loss = 1.41127569\n",
      "Iteration 306, loss = 1.41047946\n",
      "Iteration 307, loss = 1.40968351\n",
      "Iteration 308, loss = 1.40888786\n",
      "Iteration 309, loss = 1.40809255\n",
      "Iteration 310, loss = 1.40729758\n",
      "Iteration 311, loss = 1.40650298\n",
      "Iteration 312, loss = 1.40570878\n",
      "Iteration 313, loss = 1.40491499\n",
      "Iteration 314, loss = 1.40412147\n",
      "Iteration 315, loss = 1.40332847\n",
      "Iteration 316, loss = 1.40253592\n",
      "Iteration 317, loss = 1.40174383\n",
      "Iteration 318, loss = 1.40095220\n",
      "Iteration 319, loss = 1.40016104\n",
      "Iteration 320, loss = 1.39937035\n",
      "Iteration 321, loss = 1.39858015\n",
      "Iteration 322, loss = 1.39779043\n",
      "Iteration 323, loss = 1.39699755\n",
      "Iteration 324, loss = 1.39620476\n",
      "Iteration 325, loss = 1.39541231\n",
      "Iteration 326, loss = 1.39462025\n",
      "Iteration 327, loss = 1.39382854\n",
      "Iteration 328, loss = 1.39303737\n",
      "Iteration 329, loss = 1.39224654\n",
      "Iteration 330, loss = 1.39145609\n",
      "Iteration 331, loss = 1.39066599\n",
      "Iteration 332, loss = 1.38987623\n",
      "Iteration 333, loss = 1.38908655\n",
      "Iteration 334, loss = 1.38829720\n",
      "Iteration 335, loss = 1.38750825\n",
      "Iteration 336, loss = 1.38671970\n",
      "Iteration 337, loss = 1.38593158\n",
      "Iteration 338, loss = 1.38514389\n",
      "Iteration 339, loss = 1.38435664\n",
      "Iteration 340, loss = 1.38356983\n",
      "Iteration 341, loss = 1.38278347\n",
      "Iteration 342, loss = 1.38199757\n",
      "Iteration 343, loss = 1.38121214\n",
      "Iteration 344, loss = 1.38042717\n",
      "Iteration 345, loss = 1.37964266\n",
      "Iteration 346, loss = 1.37885863\n",
      "Iteration 347, loss = 1.37807507\n",
      "Iteration 348, loss = 1.37729200\n",
      "Iteration 349, loss = 1.37651026\n",
      "Iteration 350, loss = 1.37572906\n",
      "Iteration 351, loss = 1.37494831\n",
      "Iteration 352, loss = 1.37416805\n",
      "Iteration 353, loss = 1.37338830\n",
      "Iteration 354, loss = 1.37260907\n",
      "Iteration 355, loss = 1.37183034\n",
      "Iteration 356, loss = 1.37105212\n",
      "Iteration 357, loss = 1.37027440\n",
      "Iteration 358, loss = 1.36949717\n",
      "Iteration 359, loss = 1.36872044\n",
      "Iteration 360, loss = 1.36794427\n",
      "Iteration 361, loss = 1.36716874\n",
      "Iteration 362, loss = 1.36639334\n",
      "Iteration 363, loss = 1.36561834\n",
      "Iteration 364, loss = 1.36484380\n",
      "Iteration 365, loss = 1.36406971\n",
      "Iteration 366, loss = 1.36329613\n",
      "Iteration 367, loss = 1.36252299\n",
      "Iteration 368, loss = 1.36175032\n",
      "Iteration 369, loss = 1.36097810\n",
      "Iteration 370, loss = 1.36020633\n",
      "Iteration 371, loss = 1.35943501\n",
      "Iteration 372, loss = 1.35866414\n",
      "Iteration 373, loss = 1.35789372\n",
      "Iteration 374, loss = 1.35712368\n",
      "Iteration 375, loss = 1.35635401\n",
      "Iteration 376, loss = 1.35558468\n",
      "Iteration 377, loss = 1.35481598\n",
      "Iteration 378, loss = 1.35404787\n",
      "Iteration 379, loss = 1.35328021\n",
      "Iteration 380, loss = 1.35251277\n",
      "Iteration 381, loss = 1.35174562\n",
      "Iteration 382, loss = 1.35097904\n",
      "Iteration 383, loss = 1.35021289\n",
      "Iteration 384, loss = 1.34944718\n",
      "Iteration 385, loss = 1.34868204\n",
      "Iteration 386, loss = 1.34791733\n",
      "Iteration 387, loss = 1.34715306\n",
      "Iteration 388, loss = 1.34638431\n",
      "Iteration 389, loss = 1.34561399\n",
      "Iteration 390, loss = 1.34484369\n",
      "Iteration 391, loss = 1.34407334\n",
      "Iteration 392, loss = 1.34330298\n",
      "Iteration 393, loss = 1.34253268\n",
      "Iteration 394, loss = 1.34176246\n",
      "Iteration 395, loss = 1.34099237\n",
      "Iteration 396, loss = 1.34022243\n",
      "Iteration 397, loss = 1.33945268\n",
      "Iteration 398, loss = 1.33868314\n",
      "Iteration 399, loss = 1.33791384\n",
      "Iteration 400, loss = 1.33714479\n",
      "Iteration 401, loss = 1.33637601\n",
      "Iteration 402, loss = 1.33560753\n",
      "Iteration 403, loss = 1.33483934\n",
      "Iteration 404, loss = 1.33407148\n",
      "Iteration 405, loss = 1.33330395\n",
      "Iteration 406, loss = 1.33253675\n",
      "Iteration 407, loss = 1.33176990\n",
      "Iteration 408, loss = 1.33100341\n",
      "Iteration 409, loss = 1.33023725\n",
      "Iteration 410, loss = 1.32947139\n",
      "Iteration 411, loss = 1.32870632\n",
      "Iteration 412, loss = 1.32794167\n",
      "Iteration 413, loss = 1.32717744\n",
      "Iteration 414, loss = 1.32641361\n",
      "Iteration 415, loss = 1.32564924\n",
      "Iteration 416, loss = 1.32488054\n",
      "Iteration 417, loss = 1.32411180\n",
      "Iteration 418, loss = 1.32334328\n",
      "Iteration 419, loss = 1.32257485\n",
      "Iteration 420, loss = 1.32180652\n",
      "Iteration 421, loss = 1.32103834\n",
      "Iteration 422, loss = 1.32027034\n",
      "Iteration 423, loss = 1.31950253\n",
      "Iteration 424, loss = 1.31873373\n",
      "Iteration 425, loss = 1.31796284\n",
      "Iteration 426, loss = 1.31719193\n",
      "Iteration 427, loss = 1.31642105\n",
      "Iteration 428, loss = 1.31565024\n",
      "Iteration 429, loss = 1.31487955\n",
      "Iteration 430, loss = 1.31410893\n",
      "Iteration 431, loss = 1.31333842\n",
      "Iteration 432, loss = 1.31256287\n",
      "Iteration 433, loss = 1.31178651\n",
      "Iteration 434, loss = 1.31100984\n",
      "Iteration 435, loss = 1.31023312\n",
      "Iteration 436, loss = 1.30945630\n",
      "Iteration 437, loss = 1.30867944\n",
      "Iteration 438, loss = 1.30790258\n",
      "Iteration 439, loss = 1.30712577\n",
      "Iteration 440, loss = 1.30634907\n",
      "Iteration 441, loss = 1.30557250\n",
      "Iteration 442, loss = 1.30479611\n",
      "Iteration 443, loss = 1.30401998\n",
      "Iteration 444, loss = 1.30324345\n",
      "Iteration 445, loss = 1.30246117\n",
      "Iteration 446, loss = 1.30167864\n",
      "Iteration 447, loss = 1.30089586\n",
      "Iteration 448, loss = 1.30011289\n",
      "Iteration 449, loss = 1.29933034\n",
      "Iteration 450, loss = 1.29854793\n",
      "Iteration 451, loss = 1.29776562\n",
      "Iteration 452, loss = 1.29698345\n",
      "Iteration 453, loss = 1.29620146\n",
      "Iteration 454, loss = 1.29541969\n",
      "Iteration 455, loss = 1.29463816\n",
      "Iteration 456, loss = 1.29385688\n",
      "Iteration 457, loss = 1.29307574\n",
      "Iteration 458, loss = 1.29229491\n",
      "Iteration 459, loss = 1.29151440\n",
      "Iteration 460, loss = 1.29072801\n",
      "Iteration 461, loss = 1.28994096\n",
      "Iteration 462, loss = 1.28915373\n",
      "Iteration 463, loss = 1.28836650\n",
      "Iteration 464, loss = 1.28757921\n",
      "Iteration 465, loss = 1.28679194\n",
      "Iteration 466, loss = 1.28600472\n",
      "Iteration 467, loss = 1.28521761\n",
      "Iteration 468, loss = 1.28443065\n",
      "Iteration 469, loss = 1.28364388\n",
      "Iteration 470, loss = 1.28285734\n",
      "Iteration 471, loss = 1.28207093\n",
      "Iteration 472, loss = 1.28127980\n",
      "Iteration 473, loss = 1.28048857\n",
      "Iteration 474, loss = 1.27969731\n",
      "Iteration 475, loss = 1.27890607\n",
      "Iteration 476, loss = 1.27811490\n",
      "Iteration 477, loss = 1.27732387\n",
      "Iteration 478, loss = 1.27653301\n",
      "Iteration 479, loss = 1.27574235\n",
      "Iteration 480, loss = 1.27495194\n",
      "Iteration 481, loss = 1.27416180\n",
      "Iteration 482, loss = 1.27337196\n",
      "Iteration 483, loss = 1.27258239\n",
      "Iteration 484, loss = 1.27179323\n",
      "Iteration 485, loss = 1.27100447\n",
      "Iteration 486, loss = 1.27021610\n",
      "Iteration 487, loss = 1.26942814\n",
      "Iteration 488, loss = 1.26864058\n",
      "Iteration 489, loss = 1.26785345\n",
      "Iteration 490, loss = 1.26706869\n",
      "Iteration 491, loss = 1.26628519\n",
      "Iteration 492, loss = 1.26550235\n",
      "Iteration 493, loss = 1.26472011\n",
      "Iteration 494, loss = 1.26393839\n",
      "Iteration 495, loss = 1.26315728\n",
      "Iteration 496, loss = 1.26237675\n",
      "Iteration 497, loss = 1.26159695\n",
      "Iteration 498, loss = 1.26081781\n",
      "Iteration 499, loss = 1.26003925\n",
      "Iteration 500, loss = 1.25926126\n",
      "Iteration 501, loss = 1.25848383\n",
      "Iteration 502, loss = 1.25770696\n",
      "Iteration 503, loss = 1.25693064\n",
      "Iteration 504, loss = 1.25615485\n",
      "Iteration 505, loss = 1.25537961\n",
      "Iteration 506, loss = 1.25460489\n",
      "Iteration 507, loss = 1.25383069\n",
      "Iteration 508, loss = 1.25305682\n",
      "Iteration 509, loss = 1.25228331\n",
      "Iteration 510, loss = 1.25151017\n",
      "Iteration 511, loss = 1.25073749\n",
      "Iteration 512, loss = 1.24996529\n",
      "Iteration 513, loss = 1.24919355\n",
      "Iteration 514, loss = 1.24842237\n",
      "Iteration 515, loss = 1.24765169\n",
      "Iteration 516, loss = 1.24688148\n",
      "Iteration 517, loss = 1.24611171\n",
      "Iteration 518, loss = 1.24534237\n",
      "Iteration 519, loss = 1.24457350\n",
      "Iteration 520, loss = 1.24380510\n",
      "Iteration 521, loss = 1.24303738\n",
      "Iteration 522, loss = 1.24227013\n",
      "Iteration 523, loss = 1.24150336\n",
      "Iteration 524, loss = 1.24073706\n",
      "Iteration 525, loss = 1.23997124\n",
      "Iteration 526, loss = 1.23920588\n",
      "Iteration 527, loss = 1.23844098\n",
      "Iteration 528, loss = 1.23767655\n",
      "Iteration 529, loss = 1.23691257\n",
      "Iteration 530, loss = 1.23614906\n",
      "Iteration 531, loss = 1.23538600\n",
      "Iteration 532, loss = 1.23462339\n",
      "Iteration 533, loss = 1.23386124\n",
      "Iteration 534, loss = 1.23309972\n",
      "Iteration 535, loss = 1.23233893\n",
      "Iteration 536, loss = 1.23157862\n",
      "Iteration 537, loss = 1.23081689\n",
      "Iteration 538, loss = 1.23005346\n",
      "Iteration 539, loss = 1.22929016\n",
      "Iteration 540, loss = 1.22851975\n",
      "Iteration 541, loss = 1.22774800\n",
      "Iteration 542, loss = 1.22697573\n",
      "Iteration 543, loss = 1.22620383\n",
      "Iteration 544, loss = 1.22543217\n",
      "Iteration 545, loss = 1.22466033\n",
      "Iteration 546, loss = 1.22388838\n",
      "Iteration 547, loss = 1.22311638\n",
      "Iteration 548, loss = 1.22234440\n",
      "Iteration 549, loss = 1.22157241\n",
      "Iteration 550, loss = 1.22080042\n",
      "Iteration 551, loss = 1.22002857\n",
      "Iteration 552, loss = 1.21925688\n",
      "Iteration 553, loss = 1.21848539\n",
      "Iteration 554, loss = 1.21771402\n",
      "Iteration 555, loss = 1.21694284\n",
      "Iteration 556, loss = 1.21616980\n",
      "Iteration 557, loss = 1.21539274\n",
      "Iteration 558, loss = 1.21461545\n",
      "Iteration 559, loss = 1.21383802\n",
      "Iteration 560, loss = 1.21306051\n",
      "Iteration 561, loss = 1.21228299\n",
      "Iteration 562, loss = 1.21150555\n",
      "Iteration 563, loss = 1.21072839\n",
      "Iteration 564, loss = 1.20995138\n",
      "Iteration 565, loss = 1.20917455\n",
      "Iteration 566, loss = 1.20839795\n",
      "Iteration 567, loss = 1.20762159\n",
      "Iteration 568, loss = 1.20684551\n",
      "Iteration 569, loss = 1.20606974\n",
      "Iteration 570, loss = 1.20529429\n",
      "Iteration 571, loss = 1.20451918\n",
      "Iteration 572, loss = 1.20374443\n",
      "Iteration 573, loss = 1.20297005\n",
      "Iteration 574, loss = 1.20219606\n",
      "Iteration 575, loss = 1.20142246\n",
      "Iteration 576, loss = 1.20064927\n",
      "Iteration 577, loss = 1.19987649\n",
      "Iteration 578, loss = 1.19910418\n",
      "Iteration 579, loss = 1.19833255\n",
      "Iteration 580, loss = 1.19756138\n",
      "Iteration 581, loss = 1.19679073\n",
      "Iteration 582, loss = 1.19602073\n",
      "Iteration 583, loss = 1.19525121\n",
      "Iteration 584, loss = 1.19448218\n",
      "Iteration 585, loss = 1.19371303\n",
      "Iteration 586, loss = 1.19294428\n",
      "Iteration 587, loss = 1.19217597\n",
      "Iteration 588, loss = 1.19140809\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 589, loss = 1.19064064\n",
      "Iteration 590, loss = 1.18987364\n",
      "Iteration 591, loss = 1.18910708\n",
      "Iteration 592, loss = 1.18834097\n",
      "Iteration 593, loss = 1.18757531\n",
      "Iteration 594, loss = 1.18681010\n",
      "Iteration 595, loss = 1.18604534\n",
      "Iteration 596, loss = 1.18528104\n",
      "Iteration 597, loss = 1.18451720\n",
      "Iteration 598, loss = 1.18375381\n",
      "Iteration 599, loss = 1.18299088\n",
      "Iteration 600, loss = 1.18222841\n",
      "Iteration 601, loss = 1.18146640\n",
      "Iteration 602, loss = 1.18070485\n",
      "Iteration 603, loss = 1.17994375\n",
      "Iteration 604, loss = 1.17918312\n",
      "Iteration 605, loss = 1.17842294\n",
      "Iteration 606, loss = 1.17766322\n",
      "Iteration 607, loss = 1.17690395\n",
      "Iteration 608, loss = 1.17614518\n",
      "Iteration 609, loss = 1.17538702\n",
      "Iteration 610, loss = 1.17462933\n",
      "Iteration 611, loss = 1.17387222\n",
      "Iteration 612, loss = 1.17311560\n",
      "Iteration 613, loss = 1.17235946\n",
      "Iteration 614, loss = 1.17160380\n",
      "Iteration 615, loss = 1.17084860\n",
      "Iteration 616, loss = 1.17009387\n",
      "Iteration 617, loss = 1.16933960\n",
      "Iteration 618, loss = 1.16858580\n",
      "Iteration 619, loss = 1.16783244\n",
      "Iteration 620, loss = 1.16707955\n",
      "Iteration 621, loss = 1.16632710\n",
      "Iteration 622, loss = 1.16557511\n",
      "Iteration 623, loss = 1.16482349\n",
      "Iteration 624, loss = 1.16407228\n",
      "Iteration 625, loss = 1.16332151\n",
      "Iteration 626, loss = 1.16257126\n",
      "Iteration 627, loss = 1.16182141\n",
      "Iteration 628, loss = 1.16107198\n",
      "Iteration 629, loss = 1.16032287\n",
      "Iteration 630, loss = 1.15957391\n",
      "Iteration 631, loss = 1.15882534\n",
      "Iteration 632, loss = 1.15807728\n",
      "Iteration 633, loss = 1.15732966\n",
      "Iteration 634, loss = 1.15658246\n",
      "Iteration 635, loss = 1.15583580\n",
      "Iteration 636, loss = 1.15508956\n",
      "Iteration 637, loss = 1.15434371\n",
      "Iteration 638, loss = 1.15359825\n",
      "Iteration 639, loss = 1.15285338\n",
      "Iteration 640, loss = 1.15210918\n",
      "Iteration 641, loss = 1.15136541\n",
      "Iteration 642, loss = 1.15062203\n",
      "Iteration 643, loss = 1.14987907\n",
      "Iteration 644, loss = 1.14913652\n",
      "Iteration 645, loss = 1.14839428\n",
      "Iteration 646, loss = 1.14765247\n",
      "Iteration 647, loss = 1.14691116\n",
      "Iteration 648, loss = 1.14617027\n",
      "Iteration 649, loss = 1.14542979\n",
      "Iteration 650, loss = 1.14468974\n",
      "Iteration 651, loss = 1.14395010\n",
      "Iteration 652, loss = 1.14321087\n",
      "Iteration 653, loss = 1.14247206\n",
      "Iteration 654, loss = 1.14173365\n",
      "Iteration 655, loss = 1.14099566\n",
      "Iteration 656, loss = 1.14025807\n",
      "Iteration 657, loss = 1.13952089\n",
      "Iteration 658, loss = 1.13878412\n",
      "Iteration 659, loss = 1.13804775\n",
      "Iteration 660, loss = 1.13731181\n",
      "Iteration 661, loss = 1.13657636\n",
      "Iteration 662, loss = 1.13584131\n",
      "Iteration 663, loss = 1.13510667\n",
      "Iteration 664, loss = 1.13437244\n",
      "Iteration 665, loss = 1.13363861\n",
      "Iteration 666, loss = 1.13290518\n",
      "Iteration 667, loss = 1.13217215\n",
      "Iteration 668, loss = 1.13143941\n",
      "Iteration 669, loss = 1.13070704\n",
      "Iteration 670, loss = 1.12997505\n",
      "Iteration 671, loss = 1.12924337\n",
      "Iteration 672, loss = 1.12851200\n",
      "Iteration 673, loss = 1.12778101\n",
      "Iteration 674, loss = 1.12705034\n",
      "Iteration 675, loss = 1.12632058\n",
      "Iteration 676, loss = 1.12559166\n",
      "Iteration 677, loss = 1.12486331\n",
      "Iteration 678, loss = 1.12413539\n",
      "Iteration 679, loss = 1.12340790\n",
      "Iteration 680, loss = 1.12268083\n",
      "Iteration 681, loss = 1.12195418\n",
      "Iteration 682, loss = 1.12122794\n",
      "Iteration 683, loss = 1.12050211\n",
      "Iteration 684, loss = 1.11977669\n",
      "Iteration 685, loss = 1.11905167\n",
      "Iteration 686, loss = 1.11832705\n",
      "Iteration 687, loss = 1.11760283\n",
      "Iteration 688, loss = 1.11687862\n",
      "Iteration 689, loss = 1.11615450\n",
      "Iteration 690, loss = 1.11543065\n",
      "Iteration 691, loss = 1.11470737\n",
      "Iteration 692, loss = 1.11398456\n",
      "Iteration 693, loss = 1.11326212\n",
      "Iteration 694, loss = 1.11254004\n",
      "Iteration 695, loss = 1.11181832\n",
      "Iteration 696, loss = 1.11109698\n",
      "Iteration 697, loss = 1.11037599\n",
      "Iteration 698, loss = 1.10965538\n",
      "Iteration 699, loss = 1.10893513\n",
      "Iteration 700, loss = 1.10821524\n",
      "Iteration 701, loss = 1.10749573\n",
      "Iteration 702, loss = 1.10677658\n",
      "Iteration 703, loss = 1.10605764\n",
      "Iteration 704, loss = 1.10533871\n",
      "Iteration 705, loss = 1.10462015\n",
      "Iteration 706, loss = 1.10390193\n",
      "Iteration 707, loss = 1.10318405\n",
      "Iteration 708, loss = 1.10246651\n",
      "Iteration 709, loss = 1.10174931\n",
      "Iteration 710, loss = 1.10103269\n",
      "Iteration 711, loss = 1.10031648\n",
      "Iteration 712, loss = 1.09960061\n",
      "Iteration 713, loss = 1.09888509\n",
      "Iteration 714, loss = 1.09816994\n",
      "Iteration 715, loss = 1.09745514\n",
      "Iteration 716, loss = 1.09674071\n",
      "Iteration 717, loss = 1.09602663\n",
      "Iteration 718, loss = 1.09531306\n",
      "Iteration 719, loss = 1.09459988\n",
      "Iteration 720, loss = 1.09388708\n",
      "Iteration 721, loss = 1.09317464\n",
      "Iteration 722, loss = 1.09246263\n",
      "Iteration 723, loss = 1.09175101\n",
      "Iteration 724, loss = 1.09103977\n",
      "Iteration 725, loss = 1.09032889\n",
      "Iteration 726, loss = 1.08961839\n",
      "Iteration 727, loss = 1.08890952\n",
      "Iteration 728, loss = 1.08820125\n",
      "Iteration 729, loss = 1.08749346\n",
      "Iteration 730, loss = 1.08678613\n",
      "Iteration 731, loss = 1.08607926\n",
      "Iteration 732, loss = 1.08537291\n",
      "Iteration 733, loss = 1.08466701\n",
      "Iteration 734, loss = 1.08396154\n",
      "Iteration 735, loss = 1.08325649\n",
      "Iteration 736, loss = 1.08255186\n",
      "Iteration 737, loss = 1.08184769\n",
      "Iteration 738, loss = 1.08114529\n",
      "Iteration 739, loss = 1.08044339\n",
      "Iteration 740, loss = 1.07974197\n",
      "Iteration 741, loss = 1.07904115\n",
      "Iteration 742, loss = 1.07834183\n",
      "Iteration 743, loss = 1.07764303\n",
      "Iteration 744, loss = 1.07694473\n",
      "Iteration 745, loss = 1.07624692\n",
      "Iteration 746, loss = 1.07554949\n",
      "Iteration 747, loss = 1.07485251\n",
      "Iteration 748, loss = 1.07415597\n",
      "Iteration 749, loss = 1.07345986\n",
      "Iteration 750, loss = 1.07276416\n",
      "Iteration 751, loss = 1.07206889\n",
      "Iteration 752, loss = 1.07137401\n",
      "Iteration 753, loss = 1.07067953\n",
      "Iteration 754, loss = 1.06998544\n",
      "Iteration 755, loss = 1.06929173\n",
      "Iteration 756, loss = 1.06859841\n",
      "Iteration 757, loss = 1.06790547\n",
      "Iteration 758, loss = 1.06721307\n",
      "Iteration 759, loss = 1.06652104\n",
      "Iteration 760, loss = 1.06582945\n",
      "Iteration 761, loss = 1.06513823\n",
      "Iteration 762, loss = 1.06444737\n",
      "Iteration 763, loss = 1.06375688\n",
      "Iteration 764, loss = 1.06306674\n",
      "Iteration 765, loss = 1.06237707\n",
      "Iteration 766, loss = 1.06168777\n",
      "Iteration 767, loss = 1.06099884\n",
      "Iteration 768, loss = 1.06031027\n",
      "Iteration 769, loss = 1.05962204\n",
      "Iteration 770, loss = 1.05893390\n",
      "Iteration 771, loss = 1.05824581\n",
      "Iteration 772, loss = 1.05755883\n",
      "Iteration 773, loss = 1.05687267\n",
      "Iteration 774, loss = 1.05618691\n",
      "Iteration 775, loss = 1.05550158\n",
      "Iteration 776, loss = 1.05481779\n",
      "Iteration 777, loss = 1.05413445\n",
      "Iteration 778, loss = 1.05345157\n",
      "Iteration 779, loss = 1.05276894\n",
      "Iteration 780, loss = 1.05208673\n",
      "Iteration 781, loss = 1.05140492\n",
      "Iteration 782, loss = 1.05072350\n",
      "Iteration 783, loss = 1.05004247\n",
      "Iteration 784, loss = 1.04936183\n",
      "Iteration 785, loss = 1.04868156\n",
      "Iteration 786, loss = 1.04800166\n",
      "Iteration 787, loss = 1.04732212\n",
      "Iteration 788, loss = 1.04664294\n",
      "Iteration 789, loss = 1.04596407\n",
      "Iteration 790, loss = 1.04528547\n",
      "Iteration 791, loss = 1.04460721\n",
      "Iteration 792, loss = 1.04392929\n",
      "Iteration 793, loss = 1.04325170\n",
      "Iteration 794, loss = 1.04257444\n",
      "Iteration 795, loss = 1.04189752\n",
      "Iteration 796, loss = 1.04122093\n",
      "Iteration 797, loss = 1.04054466\n",
      "Iteration 798, loss = 1.03986864\n",
      "Iteration 799, loss = 1.03919299\n",
      "Iteration 800, loss = 1.03851766\n",
      "Iteration 801, loss = 1.03784265\n",
      "Iteration 802, loss = 1.03716796\n",
      "Iteration 803, loss = 1.03649358\n",
      "Iteration 804, loss = 1.03581953\n",
      "Iteration 805, loss = 1.03514592\n",
      "Iteration 806, loss = 1.03447279\n",
      "Iteration 807, loss = 1.03379952\n",
      "Iteration 808, loss = 1.03312648\n",
      "Iteration 809, loss = 1.03245373\n",
      "Iteration 810, loss = 1.03178128\n",
      "Iteration 811, loss = 1.03110912\n",
      "Iteration 812, loss = 1.03043725\n",
      "Iteration 813, loss = 1.02976569\n",
      "Iteration 814, loss = 1.02909447\n",
      "Iteration 815, loss = 1.02842357\n",
      "Iteration 816, loss = 1.02775296\n",
      "Iteration 817, loss = 1.02708267\n",
      "Iteration 818, loss = 1.02641267\n",
      "Iteration 819, loss = 1.02574284\n",
      "Iteration 820, loss = 1.02507329\n",
      "Iteration 821, loss = 1.02440403\n",
      "Iteration 822, loss = 1.02373501\n",
      "Iteration 823, loss = 1.02306619\n",
      "Iteration 824, loss = 1.02239767\n",
      "Iteration 825, loss = 1.02172944\n",
      "Iteration 826, loss = 1.02106149\n",
      "Iteration 827, loss = 1.02039384\n",
      "Iteration 828, loss = 1.01972648\n",
      "Iteration 829, loss = 1.01905942\n",
      "Iteration 830, loss = 1.01839265\n",
      "Iteration 831, loss = 1.01772618\n",
      "Iteration 832, loss = 1.01706001\n",
      "Iteration 833, loss = 1.01639414\n",
      "Iteration 834, loss = 1.01572856\n",
      "Iteration 835, loss = 1.01506329\n",
      "Iteration 836, loss = 1.01439833\n",
      "Iteration 837, loss = 1.01373338\n",
      "Iteration 838, loss = 1.01306899\n",
      "Iteration 839, loss = 1.01240491\n",
      "Iteration 840, loss = 1.01174113\n",
      "Iteration 841, loss = 1.01107765\n",
      "Iteration 842, loss = 1.01041447\n",
      "Iteration 843, loss = 1.00975178\n",
      "Iteration 844, loss = 1.00908971\n",
      "Iteration 845, loss = 1.00842798\n",
      "Iteration 846, loss = 1.00776659\n",
      "Iteration 847, loss = 1.00710554\n",
      "Iteration 848, loss = 1.00644482\n",
      "Iteration 849, loss = 1.00578445\n",
      "Iteration 850, loss = 1.00512443\n",
      "Iteration 851, loss = 1.00446474\n",
      "Iteration 852, loss = 1.00380519\n",
      "Iteration 853, loss = 1.00314594\n",
      "Iteration 854, loss = 1.00248691\n",
      "Iteration 855, loss = 1.00182812\n",
      "Iteration 856, loss = 1.00116961\n",
      "Iteration 857, loss = 1.00051139\n",
      "Iteration 858, loss = 0.99985347\n",
      "Iteration 859, loss = 0.99919583\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 860, loss = 0.99853838\n",
      "Iteration 861, loss = 0.99788121\n",
      "Iteration 862, loss = 0.99722433\n",
      "Iteration 863, loss = 0.99656779\n",
      "Iteration 864, loss = 0.99591154\n",
      "Iteration 865, loss = 0.99525559\n",
      "Iteration 866, loss = 0.99459993\n",
      "Iteration 867, loss = 0.99394456\n",
      "Iteration 868, loss = 0.99328950\n",
      "Iteration 869, loss = 0.99263484\n",
      "Iteration 870, loss = 0.99198045\n",
      "Iteration 871, loss = 0.99132623\n",
      "Iteration 872, loss = 0.99067230\n",
      "Iteration 873, loss = 0.99001865\n",
      "Iteration 874, loss = 0.98936528\n",
      "Iteration 875, loss = 0.98871219\n",
      "Iteration 876, loss = 0.98805939\n",
      "Iteration 877, loss = 0.98740690\n",
      "Iteration 878, loss = 0.98675465\n",
      "Iteration 879, loss = 0.98610272\n",
      "Iteration 880, loss = 0.98545107\n",
      "Iteration 881, loss = 0.98479971\n",
      "Iteration 882, loss = 0.98414864\n",
      "Iteration 883, loss = 0.98349786\n",
      "Iteration 884, loss = 0.98284737\n",
      "Iteration 885, loss = 0.98219697\n",
      "Iteration 886, loss = 0.98154637\n",
      "Iteration 887, loss = 0.98089594\n",
      "Iteration 888, loss = 0.98024587\n",
      "Iteration 889, loss = 0.97959658\n",
      "Iteration 890, loss = 0.97894759\n",
      "Iteration 891, loss = 0.97829889\n",
      "Iteration 892, loss = 0.97765049\n",
      "Iteration 893, loss = 0.97700240\n",
      "Iteration 894, loss = 0.97635458\n",
      "Iteration 895, loss = 0.97570707\n",
      "Iteration 896, loss = 0.97505986\n",
      "Iteration 897, loss = 0.97441317\n",
      "Iteration 898, loss = 0.97376701\n",
      "Iteration 899, loss = 0.97312118\n",
      "Iteration 900, loss = 0.97247567\n",
      "Iteration 901, loss = 0.97183049\n",
      "Iteration 902, loss = 0.97118562\n",
      "Iteration 903, loss = 0.97054096\n",
      "Iteration 904, loss = 0.96989663\n",
      "Iteration 905, loss = 0.96925263\n",
      "Iteration 906, loss = 0.96860893\n",
      "Iteration 907, loss = 0.96796553\n",
      "Iteration 908, loss = 0.96732244\n",
      "Iteration 909, loss = 0.96667967\n",
      "Iteration 910, loss = 0.96603716\n",
      "Iteration 911, loss = 0.96539498\n",
      "Iteration 912, loss = 0.96475309\n",
      "Iteration 913, loss = 0.96411123\n",
      "Iteration 914, loss = 0.96346954\n",
      "Iteration 915, loss = 0.96282811\n",
      "Iteration 916, loss = 0.96218694\n",
      "Iteration 917, loss = 0.96154604\n",
      "Iteration 918, loss = 0.96090531\n",
      "Iteration 919, loss = 0.96026485\n",
      "Iteration 920, loss = 0.95962465\n",
      "Iteration 921, loss = 0.95898472\n",
      "Iteration 922, loss = 0.95834454\n",
      "Iteration 923, loss = 0.95770448\n",
      "Iteration 924, loss = 0.95706463\n",
      "Iteration 925, loss = 0.95642500\n",
      "Iteration 926, loss = 0.95578561\n",
      "Iteration 927, loss = 0.95514645\n",
      "Iteration 928, loss = 0.95450754\n",
      "Iteration 929, loss = 0.95386888\n",
      "Iteration 930, loss = 0.95323048\n",
      "Iteration 931, loss = 0.95259233\n",
      "Iteration 932, loss = 0.95195444\n",
      "Iteration 933, loss = 0.95131679\n",
      "Iteration 934, loss = 0.95067940\n",
      "Iteration 935, loss = 0.95004227\n",
      "Iteration 936, loss = 0.94940539\n",
      "Iteration 937, loss = 0.94876876\n",
      "Iteration 938, loss = 0.94813241\n",
      "Iteration 939, loss = 0.94749638\n",
      "Iteration 940, loss = 0.94686062\n",
      "Iteration 941, loss = 0.94622514\n",
      "Iteration 942, loss = 0.94558994\n",
      "Iteration 943, loss = 0.94495502\n",
      "Iteration 944, loss = 0.94432038\n",
      "Iteration 945, loss = 0.94368602\n",
      "Iteration 946, loss = 0.94305194\n",
      "Iteration 947, loss = 0.94241794\n",
      "Iteration 948, loss = 0.94178369\n",
      "Iteration 949, loss = 0.94114967\n",
      "Iteration 950, loss = 0.94051585\n",
      "Iteration 951, loss = 0.93988228\n",
      "Iteration 952, loss = 0.93924895\n",
      "Iteration 953, loss = 0.93861586\n",
      "Iteration 954, loss = 0.93798302\n",
      "Iteration 955, loss = 0.93735043\n",
      "Iteration 956, loss = 0.93671810\n",
      "Iteration 957, loss = 0.93608603\n",
      "Iteration 958, loss = 0.93545422\n",
      "Iteration 959, loss = 0.93482267\n",
      "Iteration 960, loss = 0.93419147\n",
      "Iteration 961, loss = 0.93356083\n",
      "Iteration 962, loss = 0.93293048\n",
      "Iteration 963, loss = 0.93230043\n",
      "Iteration 964, loss = 0.93167068\n",
      "Iteration 965, loss = 0.93104122\n",
      "Iteration 966, loss = 0.93041206\n",
      "Iteration 967, loss = 0.92978319\n",
      "Iteration 968, loss = 0.92915462\n",
      "Iteration 969, loss = 0.92852633\n",
      "Iteration 970, loss = 0.92789834\n",
      "Iteration 971, loss = 0.92727063\n",
      "Iteration 972, loss = 0.92664322\n",
      "Iteration 973, loss = 0.92601606\n",
      "Iteration 974, loss = 0.92538903\n",
      "Iteration 975, loss = 0.92476228\n",
      "Iteration 976, loss = 0.92413579\n",
      "Iteration 977, loss = 0.92350959\n",
      "Iteration 978, loss = 0.92288365\n",
      "Iteration 979, loss = 0.92225800\n",
      "Iteration 980, loss = 0.92163262\n",
      "Iteration 981, loss = 0.92100752\n",
      "Iteration 982, loss = 0.92038270\n",
      "Iteration 983, loss = 0.91975817\n",
      "Iteration 984, loss = 0.91913424\n",
      "Iteration 985, loss = 0.91851066\n",
      "Iteration 986, loss = 0.91788729\n",
      "Iteration 987, loss = 0.91726424\n",
      "Iteration 988, loss = 0.91664143\n",
      "Iteration 989, loss = 0.91601869\n",
      "Iteration 990, loss = 0.91539571\n",
      "Iteration 991, loss = 0.91477226\n",
      "Iteration 992, loss = 0.91414898\n",
      "Iteration 993, loss = 0.91352587\n",
      "Iteration 994, loss = 0.91290296\n",
      "Iteration 995, loss = 0.91228054\n",
      "Iteration 996, loss = 0.91165842\n",
      "Iteration 997, loss = 0.91103656\n",
      "Iteration 998, loss = 0.91041495\n",
      "Iteration 999, loss = 0.90979360\n",
      "Iteration 1000, loss = 0.90917251\n",
      "Iteration 1001, loss = 0.90855167\n",
      "Iteration 1002, loss = 0.90793111\n",
      "Iteration 1003, loss = 0.90731100\n",
      "Iteration 1004, loss = 0.90669119\n",
      "Iteration 1005, loss = 0.90607167\n",
      "Iteration 1006, loss = 0.90545278\n",
      "Iteration 1007, loss = 0.90483444\n",
      "Iteration 1008, loss = 0.90421650\n",
      "Iteration 1009, loss = 0.90359890\n",
      "Iteration 1010, loss = 0.90298182\n",
      "Iteration 1011, loss = 0.90236530\n",
      "Iteration 1012, loss = 0.90174914\n",
      "Iteration 1013, loss = 0.90113332\n",
      "Iteration 1014, loss = 0.90051784\n",
      "Iteration 1015, loss = 0.89990270\n",
      "Iteration 1016, loss = 0.89928788\n",
      "Iteration 1017, loss = 0.89867338\n",
      "Iteration 1018, loss = 0.89805934\n",
      "Iteration 1019, loss = 0.89744564\n",
      "Iteration 1020, loss = 0.89683226\n",
      "Iteration 1021, loss = 0.89621920\n",
      "Iteration 1022, loss = 0.89560645\n",
      "Iteration 1023, loss = 0.89499403\n",
      "Iteration 1024, loss = 0.89438190\n",
      "Iteration 1025, loss = 0.89377009\n",
      "Iteration 1026, loss = 0.89315858\n",
      "Iteration 1027, loss = 0.89254737\n",
      "Iteration 1028, loss = 0.89193646\n",
      "Iteration 1029, loss = 0.89132585\n",
      "Iteration 1030, loss = 0.89071553\n",
      "Iteration 1031, loss = 0.89010550\n",
      "Iteration 1032, loss = 0.88949577\n",
      "Iteration 1033, loss = 0.88888633\n",
      "Iteration 1034, loss = 0.88827718\n",
      "Iteration 1035, loss = 0.88766835\n",
      "Iteration 1036, loss = 0.88705988\n",
      "Iteration 1037, loss = 0.88645169\n",
      "Iteration 1038, loss = 0.88584382\n",
      "Iteration 1039, loss = 0.88523625\n",
      "Iteration 1040, loss = 0.88462896\n",
      "Iteration 1041, loss = 0.88402196\n",
      "Iteration 1042, loss = 0.88341526\n",
      "Iteration 1043, loss = 0.88280883\n",
      "Iteration 1044, loss = 0.88220270\n",
      "Iteration 1045, loss = 0.88159684\n",
      "Iteration 1046, loss = 0.88099128\n",
      "Iteration 1047, loss = 0.88038599\n",
      "Iteration 1048, loss = 0.87978111\n",
      "Iteration 1049, loss = 0.87917665\n",
      "Iteration 1050, loss = 0.87857249\n",
      "Iteration 1051, loss = 0.87796860\n",
      "Iteration 1052, loss = 0.87736500\n",
      "Iteration 1053, loss = 0.87676172\n",
      "Iteration 1054, loss = 0.87615874\n",
      "Iteration 1055, loss = 0.87555595\n",
      "Iteration 1056, loss = 0.87495337\n",
      "Iteration 1057, loss = 0.87435109\n",
      "Iteration 1058, loss = 0.87374912\n",
      "Iteration 1059, loss = 0.87314742\n",
      "Iteration 1060, loss = 0.87254600\n",
      "Iteration 1061, loss = 0.87194466\n",
      "Iteration 1062, loss = 0.87134359\n",
      "Iteration 1063, loss = 0.87074278\n",
      "Iteration 1064, loss = 0.87014224\n",
      "Iteration 1065, loss = 0.86954197\n",
      "Iteration 1066, loss = 0.86894201\n",
      "Iteration 1067, loss = 0.86834230\n",
      "Iteration 1068, loss = 0.86774284\n",
      "Iteration 1069, loss = 0.86714366\n",
      "Iteration 1070, loss = 0.86654475\n",
      "Iteration 1071, loss = 0.86594612\n",
      "Iteration 1072, loss = 0.86534775\n",
      "Iteration 1073, loss = 0.86474966\n",
      "Iteration 1074, loss = 0.86415183\n",
      "Iteration 1075, loss = 0.86355428\n",
      "Iteration 1076, loss = 0.86295699\n",
      "Iteration 1077, loss = 0.86235997\n",
      "Iteration 1078, loss = 0.86176322\n",
      "Iteration 1079, loss = 0.86116675\n",
      "Iteration 1080, loss = 0.86057054\n",
      "Iteration 1081, loss = 0.85997461\n",
      "Iteration 1082, loss = 0.85937917\n",
      "Iteration 1083, loss = 0.85878408\n",
      "Iteration 1084, loss = 0.85818928\n",
      "Iteration 1085, loss = 0.85759476\n",
      "Iteration 1086, loss = 0.85700054\n",
      "Iteration 1087, loss = 0.85640660\n",
      "Iteration 1088, loss = 0.85581295\n",
      "Iteration 1089, loss = 0.85521958\n",
      "Iteration 1090, loss = 0.85462650\n",
      "Iteration 1091, loss = 0.85403370\n",
      "Iteration 1092, loss = 0.85344145\n",
      "Iteration 1093, loss = 0.85284948\n",
      "Iteration 1094, loss = 0.85225793\n",
      "Iteration 1095, loss = 0.85166671\n",
      "Iteration 1096, loss = 0.85107567\n",
      "Iteration 1097, loss = 0.85048470\n",
      "Iteration 1098, loss = 0.84989397\n",
      "Iteration 1099, loss = 0.84930347\n",
      "Iteration 1100, loss = 0.84871322\n",
      "Iteration 1101, loss = 0.84812340\n",
      "Iteration 1102, loss = 0.84753384\n",
      "Iteration 1103, loss = 0.84694449\n",
      "Iteration 1104, loss = 0.84635508\n",
      "Iteration 1105, loss = 0.84576561\n",
      "Iteration 1106, loss = 0.84517632\n",
      "Iteration 1107, loss = 0.84458727\n",
      "Iteration 1108, loss = 0.84399852\n",
      "Iteration 1109, loss = 0.84341022\n",
      "Iteration 1110, loss = 0.84282218\n",
      "Iteration 1111, loss = 0.84223439\n",
      "Iteration 1112, loss = 0.84164685\n",
      "Iteration 1113, loss = 0.84105960\n",
      "Iteration 1114, loss = 0.84047241\n",
      "Iteration 1115, loss = 0.83988541\n",
      "Iteration 1116, loss = 0.83929867\n",
      "Iteration 1117, loss = 0.83871213\n",
      "Iteration 1118, loss = 0.83812586\n",
      "Iteration 1119, loss = 0.83753989\n",
      "Iteration 1120, loss = 0.83695439\n",
      "Iteration 1121, loss = 0.83636915\n",
      "Iteration 1122, loss = 0.83578420\n",
      "Iteration 1123, loss = 0.83519952\n",
      "Iteration 1124, loss = 0.83461511\n",
      "Iteration 1125, loss = 0.83403098\n",
      "Iteration 1126, loss = 0.83344713\n",
      "Iteration 1127, loss = 0.83286355\n",
      "Iteration 1128, loss = 0.83228030\n",
      "Iteration 1129, loss = 0.83169734\n",
      "Iteration 1130, loss = 0.83111463\n",
      "Iteration 1131, loss = 0.83053219\n",
      "Iteration 1132, loss = 0.82995003\n",
      "Iteration 1133, loss = 0.82936813\n",
      "Iteration 1134, loss = 0.82878655\n",
      "Iteration 1135, loss = 0.82820533\n",
      "Iteration 1136, loss = 0.82762435\n",
      "Iteration 1137, loss = 0.82704369\n",
      "Iteration 1138, loss = 0.82646330\n",
      "Iteration 1139, loss = 0.82588318\n",
      "Iteration 1140, loss = 0.82530333\n",
      "Iteration 1141, loss = 0.82472375\n",
      "Iteration 1142, loss = 0.82414445\n",
      "Iteration 1143, loss = 0.82356541\n",
      "Iteration 1144, loss = 0.82298665\n",
      "Iteration 1145, loss = 0.82240818\n",
      "Iteration 1146, loss = 0.82182999\n",
      "Iteration 1147, loss = 0.82125207\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1148, loss = 0.82067442\n",
      "Iteration 1149, loss = 0.82009703\n",
      "Iteration 1150, loss = 0.81951993\n",
      "Iteration 1151, loss = 0.81894311\n",
      "Iteration 1152, loss = 0.81836662\n",
      "Iteration 1153, loss = 0.81779038\n",
      "Iteration 1154, loss = 0.81721447\n",
      "Iteration 1155, loss = 0.81663888\n",
      "Iteration 1156, loss = 0.81606358\n",
      "Iteration 1157, loss = 0.81548833\n",
      "Iteration 1158, loss = 0.81491267\n",
      "Iteration 1159, loss = 0.81433713\n",
      "Iteration 1160, loss = 0.81376188\n",
      "Iteration 1161, loss = 0.81318688\n",
      "Iteration 1162, loss = 0.81261214\n",
      "Iteration 1163, loss = 0.81203760\n",
      "Iteration 1164, loss = 0.81146321\n",
      "Iteration 1165, loss = 0.81088906\n",
      "Iteration 1166, loss = 0.81031516\n",
      "Iteration 1167, loss = 0.80974150\n",
      "Iteration 1168, loss = 0.80916808\n",
      "Iteration 1169, loss = 0.80859491\n",
      "Iteration 1170, loss = 0.80802199\n",
      "Iteration 1171, loss = 0.80744912\n",
      "Iteration 1172, loss = 0.80687624\n",
      "Iteration 1173, loss = 0.80630335\n",
      "Iteration 1174, loss = 0.80573065\n",
      "Iteration 1175, loss = 0.80515817\n",
      "Iteration 1176, loss = 0.80458591\n",
      "Iteration 1177, loss = 0.80401388\n",
      "Iteration 1178, loss = 0.80344207\n",
      "Iteration 1179, loss = 0.80287051\n",
      "Iteration 1180, loss = 0.80229918\n",
      "Iteration 1181, loss = 0.80172804\n",
      "Iteration 1182, loss = 0.80115738\n",
      "Iteration 1183, loss = 0.80058698\n",
      "Iteration 1184, loss = 0.80001685\n",
      "Iteration 1185, loss = 0.79944694\n",
      "Iteration 1186, loss = 0.79887722\n",
      "Iteration 1187, loss = 0.79830779\n",
      "Iteration 1188, loss = 0.79773861\n",
      "Iteration 1189, loss = 0.79716964\n",
      "Iteration 1190, loss = 0.79660089\n",
      "Iteration 1191, loss = 0.79603251\n",
      "Iteration 1192, loss = 0.79546443\n",
      "Iteration 1193, loss = 0.79489630\n",
      "Iteration 1194, loss = 0.79432808\n",
      "Iteration 1195, loss = 0.79376008\n",
      "Iteration 1196, loss = 0.79319220\n",
      "Iteration 1197, loss = 0.79262447\n",
      "Iteration 1198, loss = 0.79205699\n",
      "Iteration 1199, loss = 0.79148895\n",
      "Iteration 1200, loss = 0.79092101\n",
      "Iteration 1201, loss = 0.79035309\n",
      "Iteration 1202, loss = 0.78978528\n",
      "Iteration 1203, loss = 0.78921765\n",
      "Iteration 1204, loss = 0.78865019\n",
      "Iteration 1205, loss = 0.78808288\n",
      "Iteration 1206, loss = 0.78751572\n",
      "Iteration 1207, loss = 0.78694875\n",
      "Iteration 1208, loss = 0.78638195\n",
      "Iteration 1209, loss = 0.78581532\n",
      "Iteration 1210, loss = 0.78524890\n",
      "Iteration 1211, loss = 0.78468273\n",
      "Iteration 1212, loss = 0.78411680\n",
      "Iteration 1213, loss = 0.78355110\n",
      "Iteration 1214, loss = 0.78298561\n",
      "Iteration 1215, loss = 0.78242011\n",
      "Iteration 1216, loss = 0.78185443\n",
      "Iteration 1217, loss = 0.78128900\n",
      "Iteration 1218, loss = 0.78072365\n",
      "Iteration 1219, loss = 0.78015848\n",
      "Iteration 1220, loss = 0.77959352\n",
      "Iteration 1221, loss = 0.77902871\n",
      "Iteration 1222, loss = 0.77846398\n",
      "Iteration 1223, loss = 0.77789943\n",
      "Iteration 1224, loss = 0.77733509\n",
      "Iteration 1225, loss = 0.77677100\n",
      "Iteration 1226, loss = 0.77620714\n",
      "Iteration 1227, loss = 0.77564353\n",
      "Iteration 1228, loss = 0.77508017\n",
      "Iteration 1229, loss = 0.77451706\n",
      "Iteration 1230, loss = 0.77395419\n",
      "Iteration 1231, loss = 0.77339148\n",
      "Iteration 1232, loss = 0.77282900\n",
      "Iteration 1233, loss = 0.77226669\n",
      "Iteration 1234, loss = 0.77170463\n",
      "Iteration 1235, loss = 0.77114283\n",
      "Iteration 1236, loss = 0.77058131\n",
      "Iteration 1237, loss = 0.77002007\n",
      "Iteration 1238, loss = 0.76945910\n",
      "Iteration 1239, loss = 0.76889837\n",
      "Iteration 1240, loss = 0.76833785\n",
      "Iteration 1241, loss = 0.76777756\n",
      "Iteration 1242, loss = 0.76721745\n",
      "Iteration 1243, loss = 0.76665761\n",
      "Iteration 1244, loss = 0.76609804\n",
      "Iteration 1245, loss = 0.76553874\n",
      "Iteration 1246, loss = 0.76497972\n",
      "Iteration 1247, loss = 0.76442097\n",
      "Iteration 1248, loss = 0.76386248\n",
      "Iteration 1249, loss = 0.76330398\n",
      "Iteration 1250, loss = 0.76274571\n",
      "Iteration 1251, loss = 0.76218783\n",
      "Iteration 1252, loss = 0.76163032\n",
      "Iteration 1253, loss = 0.76107308\n",
      "Iteration 1254, loss = 0.76051600\n",
      "Iteration 1255, loss = 0.75995919\n",
      "Iteration 1256, loss = 0.75940266\n",
      "Iteration 1257, loss = 0.75884641\n",
      "Iteration 1258, loss = 0.75829044\n",
      "Iteration 1259, loss = 0.75773484\n",
      "Iteration 1260, loss = 0.75717953\n",
      "Iteration 1261, loss = 0.75662451\n",
      "Iteration 1262, loss = 0.75606978\n",
      "Iteration 1263, loss = 0.75551534\n",
      "Iteration 1264, loss = 0.75496120\n",
      "Iteration 1265, loss = 0.75440735\n",
      "Iteration 1266, loss = 0.75385378\n",
      "Iteration 1267, loss = 0.75330051\n",
      "Iteration 1268, loss = 0.75274753\n",
      "Iteration 1269, loss = 0.75219484\n",
      "Iteration 1270, loss = 0.75164239\n",
      "Iteration 1271, loss = 0.75109022\n",
      "Iteration 1272, loss = 0.75053830\n",
      "Iteration 1273, loss = 0.74998643\n",
      "Iteration 1274, loss = 0.74943463\n",
      "Iteration 1275, loss = 0.74888308\n",
      "Iteration 1276, loss = 0.74833136\n",
      "Iteration 1277, loss = 0.74777952\n",
      "Iteration 1278, loss = 0.74722788\n",
      "Iteration 1279, loss = 0.74667648\n",
      "Iteration 1280, loss = 0.74612529\n",
      "Iteration 1281, loss = 0.74557433\n",
      "Iteration 1282, loss = 0.74502361\n",
      "Iteration 1283, loss = 0.74447238\n",
      "Iteration 1284, loss = 0.74392065\n",
      "Iteration 1285, loss = 0.74336905\n",
      "Iteration 1286, loss = 0.74281758\n",
      "Iteration 1287, loss = 0.74226628\n",
      "Iteration 1288, loss = 0.74171515\n",
      "Iteration 1289, loss = 0.74116440\n",
      "Iteration 1290, loss = 0.74061429\n",
      "Iteration 1291, loss = 0.74006444\n",
      "Iteration 1292, loss = 0.73951485\n",
      "Iteration 1293, loss = 0.73896553\n",
      "Iteration 1294, loss = 0.73841647\n",
      "Iteration 1295, loss = 0.73786757\n",
      "Iteration 1296, loss = 0.73731885\n",
      "Iteration 1297, loss = 0.73677032\n",
      "Iteration 1298, loss = 0.73622209\n",
      "Iteration 1299, loss = 0.73567413\n",
      "Iteration 1300, loss = 0.73512646\n",
      "Iteration 1301, loss = 0.73457905\n",
      "Iteration 1302, loss = 0.73403193\n",
      "Iteration 1303, loss = 0.73348503\n",
      "Iteration 1304, loss = 0.73293831\n",
      "Iteration 1305, loss = 0.73239187\n",
      "Iteration 1306, loss = 0.73184572\n",
      "Iteration 1307, loss = 0.73129981\n",
      "Iteration 1308, loss = 0.73075409\n",
      "Iteration 1309, loss = 0.73020865\n",
      "Iteration 1310, loss = 0.72966348\n",
      "Iteration 1311, loss = 0.72911852\n",
      "Iteration 1312, loss = 0.72857381\n",
      "Iteration 1313, loss = 0.72802939\n",
      "Iteration 1314, loss = 0.72748524\n",
      "Iteration 1315, loss = 0.72694138\n",
      "Iteration 1316, loss = 0.72639780\n",
      "Iteration 1317, loss = 0.72585451\n",
      "Iteration 1318, loss = 0.72531155\n",
      "Iteration 1319, loss = 0.72476892\n",
      "Iteration 1320, loss = 0.72422659\n",
      "Iteration 1321, loss = 0.72368458\n",
      "Iteration 1322, loss = 0.72314287\n",
      "Iteration 1323, loss = 0.72260146\n",
      "Iteration 1324, loss = 0.72206035\n",
      "Iteration 1325, loss = 0.72151954\n",
      "Iteration 1326, loss = 0.72097904\n",
      "Iteration 1327, loss = 0.72043883\n",
      "Iteration 1328, loss = 0.71989893\n",
      "Iteration 1329, loss = 0.71935932\n",
      "Iteration 1330, loss = 0.71882002\n",
      "Iteration 1331, loss = 0.71828103\n",
      "Iteration 1332, loss = 0.71774192\n",
      "Iteration 1333, loss = 0.71720270\n",
      "Iteration 1334, loss = 0.71666372\n",
      "Iteration 1335, loss = 0.71612497\n",
      "Iteration 1336, loss = 0.71558617\n",
      "Iteration 1337, loss = 0.71504737\n",
      "Iteration 1338, loss = 0.71450877\n",
      "Iteration 1339, loss = 0.71397040\n",
      "Iteration 1340, loss = 0.71343226\n",
      "Iteration 1341, loss = 0.71289435\n",
      "Iteration 1342, loss = 0.71235668\n",
      "Iteration 1343, loss = 0.71181927\n",
      "Iteration 1344, loss = 0.71128211\n",
      "Iteration 1345, loss = 0.71074520\n",
      "Iteration 1346, loss = 0.71020882\n",
      "Iteration 1347, loss = 0.70967277\n",
      "Iteration 1348, loss = 0.70913703\n",
      "Iteration 1349, loss = 0.70860158\n",
      "Iteration 1350, loss = 0.70806634\n",
      "Iteration 1351, loss = 0.70753137\n",
      "Iteration 1352, loss = 0.70699668\n",
      "Iteration 1353, loss = 0.70646230\n",
      "Iteration 1354, loss = 0.70592820\n",
      "Iteration 1355, loss = 0.70539439\n",
      "Iteration 1356, loss = 0.70486088\n",
      "Iteration 1357, loss = 0.70432766\n",
      "Iteration 1358, loss = 0.70379474\n",
      "Iteration 1359, loss = 0.70326211\n",
      "Iteration 1360, loss = 0.70272978\n",
      "Iteration 1361, loss = 0.70219775\n",
      "Iteration 1362, loss = 0.70166603\n",
      "Iteration 1363, loss = 0.70113469\n",
      "Iteration 1364, loss = 0.70060364\n",
      "Iteration 1365, loss = 0.70007281\n",
      "Iteration 1366, loss = 0.69954202\n",
      "Iteration 1367, loss = 0.69901158\n",
      "Iteration 1368, loss = 0.69848138\n",
      "Iteration 1369, loss = 0.69795142\n",
      "Iteration 1370, loss = 0.69742178\n",
      "Iteration 1371, loss = 0.69689242\n",
      "Iteration 1372, loss = 0.69636338\n",
      "Iteration 1373, loss = 0.69583463\n",
      "Iteration 1374, loss = 0.69530617\n",
      "Iteration 1375, loss = 0.69477801\n",
      "Iteration 1376, loss = 0.69425014\n",
      "Iteration 1377, loss = 0.69372256\n",
      "Iteration 1378, loss = 0.69319528\n",
      "Iteration 1379, loss = 0.69266830\n",
      "Iteration 1380, loss = 0.69214161\n",
      "Iteration 1381, loss = 0.69161522\n",
      "Iteration 1382, loss = 0.69108912\n",
      "Iteration 1383, loss = 0.69056342\n",
      "Iteration 1384, loss = 0.69003793\n",
      "Iteration 1385, loss = 0.68951273\n",
      "Iteration 1386, loss = 0.68898782\n",
      "Iteration 1387, loss = 0.68846305\n",
      "Iteration 1388, loss = 0.68793817\n",
      "Iteration 1389, loss = 0.68741351\n",
      "Iteration 1390, loss = 0.68688905\n",
      "Iteration 1391, loss = 0.68636484\n",
      "Iteration 1392, loss = 0.68584100\n",
      "Iteration 1393, loss = 0.68531745\n",
      "Iteration 1394, loss = 0.68479418\n",
      "Iteration 1395, loss = 0.68427118\n",
      "Iteration 1396, loss = 0.68374826\n",
      "Iteration 1397, loss = 0.68322561\n",
      "Iteration 1398, loss = 0.68270322\n",
      "Iteration 1399, loss = 0.68218111\n",
      "Iteration 1400, loss = 0.68165929\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1401, loss = 0.68113773\n",
      "Iteration 1402, loss = 0.68061646\n",
      "Iteration 1403, loss = 0.68009547\n",
      "Iteration 1404, loss = 0.67957476\n",
      "Iteration 1405, loss = 0.67905434\n",
      "Iteration 1406, loss = 0.67853421\n",
      "Iteration 1407, loss = 0.67801437\n",
      "Iteration 1408, loss = 0.67749482\n",
      "Iteration 1409, loss = 0.67697556\n",
      "Iteration 1410, loss = 0.67645659\n",
      "Iteration 1411, loss = 0.67593791\n",
      "Iteration 1412, loss = 0.67541952\n",
      "Iteration 1413, loss = 0.67490143\n",
      "Iteration 1414, loss = 0.67438363\n",
      "Iteration 1415, loss = 0.67386613\n",
      "Iteration 1416, loss = 0.67334892\n",
      "Iteration 1417, loss = 0.67283200\n",
      "Iteration 1418, loss = 0.67231538\n",
      "Iteration 1419, loss = 0.67179905\n",
      "Iteration 1420, loss = 0.67128302\n",
      "Iteration 1421, loss = 0.67076728\n",
      "Iteration 1422, loss = 0.67025184\n",
      "Iteration 1423, loss = 0.66973669\n",
      "Iteration 1424, loss = 0.66922184\n",
      "Iteration 1425, loss = 0.66870720\n",
      "Iteration 1426, loss = 0.66819273\n",
      "Iteration 1427, loss = 0.66767849\n",
      "Iteration 1428, loss = 0.66716453\n",
      "Iteration 1429, loss = 0.66665085\n",
      "Iteration 1430, loss = 0.66613745\n",
      "Iteration 1431, loss = 0.66562409\n",
      "Iteration 1432, loss = 0.66511097\n",
      "Iteration 1433, loss = 0.66459810\n",
      "Iteration 1434, loss = 0.66408550\n",
      "Iteration 1435, loss = 0.66357318\n",
      "Iteration 1436, loss = 0.66306105\n",
      "Iteration 1437, loss = 0.66254910\n",
      "Iteration 1438, loss = 0.66203741\n",
      "Iteration 1439, loss = 0.66152591\n",
      "Iteration 1440, loss = 0.66101440\n",
      "Iteration 1441, loss = 0.66050323\n",
      "Iteration 1442, loss = 0.65999233\n",
      "Iteration 1443, loss = 0.65948168\n",
      "Iteration 1444, loss = 0.65897134\n",
      "Iteration 1445, loss = 0.65846134\n",
      "Iteration 1446, loss = 0.65795166\n",
      "Iteration 1447, loss = 0.65744227\n",
      "Iteration 1448, loss = 0.65693317\n",
      "Iteration 1449, loss = 0.65642435\n",
      "Iteration 1450, loss = 0.65591581\n",
      "Iteration 1451, loss = 0.65540757\n",
      "Iteration 1452, loss = 0.65489961\n",
      "Iteration 1453, loss = 0.65439195\n",
      "Iteration 1454, loss = 0.65388457\n",
      "Iteration 1455, loss = 0.65337748\n",
      "Iteration 1456, loss = 0.65287069\n",
      "Iteration 1457, loss = 0.65236419\n",
      "Iteration 1458, loss = 0.65185799\n",
      "Iteration 1459, loss = 0.65135207\n",
      "Iteration 1460, loss = 0.65084639\n",
      "Iteration 1461, loss = 0.65034099\n",
      "Iteration 1462, loss = 0.64983588\n",
      "Iteration 1463, loss = 0.64933110\n",
      "Iteration 1464, loss = 0.64882665\n",
      "Iteration 1465, loss = 0.64832195\n",
      "Iteration 1466, loss = 0.64781748\n",
      "Iteration 1467, loss = 0.64731290\n",
      "Iteration 1468, loss = 0.64680805\n",
      "Iteration 1469, loss = 0.64630309\n",
      "Iteration 1470, loss = 0.64579830\n",
      "Iteration 1471, loss = 0.64529369\n",
      "Iteration 1472, loss = 0.64478920\n",
      "Iteration 1473, loss = 0.64428476\n",
      "Iteration 1474, loss = 0.64378047\n",
      "Iteration 1475, loss = 0.64327638\n",
      "Iteration 1476, loss = 0.64277251\n",
      "Iteration 1477, loss = 0.64226886\n",
      "Iteration 1478, loss = 0.64176544\n",
      "Iteration 1479, loss = 0.64126226\n",
      "Iteration 1480, loss = 0.64075934\n",
      "Iteration 1481, loss = 0.64025667\n",
      "Iteration 1482, loss = 0.63975425\n",
      "Iteration 1483, loss = 0.63925210\n",
      "Iteration 1484, loss = 0.63875022\n",
      "Iteration 1485, loss = 0.63824860\n",
      "Iteration 1486, loss = 0.63774725\n",
      "Iteration 1487, loss = 0.63724618\n",
      "Iteration 1488, loss = 0.63674539\n",
      "Iteration 1489, loss = 0.63624488\n",
      "Iteration 1490, loss = 0.63574466\n",
      "Iteration 1491, loss = 0.63524472\n",
      "Iteration 1492, loss = 0.63474516\n",
      "Iteration 1493, loss = 0.63424591\n",
      "Iteration 1494, loss = 0.63374695\n",
      "Iteration 1495, loss = 0.63324804\n",
      "Iteration 1496, loss = 0.63274907\n",
      "Iteration 1497, loss = 0.63225033\n",
      "Iteration 1498, loss = 0.63175162\n",
      "Iteration 1499, loss = 0.63125315\n",
      "Iteration 1500, loss = 0.63075493\n",
      "Iteration 1501, loss = 0.63025682\n",
      "Iteration 1502, loss = 0.62975870\n",
      "Iteration 1503, loss = 0.62926080\n",
      "Iteration 1504, loss = 0.62876317\n",
      "Iteration 1505, loss = 0.62826573\n",
      "Iteration 1506, loss = 0.62776853\n",
      "Iteration 1507, loss = 0.62727112\n",
      "Iteration 1508, loss = 0.62677361\n",
      "Iteration 1509, loss = 0.62627629\n",
      "Iteration 1510, loss = 0.62577919\n",
      "Iteration 1511, loss = 0.62528231\n",
      "Iteration 1512, loss = 0.62478567\n",
      "Iteration 1513, loss = 0.62428929\n",
      "Iteration 1514, loss = 0.62379315\n",
      "Iteration 1515, loss = 0.62329727\n",
      "Iteration 1516, loss = 0.62280164\n",
      "Iteration 1517, loss = 0.62230628\n",
      "Iteration 1518, loss = 0.62181118\n",
      "Iteration 1519, loss = 0.62131636\n",
      "Iteration 1520, loss = 0.62082181\n",
      "Iteration 1521, loss = 0.62032754\n",
      "Iteration 1522, loss = 0.61983355\n",
      "Iteration 1523, loss = 0.61933984\n",
      "Iteration 1524, loss = 0.61884642\n",
      "Iteration 1525, loss = 0.61835328\n",
      "Iteration 1526, loss = 0.61786044\n",
      "Iteration 1527, loss = 0.61736789\n",
      "Iteration 1528, loss = 0.61687563\n",
      "Iteration 1529, loss = 0.61638367\n",
      "Iteration 1530, loss = 0.61589200\n",
      "Iteration 1531, loss = 0.61540063\n",
      "Iteration 1532, loss = 0.61490958\n",
      "Iteration 1533, loss = 0.61441890\n",
      "Iteration 1534, loss = 0.61392852\n",
      "Iteration 1535, loss = 0.61343845\n",
      "Iteration 1536, loss = 0.61294868\n",
      "Iteration 1537, loss = 0.61245922\n",
      "Iteration 1538, loss = 0.61197006\n",
      "Iteration 1539, loss = 0.61148120\n",
      "Iteration 1540, loss = 0.61099258\n",
      "Iteration 1541, loss = 0.61050400\n",
      "Iteration 1542, loss = 0.61001569\n",
      "Iteration 1543, loss = 0.60952767\n",
      "Iteration 1544, loss = 0.60903992\n",
      "Iteration 1545, loss = 0.60855242\n",
      "Iteration 1546, loss = 0.60806507\n",
      "Iteration 1547, loss = 0.60757790\n",
      "Iteration 1548, loss = 0.60709101\n",
      "Iteration 1549, loss = 0.60660439\n",
      "Iteration 1550, loss = 0.60611804\n",
      "Iteration 1551, loss = 0.60563188\n",
      "Iteration 1552, loss = 0.60514586\n",
      "Iteration 1553, loss = 0.60466010\n",
      "Iteration 1554, loss = 0.60417460\n",
      "Iteration 1555, loss = 0.60368938\n",
      "Iteration 1556, loss = 0.60320444\n",
      "Iteration 1557, loss = 0.60271977\n",
      "Iteration 1558, loss = 0.60223539\n",
      "Iteration 1559, loss = 0.60175129\n",
      "Iteration 1560, loss = 0.60126748\n",
      "Iteration 1561, loss = 0.60078395\n",
      "Iteration 1562, loss = 0.60030053\n",
      "Iteration 1563, loss = 0.59981726\n",
      "Iteration 1564, loss = 0.59933419\n",
      "Iteration 1565, loss = 0.59885133\n",
      "Iteration 1566, loss = 0.59836875\n",
      "Iteration 1567, loss = 0.59788643\n",
      "Iteration 1568, loss = 0.59740438\n",
      "Iteration 1569, loss = 0.59692261\n",
      "Iteration 1570, loss = 0.59644112\n",
      "Iteration 1571, loss = 0.59595925\n",
      "Iteration 1572, loss = 0.59547754\n",
      "Iteration 1573, loss = 0.59499604\n",
      "Iteration 1574, loss = 0.59451478\n",
      "Iteration 1575, loss = 0.59403375\n",
      "Iteration 1576, loss = 0.59355296\n",
      "Iteration 1577, loss = 0.59307244\n",
      "Iteration 1578, loss = 0.59259203\n",
      "Iteration 1579, loss = 0.59211187\n",
      "Iteration 1580, loss = 0.59163197\n",
      "Iteration 1581, loss = 0.59115235\n",
      "Iteration 1582, loss = 0.59067297\n",
      "Iteration 1583, loss = 0.59019380\n",
      "Iteration 1584, loss = 0.58971478\n",
      "Iteration 1585, loss = 0.58923603\n",
      "Iteration 1586, loss = 0.58875755\n",
      "Iteration 1587, loss = 0.58827935\n",
      "Iteration 1588, loss = 0.58780142\n",
      "Iteration 1589, loss = 0.58732377\n",
      "Iteration 1590, loss = 0.58684641\n",
      "Iteration 1591, loss = 0.58636933\n",
      "Iteration 1592, loss = 0.58589254\n",
      "Iteration 1593, loss = 0.58541612\n",
      "Iteration 1594, loss = 0.58494003\n",
      "Iteration 1595, loss = 0.58446424\n",
      "Iteration 1596, loss = 0.58398876\n",
      "Iteration 1597, loss = 0.58351358\n",
      "Iteration 1598, loss = 0.58303871\n",
      "Iteration 1599, loss = 0.58256413\n",
      "Iteration 1600, loss = 0.58208987\n",
      "Iteration 1601, loss = 0.58161583\n",
      "Iteration 1602, loss = 0.58114206\n",
      "Iteration 1603, loss = 0.58066861\n",
      "Iteration 1604, loss = 0.58019564\n",
      "Iteration 1605, loss = 0.57972302\n",
      "Iteration 1606, loss = 0.57925060\n",
      "Iteration 1607, loss = 0.57877828\n",
      "Iteration 1608, loss = 0.57830624\n",
      "Iteration 1609, loss = 0.57783448\n",
      "Iteration 1610, loss = 0.57736298\n",
      "Iteration 1611, loss = 0.57689160\n",
      "Iteration 1612, loss = 0.57642048\n",
      "Iteration 1613, loss = 0.57594965\n",
      "Iteration 1614, loss = 0.57547911\n",
      "Iteration 1615, loss = 0.57500885\n",
      "Iteration 1616, loss = 0.57453888\n",
      "Iteration 1617, loss = 0.57406920\n",
      "Iteration 1618, loss = 0.57359984\n",
      "Iteration 1619, loss = 0.57313080\n",
      "Iteration 1620, loss = 0.57266205\n",
      "Iteration 1621, loss = 0.57219361\n",
      "Iteration 1622, loss = 0.57172547\n",
      "Iteration 1623, loss = 0.57125766\n",
      "Iteration 1624, loss = 0.57079025\n",
      "Iteration 1625, loss = 0.57032319\n",
      "Iteration 1626, loss = 0.56985645\n",
      "Iteration 1627, loss = 0.56939004\n",
      "Iteration 1628, loss = 0.56892396\n",
      "Iteration 1629, loss = 0.56845821\n",
      "Iteration 1630, loss = 0.56799277\n",
      "Iteration 1631, loss = 0.56752766\n",
      "Iteration 1632, loss = 0.56706285\n",
      "Iteration 1633, loss = 0.56659806\n",
      "Iteration 1634, loss = 0.56613333\n",
      "Iteration 1635, loss = 0.56566885\n",
      "Iteration 1636, loss = 0.56520444\n",
      "Iteration 1637, loss = 0.56473970\n",
      "Iteration 1638, loss = 0.56427511\n",
      "Iteration 1639, loss = 0.56381074\n",
      "Iteration 1640, loss = 0.56334660\n",
      "Iteration 1641, loss = 0.56288270\n",
      "Iteration 1642, loss = 0.56241905\n",
      "Iteration 1643, loss = 0.56195564\n",
      "Iteration 1644, loss = 0.56149249\n",
      "Iteration 1645, loss = 0.56102961\n",
      "Iteration 1646, loss = 0.56056699\n",
      "Iteration 1647, loss = 0.56010464\n",
      "Iteration 1648, loss = 0.55964257\n",
      "Iteration 1649, loss = 0.55918062\n",
      "Iteration 1650, loss = 0.55871858\n",
      "Iteration 1651, loss = 0.55825676\n",
      "Iteration 1652, loss = 0.55779515\n",
      "Iteration 1653, loss = 0.55733379\n",
      "Iteration 1654, loss = 0.55687269\n",
      "Iteration 1655, loss = 0.55641186\n",
      "Iteration 1656, loss = 0.55595129\n",
      "Iteration 1657, loss = 0.55549100\n",
      "Iteration 1658, loss = 0.55503099\n",
      "Iteration 1659, loss = 0.55457126\n",
      "Iteration 1660, loss = 0.55411184\n",
      "Iteration 1661, loss = 0.55365280\n",
      "Iteration 1662, loss = 0.55319407\n",
      "Iteration 1663, loss = 0.55273565\n",
      "Iteration 1664, loss = 0.55227751\n",
      "Iteration 1665, loss = 0.55181948\n",
      "Iteration 1666, loss = 0.55136175\n",
      "Iteration 1667, loss = 0.55090431\n",
      "Iteration 1668, loss = 0.55044715\n",
      "Iteration 1669, loss = 0.54999030\n",
      "Iteration 1670, loss = 0.54953375\n",
      "Iteration 1671, loss = 0.54907686\n",
      "Iteration 1672, loss = 0.54861969\n",
      "Iteration 1673, loss = 0.54816273\n",
      "Iteration 1674, loss = 0.54770598\n",
      "Iteration 1675, loss = 0.54724943\n",
      "Iteration 1676, loss = 0.54679305\n",
      "Iteration 1677, loss = 0.54633691\n",
      "Iteration 1678, loss = 0.54588101\n",
      "Iteration 1679, loss = 0.54542537\n",
      "Iteration 1680, loss = 0.54496998\n",
      "Iteration 1681, loss = 0.54451486\n",
      "Iteration 1682, loss = 0.54406001\n",
      "Iteration 1683, loss = 0.54360543\n",
      "Iteration 1684, loss = 0.54315097\n",
      "Iteration 1685, loss = 0.54269678\n",
      "Iteration 1686, loss = 0.54224286\n",
      "Iteration 1687, loss = 0.54178915\n",
      "Iteration 1688, loss = 0.54133544\n",
      "Iteration 1689, loss = 0.54088195\n",
      "Iteration 1690, loss = 0.54042872\n",
      "Iteration 1691, loss = 0.53997575\n",
      "Iteration 1692, loss = 0.53952311\n",
      "Iteration 1693, loss = 0.53907077\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1694, loss = 0.53861872\n",
      "Iteration 1695, loss = 0.53816695\n",
      "Iteration 1696, loss = 0.53771548\n",
      "Iteration 1697, loss = 0.53726430\n",
      "Iteration 1698, loss = 0.53681341\n",
      "Iteration 1699, loss = 0.53636283\n",
      "Iteration 1700, loss = 0.53591255\n",
      "Iteration 1701, loss = 0.53546260\n",
      "Iteration 1702, loss = 0.53501297\n",
      "Iteration 1703, loss = 0.53456365\n",
      "Iteration 1704, loss = 0.53411453\n",
      "Iteration 1705, loss = 0.53366561\n",
      "Iteration 1706, loss = 0.53321698\n",
      "Iteration 1707, loss = 0.53276867\n",
      "Iteration 1708, loss = 0.53232066\n",
      "Iteration 1709, loss = 0.53187296\n",
      "Iteration 1710, loss = 0.53142557\n",
      "Iteration 1711, loss = 0.53097849\n",
      "Iteration 1712, loss = 0.53053172\n",
      "Iteration 1713, loss = 0.53008510\n",
      "Iteration 1714, loss = 0.52963870\n",
      "Iteration 1715, loss = 0.52919259\n",
      "Iteration 1716, loss = 0.52874678\n",
      "Iteration 1717, loss = 0.52830125\n",
      "Iteration 1718, loss = 0.52785585\n",
      "Iteration 1719, loss = 0.52741042\n",
      "Iteration 1720, loss = 0.52696526\n",
      "Iteration 1721, loss = 0.52652036\n",
      "Iteration 1722, loss = 0.52607574\n",
      "Iteration 1723, loss = 0.52563139\n",
      "Iteration 1724, loss = 0.52518733\n",
      "Iteration 1725, loss = 0.52474355\n",
      "Iteration 1726, loss = 0.52430006\n",
      "Iteration 1727, loss = 0.52385687\n",
      "Iteration 1728, loss = 0.52341397\n",
      "Iteration 1729, loss = 0.52297136\n",
      "Iteration 1730, loss = 0.52252906\n",
      "Iteration 1731, loss = 0.52208705\n",
      "Iteration 1732, loss = 0.52164535\n",
      "Iteration 1733, loss = 0.52120396\n",
      "Iteration 1734, loss = 0.52076287\n",
      "Iteration 1735, loss = 0.52032197\n",
      "Iteration 1736, loss = 0.51988115\n",
      "Iteration 1737, loss = 0.51944016\n",
      "Iteration 1738, loss = 0.51899943\n",
      "Iteration 1739, loss = 0.51855876\n",
      "Iteration 1740, loss = 0.51811834\n",
      "Iteration 1741, loss = 0.51767817\n",
      "Iteration 1742, loss = 0.51723825\n",
      "Iteration 1743, loss = 0.51679861\n",
      "Iteration 1744, loss = 0.51635923\n",
      "Iteration 1745, loss = 0.51592030\n",
      "Iteration 1746, loss = 0.51548169\n",
      "Iteration 1747, loss = 0.51504337\n",
      "Iteration 1748, loss = 0.51460535\n",
      "Iteration 1749, loss = 0.51416762\n",
      "Iteration 1750, loss = 0.51373016\n",
      "Iteration 1751, loss = 0.51329300\n",
      "Iteration 1752, loss = 0.51285602\n",
      "Iteration 1753, loss = 0.51241914\n",
      "Iteration 1754, loss = 0.51198254\n",
      "Iteration 1755, loss = 0.51154622\n",
      "Iteration 1756, loss = 0.51111019\n",
      "Iteration 1757, loss = 0.51067445\n",
      "Iteration 1758, loss = 0.51023900\n",
      "Iteration 1759, loss = 0.50980385\n",
      "Iteration 1760, loss = 0.50936899\n",
      "Iteration 1761, loss = 0.50893444\n",
      "Iteration 1762, loss = 0.50850018\n",
      "Iteration 1763, loss = 0.50806623\n",
      "Iteration 1764, loss = 0.50763259\n",
      "Iteration 1765, loss = 0.50719917\n",
      "Iteration 1766, loss = 0.50676605\n",
      "Iteration 1767, loss = 0.50633323\n",
      "Iteration 1768, loss = 0.50590072\n",
      "Iteration 1769, loss = 0.50546856\n",
      "Iteration 1770, loss = 0.50503670\n",
      "Iteration 1771, loss = 0.50460514\n",
      "Iteration 1772, loss = 0.50417390\n",
      "Iteration 1773, loss = 0.50374297\n",
      "Iteration 1774, loss = 0.50331235\n",
      "Iteration 1775, loss = 0.50288204\n",
      "Iteration 1776, loss = 0.50245205\n",
      "Iteration 1777, loss = 0.50202236\n",
      "Iteration 1778, loss = 0.50159299\n",
      "Iteration 1779, loss = 0.50116390\n",
      "Iteration 1780, loss = 0.50073495\n",
      "Iteration 1781, loss = 0.50030630\n",
      "Iteration 1782, loss = 0.49987795\n",
      "Iteration 1783, loss = 0.49944990\n",
      "Iteration 1784, loss = 0.49902215\n",
      "Iteration 1785, loss = 0.49859471\n",
      "Iteration 1786, loss = 0.49816757\n",
      "Iteration 1787, loss = 0.49774073\n",
      "Iteration 1788, loss = 0.49731413\n",
      "Iteration 1789, loss = 0.49688779\n",
      "Iteration 1790, loss = 0.49646176\n",
      "Iteration 1791, loss = 0.49603603\n",
      "Iteration 1792, loss = 0.49561063\n",
      "Iteration 1793, loss = 0.49518552\n",
      "Iteration 1794, loss = 0.49476050\n",
      "Iteration 1795, loss = 0.49433576\n",
      "Iteration 1796, loss = 0.49391132\n",
      "Iteration 1797, loss = 0.49348721\n",
      "Iteration 1798, loss = 0.49306342\n",
      "Iteration 1799, loss = 0.49263992\n",
      "Iteration 1800, loss = 0.49221673\n",
      "Iteration 1801, loss = 0.49179384\n",
      "Iteration 1802, loss = 0.49137125\n",
      "Iteration 1803, loss = 0.49094897\n",
      "Iteration 1804, loss = 0.49052699\n",
      "Iteration 1805, loss = 0.49010532\n",
      "Iteration 1806, loss = 0.48968395\n",
      "Iteration 1807, loss = 0.48926288\n",
      "Iteration 1808, loss = 0.48884212\n",
      "Iteration 1809, loss = 0.48842167\n",
      "Iteration 1810, loss = 0.48800153\n",
      "Iteration 1811, loss = 0.48758169\n",
      "Iteration 1812, loss = 0.48716217\n",
      "Iteration 1813, loss = 0.48674294\n",
      "Iteration 1814, loss = 0.48632403\n",
      "Iteration 1815, loss = 0.48590543\n",
      "Iteration 1816, loss = 0.48548713\n",
      "Iteration 1817, loss = 0.48506883\n",
      "Iteration 1818, loss = 0.48465078\n",
      "Iteration 1819, loss = 0.48423300\n",
      "Iteration 1820, loss = 0.48381551\n",
      "Iteration 1821, loss = 0.48339831\n",
      "Iteration 1822, loss = 0.48298139\n",
      "Iteration 1823, loss = 0.48256476\n",
      "Iteration 1824, loss = 0.48214842\n",
      "Iteration 1825, loss = 0.48173237\n",
      "Iteration 1826, loss = 0.48131662\n",
      "Iteration 1827, loss = 0.48090116\n",
      "Iteration 1828, loss = 0.48048600\n",
      "Iteration 1829, loss = 0.48007114\n",
      "Iteration 1830, loss = 0.47965658\n",
      "Iteration 1831, loss = 0.47924232\n",
      "Iteration 1832, loss = 0.47882836\n",
      "Iteration 1833, loss = 0.47841458\n",
      "Iteration 1834, loss = 0.47800101\n",
      "Iteration 1835, loss = 0.47758772\n",
      "Iteration 1836, loss = 0.47717473\n",
      "Iteration 1837, loss = 0.47676202\n",
      "Iteration 1838, loss = 0.47634961\n",
      "Iteration 1839, loss = 0.47593749\n",
      "Iteration 1840, loss = 0.47552567\n",
      "Iteration 1841, loss = 0.47511414\n",
      "Iteration 1842, loss = 0.47470291\n",
      "Iteration 1843, loss = 0.47429182\n",
      "Iteration 1844, loss = 0.47388092\n",
      "Iteration 1845, loss = 0.47347030\n",
      "Iteration 1846, loss = 0.47305978\n",
      "Iteration 1847, loss = 0.47264921\n",
      "Iteration 1848, loss = 0.47223890\n",
      "Iteration 1849, loss = 0.47182883\n",
      "Iteration 1850, loss = 0.47141903\n",
      "Iteration 1851, loss = 0.47100948\n",
      "Iteration 1852, loss = 0.47060022\n",
      "Iteration 1853, loss = 0.47019124\n",
      "Iteration 1854, loss = 0.46978254\n",
      "Iteration 1855, loss = 0.46937412\n",
      "Iteration 1856, loss = 0.46896592\n",
      "Iteration 1857, loss = 0.46855752\n",
      "Iteration 1858, loss = 0.46814921\n",
      "Iteration 1859, loss = 0.46774101\n",
      "Iteration 1860, loss = 0.46733304\n",
      "Iteration 1861, loss = 0.46692532\n",
      "Iteration 1862, loss = 0.46651784\n",
      "Iteration 1863, loss = 0.46611061\n",
      "Iteration 1864, loss = 0.46570365\n",
      "Iteration 1865, loss = 0.46529695\n",
      "Iteration 1866, loss = 0.46489053\n",
      "Iteration 1867, loss = 0.46448438\n",
      "Iteration 1868, loss = 0.46407851\n",
      "Iteration 1869, loss = 0.46367288\n",
      "Iteration 1870, loss = 0.46326747\n",
      "Iteration 1871, loss = 0.46286234\n",
      "Iteration 1872, loss = 0.46245741\n",
      "Iteration 1873, loss = 0.46205268\n",
      "Iteration 1874, loss = 0.46164821\n",
      "Iteration 1875, loss = 0.46124403\n",
      "Iteration 1876, loss = 0.46084012\n",
      "Iteration 1877, loss = 0.46043650\n",
      "Iteration 1878, loss = 0.46003316\n",
      "Iteration 1879, loss = 0.45963012\n",
      "Iteration 1880, loss = 0.45922736\n",
      "Iteration 1881, loss = 0.45882489\n",
      "Iteration 1882, loss = 0.45842272\n",
      "Iteration 1883, loss = 0.45802085\n",
      "Iteration 1884, loss = 0.45761927\n",
      "Iteration 1885, loss = 0.45721800\n",
      "Iteration 1886, loss = 0.45681702\n",
      "Iteration 1887, loss = 0.45641634\n",
      "Iteration 1888, loss = 0.45601596\n",
      "Iteration 1889, loss = 0.45561589\n",
      "Iteration 1890, loss = 0.45521612\n",
      "Iteration 1891, loss = 0.45481665\n",
      "Iteration 1892, loss = 0.45441749\n",
      "Iteration 1893, loss = 0.45401863\n",
      "Iteration 1894, loss = 0.45362007\n",
      "Iteration 1895, loss = 0.45322182\n",
      "Iteration 1896, loss = 0.45282388\n",
      "Iteration 1897, loss = 0.45242624\n",
      "Iteration 1898, loss = 0.45202890\n",
      "Iteration 1899, loss = 0.45163187\n",
      "Iteration 1900, loss = 0.45123514\n",
      "Iteration 1901, loss = 0.45083873\n",
      "Iteration 1902, loss = 0.45044261\n",
      "Iteration 1903, loss = 0.45004675\n",
      "Iteration 1904, loss = 0.44965096\n",
      "Iteration 1905, loss = 0.44925545\n",
      "Iteration 1906, loss = 0.44886022\n",
      "Iteration 1907, loss = 0.44846501\n",
      "Iteration 1908, loss = 0.44806973\n",
      "Iteration 1909, loss = 0.44767468\n",
      "Iteration 1910, loss = 0.44727989\n",
      "Iteration 1911, loss = 0.44688534\n",
      "Iteration 1912, loss = 0.44649105\n",
      "Iteration 1913, loss = 0.44609703\n",
      "Iteration 1914, loss = 0.44570328\n",
      "Iteration 1915, loss = 0.44530980\n",
      "Iteration 1916, loss = 0.44491659\n",
      "Iteration 1917, loss = 0.44452367\n",
      "Iteration 1918, loss = 0.44413103\n",
      "Iteration 1919, loss = 0.44373867\n",
      "Iteration 1920, loss = 0.44334660\n",
      "Iteration 1921, loss = 0.44295483\n",
      "Iteration 1922, loss = 0.44256334\n",
      "Iteration 1923, loss = 0.44217215\n",
      "Iteration 1924, loss = 0.44178126\n",
      "Iteration 1925, loss = 0.44139067\n",
      "Iteration 1926, loss = 0.44100038\n",
      "Iteration 1927, loss = 0.44061038\n",
      "Iteration 1928, loss = 0.44022068\n",
      "Iteration 1929, loss = 0.43983129\n",
      "Iteration 1930, loss = 0.43944215\n",
      "Iteration 1931, loss = 0.43905332\n",
      "Iteration 1932, loss = 0.43866468\n",
      "Iteration 1933, loss = 0.43827633\n",
      "Iteration 1934, loss = 0.43788826\n",
      "Iteration 1935, loss = 0.43750049\n",
      "Iteration 1936, loss = 0.43711298\n",
      "Iteration 1937, loss = 0.43672522\n",
      "Iteration 1938, loss = 0.43633770\n",
      "Iteration 1939, loss = 0.43595044\n",
      "Iteration 1940, loss = 0.43556343\n",
      "Iteration 1941, loss = 0.43517670\n",
      "Iteration 1942, loss = 0.43479023\n",
      "Iteration 1943, loss = 0.43440404\n",
      "Iteration 1944, loss = 0.43401812\n",
      "Iteration 1945, loss = 0.43363248\n",
      "Iteration 1946, loss = 0.43324701\n",
      "Iteration 1947, loss = 0.43286182\n",
      "Iteration 1948, loss = 0.43247690\n",
      "Iteration 1949, loss = 0.43209227\n",
      "Iteration 1950, loss = 0.43170793\n",
      "Iteration 1951, loss = 0.43132373\n",
      "Iteration 1952, loss = 0.43093959\n",
      "Iteration 1953, loss = 0.43055547\n",
      "Iteration 1954, loss = 0.43017158\n",
      "Iteration 1955, loss = 0.42978798\n",
      "Iteration 1956, loss = 0.42940467\n",
      "Iteration 1957, loss = 0.42902160\n",
      "Iteration 1958, loss = 0.42863870\n",
      "Iteration 1959, loss = 0.42825611\n",
      "Iteration 1960, loss = 0.42787388\n",
      "Iteration 1961, loss = 0.42749194\n",
      "Iteration 1962, loss = 0.42711027\n",
      "Iteration 1963, loss = 0.42672888\n",
      "Iteration 1964, loss = 0.42634778\n",
      "Iteration 1965, loss = 0.42596696\n",
      "Iteration 1966, loss = 0.42558644\n",
      "Iteration 1967, loss = 0.42520620\n",
      "Iteration 1968, loss = 0.42482626\n",
      "Iteration 1969, loss = 0.42444662\n",
      "Iteration 1970, loss = 0.42406729\n",
      "Iteration 1971, loss = 0.42368827\n",
      "Iteration 1972, loss = 0.42330955\n",
      "Iteration 1973, loss = 0.42293113\n",
      "Iteration 1974, loss = 0.42255302\n",
      "Iteration 1975, loss = 0.42217494\n",
      "Iteration 1976, loss = 0.42179711\n",
      "Iteration 1977, loss = 0.42141956\n",
      "Iteration 1978, loss = 0.42104230\n",
      "Iteration 1979, loss = 0.42066532\n",
      "Iteration 1980, loss = 0.42028851\n",
      "Iteration 1981, loss = 0.41991189\n",
      "Iteration 1982, loss = 0.41953539\n",
      "Iteration 1983, loss = 0.41915915\n",
      "Iteration 1984, loss = 0.41878317\n",
      "Iteration 1985, loss = 0.41840748\n",
      "Iteration 1986, loss = 0.41803191\n",
      "Iteration 1987, loss = 0.41765597\n",
      "Iteration 1988, loss = 0.41728019\n",
      "Iteration 1989, loss = 0.41690464\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1990, loss = 0.41652933\n",
      "Iteration 1991, loss = 0.41615429\n",
      "Iteration 1992, loss = 0.41577950\n",
      "Iteration 1993, loss = 0.41540496\n",
      "Iteration 1994, loss = 0.41503068\n",
      "Iteration 1995, loss = 0.41465667\n",
      "Iteration 1996, loss = 0.41428294\n",
      "Iteration 1997, loss = 0.41390948\n",
      "Iteration 1998, loss = 0.41353630\n",
      "Iteration 1999, loss = 0.41316340\n",
      "Iteration 2000, loss = 0.41279079\n",
      "Iteration 2001, loss = 0.41241846\n",
      "Iteration 2002, loss = 0.41204643\n",
      "Iteration 2003, loss = 0.41167469\n",
      "Iteration 2004, loss = 0.41130324\n",
      "Iteration 2005, loss = 0.41093210\n",
      "Iteration 2006, loss = 0.41056125\n",
      "Iteration 2007, loss = 0.41019072\n",
      "Iteration 2008, loss = 0.40982050\n",
      "Iteration 2009, loss = 0.40945059\n",
      "Iteration 2010, loss = 0.40908086\n",
      "Iteration 2011, loss = 0.40871130\n",
      "Iteration 2012, loss = 0.40834202\n",
      "Iteration 2013, loss = 0.40797303\n",
      "Iteration 2014, loss = 0.40760434\n",
      "Iteration 2015, loss = 0.40723595\n",
      "Iteration 2016, loss = 0.40686785\n",
      "Iteration 2017, loss = 0.40649994\n",
      "Iteration 2018, loss = 0.40613220\n",
      "Iteration 2019, loss = 0.40576475\n",
      "Iteration 2020, loss = 0.40539758\n",
      "Iteration 2021, loss = 0.40503070\n",
      "Iteration 2022, loss = 0.40466403\n",
      "Iteration 2023, loss = 0.40429762\n",
      "Iteration 2024, loss = 0.40393150\n",
      "Iteration 2025, loss = 0.40356566\n",
      "Iteration 2026, loss = 0.40320011\n",
      "Iteration 2027, loss = 0.40283486\n",
      "Iteration 2028, loss = 0.40246989\n",
      "Iteration 2029, loss = 0.40210522\n",
      "Iteration 2030, loss = 0.40174082\n",
      "Iteration 2031, loss = 0.40137654\n",
      "Iteration 2032, loss = 0.40101255\n",
      "Iteration 2033, loss = 0.40064884\n",
      "Iteration 2034, loss = 0.40028543\n",
      "Iteration 2035, loss = 0.39992230\n",
      "Iteration 2036, loss = 0.39955947\n",
      "Iteration 2037, loss = 0.39919662\n",
      "Iteration 2038, loss = 0.39883399\n",
      "Iteration 2039, loss = 0.39847164\n",
      "Iteration 2040, loss = 0.39810941\n",
      "Iteration 2041, loss = 0.39774723\n",
      "Iteration 2042, loss = 0.39738530\n",
      "Iteration 2043, loss = 0.39702361\n",
      "Iteration 2044, loss = 0.39666217\n",
      "Iteration 2045, loss = 0.39630099\n",
      "Iteration 2046, loss = 0.39594007\n",
      "Iteration 2047, loss = 0.39557944\n",
      "Iteration 2048, loss = 0.39521908\n",
      "Iteration 2049, loss = 0.39485900\n",
      "Iteration 2050, loss = 0.39449921\n",
      "Iteration 2051, loss = 0.39413970\n",
      "Iteration 2052, loss = 0.39378049\n",
      "Iteration 2053, loss = 0.39342157\n",
      "Iteration 2054, loss = 0.39306294\n",
      "Iteration 2055, loss = 0.39270461\n",
      "Iteration 2056, loss = 0.39234658\n",
      "Iteration 2057, loss = 0.39198884\n",
      "Iteration 2058, loss = 0.39163141\n",
      "Iteration 2059, loss = 0.39127428\n",
      "Iteration 2060, loss = 0.39091745\n",
      "Iteration 2061, loss = 0.39056092\n",
      "Iteration 2062, loss = 0.39020470\n",
      "Iteration 2063, loss = 0.38984846\n",
      "Iteration 2064, loss = 0.38949231\n",
      "Iteration 2065, loss = 0.38913635\n",
      "Iteration 2066, loss = 0.38878065\n",
      "Iteration 2067, loss = 0.38842506\n",
      "Iteration 2068, loss = 0.38806969\n",
      "Iteration 2069, loss = 0.38771457\n",
      "Iteration 2070, loss = 0.38735971\n",
      "Iteration 2071, loss = 0.38700512\n",
      "Iteration 2072, loss = 0.38665081\n",
      "Iteration 2073, loss = 0.38629678\n",
      "Iteration 2074, loss = 0.38594302\n",
      "Iteration 2075, loss = 0.38558955\n",
      "Iteration 2076, loss = 0.38523637\n",
      "Iteration 2077, loss = 0.38488349\n",
      "Iteration 2078, loss = 0.38453089\n",
      "Iteration 2079, loss = 0.38417859\n",
      "Iteration 2080, loss = 0.38382656\n",
      "Iteration 2081, loss = 0.38347481\n",
      "Iteration 2082, loss = 0.38312336\n",
      "Iteration 2083, loss = 0.38277221\n",
      "Iteration 2084, loss = 0.38242135\n",
      "Iteration 2085, loss = 0.38207080\n",
      "Iteration 2086, loss = 0.38172055\n",
      "Iteration 2087, loss = 0.38137061\n",
      "Iteration 2088, loss = 0.38102096\n",
      "Iteration 2089, loss = 0.38067163\n",
      "Iteration 2090, loss = 0.38032259\n",
      "Iteration 2091, loss = 0.37997387\n",
      "Iteration 2092, loss = 0.37962545\n",
      "Iteration 2093, loss = 0.37927734\n",
      "Iteration 2094, loss = 0.37892953\n",
      "Iteration 2095, loss = 0.37858204\n",
      "Iteration 2096, loss = 0.37823458\n",
      "Iteration 2097, loss = 0.37788730\n",
      "Iteration 2098, loss = 0.37754030\n",
      "Iteration 2099, loss = 0.37719357\n",
      "Iteration 2100, loss = 0.37684714\n",
      "Iteration 2101, loss = 0.37650099\n",
      "Iteration 2102, loss = 0.37615512\n",
      "Iteration 2103, loss = 0.37580955\n",
      "Iteration 2104, loss = 0.37546421\n",
      "Iteration 2105, loss = 0.37511851\n",
      "Iteration 2106, loss = 0.37477304\n",
      "Iteration 2107, loss = 0.37442782\n",
      "Iteration 2108, loss = 0.37408285\n",
      "Iteration 2109, loss = 0.37373813\n",
      "Iteration 2110, loss = 0.37339369\n",
      "Iteration 2111, loss = 0.37304951\n",
      "Iteration 2112, loss = 0.37270561\n",
      "Iteration 2113, loss = 0.37236198\n",
      "Iteration 2114, loss = 0.37201864\n",
      "Iteration 2115, loss = 0.37167559\n",
      "Iteration 2116, loss = 0.37133282\n",
      "Iteration 2117, loss = 0.37099037\n",
      "Iteration 2118, loss = 0.37064822\n",
      "Iteration 2119, loss = 0.37030636\n",
      "Iteration 2120, loss = 0.36996480\n",
      "Iteration 2121, loss = 0.36962354\n",
      "Iteration 2122, loss = 0.36928253\n",
      "Iteration 2123, loss = 0.36894170\n",
      "Iteration 2124, loss = 0.36860116\n",
      "Iteration 2125, loss = 0.36826092\n",
      "Iteration 2126, loss = 0.36792097\n",
      "Iteration 2127, loss = 0.36758132\n",
      "Iteration 2128, loss = 0.36724197\n",
      "Iteration 2129, loss = 0.36690292\n",
      "Iteration 2130, loss = 0.36656417\n",
      "Iteration 2131, loss = 0.36622572\n",
      "Iteration 2132, loss = 0.36588757\n",
      "Iteration 2133, loss = 0.36554972\n",
      "Iteration 2134, loss = 0.36521219\n",
      "Iteration 2135, loss = 0.36487495\n",
      "Iteration 2136, loss = 0.36453790\n",
      "Iteration 2137, loss = 0.36420074\n",
      "Iteration 2138, loss = 0.36386385\n",
      "Iteration 2139, loss = 0.36352722\n",
      "Iteration 2140, loss = 0.36319087\n",
      "Iteration 2141, loss = 0.36285480\n",
      "Iteration 2142, loss = 0.36251900\n",
      "Iteration 2143, loss = 0.36218349\n",
      "Iteration 2144, loss = 0.36184827\n",
      "Iteration 2145, loss = 0.36151333\n",
      "Iteration 2146, loss = 0.36117869\n",
      "Iteration 2147, loss = 0.36084434\n",
      "Iteration 2148, loss = 0.36051029\n",
      "Iteration 2149, loss = 0.36017653\n",
      "Iteration 2150, loss = 0.35984307\n",
      "Iteration 2151, loss = 0.35950980\n",
      "Iteration 2152, loss = 0.35917665\n",
      "Iteration 2153, loss = 0.35884377\n",
      "Iteration 2154, loss = 0.35851118\n",
      "Iteration 2155, loss = 0.35817887\n",
      "Iteration 2156, loss = 0.35784685\n",
      "Iteration 2157, loss = 0.35751512\n",
      "Iteration 2158, loss = 0.35718368\n",
      "Iteration 2159, loss = 0.35685254\n",
      "Iteration 2160, loss = 0.35652169\n",
      "Iteration 2161, loss = 0.35619114\n",
      "Iteration 2162, loss = 0.35586089\n",
      "Iteration 2163, loss = 0.35553093\n",
      "Iteration 2164, loss = 0.35520128\n",
      "Iteration 2165, loss = 0.35487193\n",
      "Iteration 2166, loss = 0.35454288\n",
      "Iteration 2167, loss = 0.35421413\n",
      "Iteration 2168, loss = 0.35388568\n",
      "Iteration 2169, loss = 0.35355754\n",
      "Iteration 2170, loss = 0.35322970\n",
      "Iteration 2171, loss = 0.35290197\n",
      "Iteration 2172, loss = 0.35257439\n",
      "Iteration 2173, loss = 0.35224709\n",
      "Iteration 2174, loss = 0.35192007\n",
      "Iteration 2175, loss = 0.35159333\n",
      "Iteration 2176, loss = 0.35126688\n",
      "Iteration 2177, loss = 0.35094072\n",
      "Iteration 2178, loss = 0.35061485\n",
      "Iteration 2179, loss = 0.35028927\n",
      "Iteration 2180, loss = 0.34996399\n",
      "Iteration 2181, loss = 0.34963900\n",
      "Iteration 2182, loss = 0.34931431\n",
      "Iteration 2183, loss = 0.34898992\n",
      "Iteration 2184, loss = 0.34866582\n",
      "Iteration 2185, loss = 0.34834202\n",
      "Iteration 2186, loss = 0.34801852\n",
      "Iteration 2187, loss = 0.34769533\n",
      "Iteration 2188, loss = 0.34737243\n",
      "Iteration 2189, loss = 0.34704983\n",
      "Iteration 2190, loss = 0.34672754\n",
      "Iteration 2191, loss = 0.34640554\n",
      "Iteration 2192, loss = 0.34608385\n",
      "Iteration 2193, loss = 0.34576246\n",
      "Iteration 2194, loss = 0.34544138\n",
      "Iteration 2195, loss = 0.34512059\n",
      "Iteration 2196, loss = 0.34480011\n",
      "Iteration 2197, loss = 0.34447993\n",
      "Iteration 2198, loss = 0.34416006\n",
      "Iteration 2199, loss = 0.34384048\n",
      "Iteration 2200, loss = 0.34352121\n",
      "Iteration 2201, loss = 0.34320224\n",
      "Iteration 2202, loss = 0.34288357\n",
      "Iteration 2203, loss = 0.34256520\n",
      "Iteration 2204, loss = 0.34224714\n",
      "Iteration 2205, loss = 0.34192937\n",
      "Iteration 2206, loss = 0.34161120\n",
      "Iteration 2207, loss = 0.34129320\n",
      "Iteration 2208, loss = 0.34097542\n",
      "Iteration 2209, loss = 0.34065788\n",
      "Iteration 2210, loss = 0.34034059\n",
      "Iteration 2211, loss = 0.34002355\n",
      "Iteration 2212, loss = 0.33970677\n",
      "Iteration 2213, loss = 0.33939025\n",
      "Iteration 2214, loss = 0.33907400\n",
      "Iteration 2215, loss = 0.33875801\n",
      "Iteration 2216, loss = 0.33844230\n",
      "Iteration 2217, loss = 0.33812687\n",
      "Iteration 2218, loss = 0.33781172\n",
      "Iteration 2219, loss = 0.33749686\n",
      "Iteration 2220, loss = 0.33718228\n",
      "Iteration 2221, loss = 0.33686800\n",
      "Iteration 2222, loss = 0.33655400\n",
      "Iteration 2223, loss = 0.33624030\n",
      "Iteration 2224, loss = 0.33592688\n",
      "Iteration 2225, loss = 0.33561376\n",
      "Iteration 2226, loss = 0.33530093\n",
      "Iteration 2227, loss = 0.33498840\n",
      "Iteration 2228, loss = 0.33467620\n",
      "Iteration 2229, loss = 0.33436431\n",
      "Iteration 2230, loss = 0.33405271\n",
      "Iteration 2231, loss = 0.33374141\n",
      "Iteration 2232, loss = 0.33343040\n",
      "Iteration 2233, loss = 0.33311969\n",
      "Iteration 2234, loss = 0.33280928\n",
      "Iteration 2235, loss = 0.33249917\n",
      "Iteration 2236, loss = 0.33218932\n",
      "Iteration 2237, loss = 0.33187972\n",
      "Iteration 2238, loss = 0.33157042\n",
      "Iteration 2239, loss = 0.33126141\n",
      "Iteration 2240, loss = 0.33095269\n",
      "Iteration 2241, loss = 0.33064426\n",
      "Iteration 2242, loss = 0.33033613\n",
      "Iteration 2243, loss = 0.33002830\n",
      "Iteration 2244, loss = 0.32972075\n",
      "Iteration 2245, loss = 0.32941328\n",
      "Iteration 2246, loss = 0.32910609\n",
      "Iteration 2247, loss = 0.32879919\n",
      "Iteration 2248, loss = 0.32849256\n",
      "Iteration 2249, loss = 0.32818622\n",
      "Iteration 2250, loss = 0.32788018\n",
      "Iteration 2251, loss = 0.32757442\n",
      "Iteration 2252, loss = 0.32726894\n",
      "Iteration 2253, loss = 0.32696374\n",
      "Iteration 2254, loss = 0.32665884\n",
      "Iteration 2255, loss = 0.32635424\n",
      "Iteration 2256, loss = 0.32604992\n",
      "Iteration 2257, loss = 0.32574590\n",
      "Iteration 2258, loss = 0.32544217\n",
      "Iteration 2259, loss = 0.32513873\n",
      "Iteration 2260, loss = 0.32483559\n",
      "Iteration 2261, loss = 0.32453274\n",
      "Iteration 2262, loss = 0.32423018\n",
      "Iteration 2263, loss = 0.32392792\n",
      "Iteration 2264, loss = 0.32362595\n",
      "Iteration 2265, loss = 0.32332428\n",
      "Iteration 2266, loss = 0.32302290\n",
      "Iteration 2267, loss = 0.32272182\n",
      "Iteration 2268, loss = 0.32242103\n",
      "Iteration 2269, loss = 0.32212054\n",
      "Iteration 2270, loss = 0.32182034\n",
      "Iteration 2271, loss = 0.32152043\n",
      "Iteration 2272, loss = 0.32122084\n",
      "Iteration 2273, loss = 0.32092156\n",
      "Iteration 2274, loss = 0.32062258\n",
      "Iteration 2275, loss = 0.32032379\n",
      "Iteration 2276, loss = 0.32002511\n",
      "Iteration 2277, loss = 0.31972670\n",
      "Iteration 2278, loss = 0.31942857\n",
      "Iteration 2279, loss = 0.31913072\n",
      "Iteration 2280, loss = 0.31883314\n",
      "Iteration 2281, loss = 0.31853585\n",
      "Iteration 2282, loss = 0.31823884\n",
      "Iteration 2283, loss = 0.31794212\n",
      "Iteration 2284, loss = 0.31764567\n",
      "Iteration 2285, loss = 0.31734952\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 2286, loss = 0.31705365\n",
      "Iteration 2287, loss = 0.31675806\n",
      "Iteration 2288, loss = 0.31646277\n",
      "Iteration 2289, loss = 0.31616776\n",
      "Iteration 2290, loss = 0.31587304\n",
      "Iteration 2291, loss = 0.31557861\n",
      "Iteration 2292, loss = 0.31528447\n",
      "Iteration 2293, loss = 0.31499062\n",
      "Iteration 2294, loss = 0.31469706\n",
      "Iteration 2295, loss = 0.31440379\n",
      "Iteration 2296, loss = 0.31411081\n",
      "Iteration 2297, loss = 0.31381812\n",
      "Iteration 2298, loss = 0.31352572\n",
      "Iteration 2299, loss = 0.31323361\n",
      "Iteration 2300, loss = 0.31294179\n",
      "Iteration 2301, loss = 0.31265027\n",
      "Iteration 2302, loss = 0.31235903\n",
      "Iteration 2303, loss = 0.31206808\n",
      "Iteration 2304, loss = 0.31177743\n",
      "Iteration 2305, loss = 0.31148697\n",
      "Iteration 2306, loss = 0.31119671\n",
      "Iteration 2307, loss = 0.31090672\n",
      "Iteration 2308, loss = 0.31061701\n",
      "Iteration 2309, loss = 0.31032758\n",
      "Iteration 2310, loss = 0.31003842\n",
      "Iteration 2311, loss = 0.30974955\n",
      "Iteration 2312, loss = 0.30946095\n",
      "Iteration 2313, loss = 0.30917264\n",
      "Iteration 2314, loss = 0.30888461\n",
      "Iteration 2315, loss = 0.30859690\n",
      "Iteration 2316, loss = 0.30830948\n",
      "Iteration 2317, loss = 0.30802230\n",
      "Iteration 2318, loss = 0.30773522\n",
      "Iteration 2319, loss = 0.30744842\n",
      "Iteration 2320, loss = 0.30716189\n",
      "Iteration 2321, loss = 0.30687564\n",
      "Iteration 2322, loss = 0.30658965\n",
      "Iteration 2323, loss = 0.30630395\n",
      "Iteration 2324, loss = 0.30601852\n",
      "Iteration 2325, loss = 0.30573337\n",
      "Iteration 2326, loss = 0.30544852\n",
      "Iteration 2327, loss = 0.30516396\n",
      "Iteration 2328, loss = 0.30487968\n",
      "Iteration 2329, loss = 0.30459567\n",
      "Iteration 2330, loss = 0.30431195\n",
      "Iteration 2331, loss = 0.30402852\n",
      "Iteration 2332, loss = 0.30374536\n",
      "Iteration 2333, loss = 0.30346249\n",
      "Iteration 2334, loss = 0.30317991\n",
      "Iteration 2335, loss = 0.30289761\n",
      "Iteration 2336, loss = 0.30261560\n",
      "Iteration 2337, loss = 0.30233387\n",
      "Iteration 2338, loss = 0.30205240\n",
      "Iteration 2339, loss = 0.30177118\n",
      "Iteration 2340, loss = 0.30149013\n",
      "Iteration 2341, loss = 0.30120929\n",
      "Iteration 2342, loss = 0.30092871\n",
      "Iteration 2343, loss = 0.30064841\n",
      "Iteration 2344, loss = 0.30036838\n",
      "Iteration 2345, loss = 0.30008862\n",
      "Iteration 2346, loss = 0.29980914\n",
      "Iteration 2347, loss = 0.29952993\n",
      "Iteration 2348, loss = 0.29925099\n",
      "Iteration 2349, loss = 0.29897234\n",
      "Iteration 2350, loss = 0.29869396\n",
      "Iteration 2351, loss = 0.29841586\n",
      "Iteration 2352, loss = 0.29813805\n",
      "Iteration 2353, loss = 0.29786051\n",
      "Iteration 2354, loss = 0.29758325\n",
      "Iteration 2355, loss = 0.29730628\n",
      "Iteration 2356, loss = 0.29702958\n",
      "Iteration 2357, loss = 0.29675317\n",
      "Iteration 2358, loss = 0.29647704\n",
      "Iteration 2359, loss = 0.29620120\n",
      "Iteration 2360, loss = 0.29592563\n",
      "Iteration 2361, loss = 0.29565035\n",
      "Iteration 2362, loss = 0.29537535\n",
      "Iteration 2363, loss = 0.29510063\n",
      "Iteration 2364, loss = 0.29482620\n",
      "Iteration 2365, loss = 0.29455205\n",
      "Iteration 2366, loss = 0.29427818\n",
      "Iteration 2367, loss = 0.29400459\n",
      "Iteration 2368, loss = 0.29373129\n",
      "Iteration 2369, loss = 0.29345827\n",
      "Iteration 2370, loss = 0.29318553\n",
      "Iteration 2371, loss = 0.29291308\n",
      "Iteration 2372, loss = 0.29264091\n",
      "Iteration 2373, loss = 0.29236902\n",
      "Iteration 2374, loss = 0.29209741\n",
      "Iteration 2375, loss = 0.29182609\n",
      "Iteration 2376, loss = 0.29155505\n",
      "Iteration 2377, loss = 0.29128429\n",
      "Iteration 2378, loss = 0.29101381\n",
      "Iteration 2379, loss = 0.29074361\n",
      "Iteration 2380, loss = 0.29047369\n",
      "Iteration 2381, loss = 0.29020406\n",
      "Iteration 2382, loss = 0.28993464\n",
      "Iteration 2383, loss = 0.28966544\n",
      "Iteration 2384, loss = 0.28939651\n",
      "Iteration 2385, loss = 0.28912778\n",
      "Iteration 2386, loss = 0.28885924\n",
      "Iteration 2387, loss = 0.28859087\n",
      "Iteration 2388, loss = 0.28832273\n",
      "Iteration 2389, loss = 0.28805485\n",
      "Iteration 2390, loss = 0.28778722\n",
      "Iteration 2391, loss = 0.28751984\n",
      "Iteration 2392, loss = 0.28725273\n",
      "Iteration 2393, loss = 0.28698588\n",
      "Iteration 2394, loss = 0.28671929\n",
      "Iteration 2395, loss = 0.28645297\n",
      "Iteration 2396, loss = 0.28618692\n",
      "Iteration 2397, loss = 0.28592113\n",
      "Iteration 2398, loss = 0.28565561\n",
      "Iteration 2399, loss = 0.28539037\n",
      "Iteration 2400, loss = 0.28512540\n",
      "Iteration 2401, loss = 0.28486070\n",
      "Iteration 2402, loss = 0.28459628\n",
      "Iteration 2403, loss = 0.28433213\n",
      "Iteration 2404, loss = 0.28406825\n",
      "Iteration 2405, loss = 0.28380465\n",
      "Iteration 2406, loss = 0.28354133\n",
      "Iteration 2407, loss = 0.28327828\n",
      "Iteration 2408, loss = 0.28301551\n",
      "Iteration 2409, loss = 0.28275302\n",
      "Iteration 2410, loss = 0.28249081\n",
      "Iteration 2411, loss = 0.28222887\n",
      "Iteration 2412, loss = 0.28196721\n",
      "Iteration 2413, loss = 0.28170583\n",
      "Iteration 2414, loss = 0.28144472\n",
      "Iteration 2415, loss = 0.28118389\n",
      "Iteration 2416, loss = 0.28092334\n",
      "Iteration 2417, loss = 0.28066307\n",
      "Iteration 2418, loss = 0.28040308\n",
      "Iteration 2419, loss = 0.28014309\n",
      "Iteration 2420, loss = 0.27988334\n",
      "Iteration 2421, loss = 0.27962383\n",
      "Iteration 2422, loss = 0.27936458\n",
      "Iteration 2423, loss = 0.27910559\n",
      "Iteration 2424, loss = 0.27884686\n",
      "Iteration 2425, loss = 0.27858839\n",
      "Iteration 2426, loss = 0.27833019\n",
      "Iteration 2427, loss = 0.27807225\n",
      "Iteration 2428, loss = 0.27781457\n",
      "Iteration 2429, loss = 0.27755717\n",
      "Iteration 2430, loss = 0.27730003\n",
      "Iteration 2431, loss = 0.27704316\n",
      "Iteration 2432, loss = 0.27678656\n",
      "Iteration 2433, loss = 0.27653022\n",
      "Iteration 2434, loss = 0.27627416\n",
      "Iteration 2435, loss = 0.27601837\n",
      "Iteration 2436, loss = 0.27576285\n",
      "Iteration 2437, loss = 0.27550761\n",
      "Iteration 2438, loss = 0.27525263\n",
      "Iteration 2439, loss = 0.27499793\n",
      "Iteration 2440, loss = 0.27474350\n",
      "Iteration 2441, loss = 0.27448934\n",
      "Iteration 2442, loss = 0.27423545\n",
      "Iteration 2443, loss = 0.27398184\n",
      "Iteration 2444, loss = 0.27372850\n",
      "Iteration 2445, loss = 0.27347543\n",
      "Iteration 2446, loss = 0.27322264\n",
      "Iteration 2447, loss = 0.27297011\n",
      "Iteration 2448, loss = 0.27271786\n",
      "Iteration 2449, loss = 0.27246588\n",
      "Iteration 2450, loss = 0.27221418\n",
      "Iteration 2451, loss = 0.27196275\n",
      "Iteration 2452, loss = 0.27171159\n",
      "Iteration 2453, loss = 0.27146070\n",
      "Iteration 2454, loss = 0.27121009\n",
      "Iteration 2455, loss = 0.27095975\n",
      "Iteration 2456, loss = 0.27070968\n",
      "Iteration 2457, loss = 0.27045988\n",
      "Iteration 2458, loss = 0.27021035\n",
      "Iteration 2459, loss = 0.26996109\n",
      "Iteration 2460, loss = 0.26971211\n",
      "Iteration 2461, loss = 0.26946339\n",
      "Iteration 2462, loss = 0.26921495\n",
      "Iteration 2463, loss = 0.26896678\n",
      "Iteration 2464, loss = 0.26871888\n",
      "Iteration 2465, loss = 0.26847125\n",
      "Iteration 2466, loss = 0.26822384\n",
      "Iteration 2467, loss = 0.26797651\n",
      "Iteration 2468, loss = 0.26772942\n",
      "Iteration 2469, loss = 0.26748259\n",
      "Iteration 2470, loss = 0.26723600\n",
      "Iteration 2471, loss = 0.26698968\n",
      "Iteration 2472, loss = 0.26674360\n",
      "Iteration 2473, loss = 0.26649779\n",
      "Iteration 2474, loss = 0.26625224\n",
      "Iteration 2475, loss = 0.26600694\n",
      "Iteration 2476, loss = 0.26576190\n",
      "Iteration 2477, loss = 0.26551713\n",
      "Iteration 2478, loss = 0.26527263\n",
      "Iteration 2479, loss = 0.26502838\n",
      "Iteration 2480, loss = 0.26478440\n",
      "Iteration 2481, loss = 0.26454067\n",
      "Iteration 2482, loss = 0.26429708\n",
      "Iteration 2483, loss = 0.26405375\n",
      "Iteration 2484, loss = 0.26381067\n",
      "Iteration 2485, loss = 0.26356785\n",
      "Iteration 2486, loss = 0.26332528\n",
      "Iteration 2487, loss = 0.26308297\n",
      "Iteration 2488, loss = 0.26284091\n",
      "Iteration 2489, loss = 0.26259912\n",
      "Iteration 2490, loss = 0.26235759\n",
      "Iteration 2491, loss = 0.26211632\n",
      "Iteration 2492, loss = 0.26187531\n",
      "Iteration 2493, loss = 0.26163456\n",
      "Iteration 2494, loss = 0.26139407\n",
      "Iteration 2495, loss = 0.26115385\n",
      "Iteration 2496, loss = 0.26091385\n",
      "Iteration 2497, loss = 0.26067403\n",
      "Iteration 2498, loss = 0.26043445\n",
      "Iteration 2499, loss = 0.26019514\n",
      "Iteration 2500, loss = 0.25995607\n",
      "Iteration 2501, loss = 0.25971726\n",
      "Iteration 2502, loss = 0.25947867\n",
      "Iteration 2503, loss = 0.25924024\n",
      "Iteration 2504, loss = 0.25900205\n",
      "Iteration 2505, loss = 0.25876409\n",
      "Iteration 2506, loss = 0.25852639\n",
      "Iteration 2507, loss = 0.25828892\n",
      "Iteration 2508, loss = 0.25805170\n",
      "Iteration 2509, loss = 0.25781473\n",
      "Iteration 2510, loss = 0.25757801\n",
      "Iteration 2511, loss = 0.25734154\n",
      "Iteration 2512, loss = 0.25710532\n",
      "Iteration 2513, loss = 0.25686936\n",
      "Iteration 2514, loss = 0.25663365\n",
      "Iteration 2515, loss = 0.25639815\n",
      "Iteration 2516, loss = 0.25616274\n",
      "Iteration 2517, loss = 0.25592755\n",
      "Iteration 2518, loss = 0.25569246\n",
      "Iteration 2519, loss = 0.25545754\n",
      "Iteration 2520, loss = 0.25522279\n",
      "Iteration 2521, loss = 0.25498827\n",
      "Iteration 2522, loss = 0.25475397\n",
      "Iteration 2523, loss = 0.25451989\n",
      "Iteration 2524, loss = 0.25428605\n",
      "Iteration 2525, loss = 0.25405244\n",
      "Iteration 2526, loss = 0.25381907\n",
      "Iteration 2527, loss = 0.25358612\n",
      "Iteration 2528, loss = 0.25335344\n",
      "Iteration 2529, loss = 0.25312102\n",
      "Iteration 2530, loss = 0.25288886\n",
      "Iteration 2531, loss = 0.25265696\n",
      "Iteration 2532, loss = 0.25242532\n",
      "Iteration 2533, loss = 0.25219393\n",
      "Iteration 2534, loss = 0.25196280\n",
      "Iteration 2535, loss = 0.25173193\n",
      "Iteration 2536, loss = 0.25150132\n",
      "Iteration 2537, loss = 0.25127097\n",
      "Iteration 2538, loss = 0.25104087\n",
      "Iteration 2539, loss = 0.25081103\n",
      "Iteration 2540, loss = 0.25058145\n",
      "Iteration 2541, loss = 0.25035211\n",
      "Iteration 2542, loss = 0.25012302\n",
      "Iteration 2543, loss = 0.24989425\n",
      "Iteration 2544, loss = 0.24966584\n",
      "Iteration 2545, loss = 0.24943769\n",
      "Iteration 2546, loss = 0.24920980\n",
      "Iteration 2547, loss = 0.24898202\n",
      "Iteration 2548, loss = 0.24875429\n",
      "Iteration 2549, loss = 0.24852680\n",
      "Iteration 2550, loss = 0.24829953\n",
      "Iteration 2551, loss = 0.24807248\n",
      "Iteration 2552, loss = 0.24784552\n",
      "Iteration 2553, loss = 0.24761879\n",
      "Iteration 2554, loss = 0.24739229\n",
      "Iteration 2555, loss = 0.24716603\n",
      "Iteration 2556, loss = 0.24694003\n",
      "Iteration 2557, loss = 0.24671440\n",
      "Iteration 2558, loss = 0.24648902\n",
      "Iteration 2559, loss = 0.24626387\n",
      "Iteration 2560, loss = 0.24603896\n",
      "Iteration 2561, loss = 0.24581430\n",
      "Iteration 2562, loss = 0.24558989\n",
      "Iteration 2563, loss = 0.24536579\n",
      "Iteration 2564, loss = 0.24514195\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 2565, loss = 0.24491835\n",
      "Iteration 2566, loss = 0.24469499\n",
      "Iteration 2567, loss = 0.24447187\n",
      "Iteration 2568, loss = 0.24424900\n",
      "Iteration 2569, loss = 0.24402638\n",
      "Iteration 2570, loss = 0.24380401\n",
      "Iteration 2571, loss = 0.24358190\n",
      "Iteration 2572, loss = 0.24336003\n",
      "Iteration 2573, loss = 0.24313842\n",
      "Iteration 2574, loss = 0.24291706\n",
      "Iteration 2575, loss = 0.24269595\n",
      "Iteration 2576, loss = 0.24247511\n",
      "Iteration 2577, loss = 0.24225452\n",
      "Iteration 2578, loss = 0.24203419\n",
      "Iteration 2579, loss = 0.24181412\n",
      "Iteration 2580, loss = 0.24159431\n",
      "Iteration 2581, loss = 0.24137475\n",
      "Iteration 2582, loss = 0.24115547\n",
      "Iteration 2583, loss = 0.24093647\n",
      "Iteration 2584, loss = 0.24071772\n",
      "Iteration 2585, loss = 0.24049922\n",
      "Iteration 2586, loss = 0.24028098\n",
      "Iteration 2587, loss = 0.24006300\n",
      "Iteration 2588, loss = 0.23984526\n",
      "Iteration 2589, loss = 0.23962778\n",
      "Iteration 2590, loss = 0.23941056\n",
      "Iteration 2591, loss = 0.23919359\n",
      "Iteration 2592, loss = 0.23897691\n",
      "Iteration 2593, loss = 0.23876047\n",
      "Iteration 2594, loss = 0.23854430\n",
      "Iteration 2595, loss = 0.23832838\n",
      "Iteration 2596, loss = 0.23811271\n",
      "Iteration 2597, loss = 0.23789730\n",
      "Iteration 2598, loss = 0.23768215\n",
      "Iteration 2599, loss = 0.23746725\n",
      "Iteration 2600, loss = 0.23725260\n",
      "Iteration 2601, loss = 0.23703814\n",
      "Iteration 2602, loss = 0.23682386\n",
      "Iteration 2603, loss = 0.23660983\n",
      "Iteration 2604, loss = 0.23639605\n",
      "Iteration 2605, loss = 0.23618252\n",
      "Iteration 2606, loss = 0.23596924\n",
      "Iteration 2607, loss = 0.23575620\n",
      "Iteration 2608, loss = 0.23554340\n",
      "Iteration 2609, loss = 0.23533086\n",
      "Iteration 2610, loss = 0.23511857\n",
      "Iteration 2611, loss = 0.23490653\n",
      "Iteration 2612, loss = 0.23469474\n",
      "Iteration 2613, loss = 0.23448320\n",
      "Iteration 2614, loss = 0.23427192\n",
      "Iteration 2615, loss = 0.23406088\n",
      "Iteration 2616, loss = 0.23385010\n",
      "Iteration 2617, loss = 0.23363957\n",
      "Iteration 2618, loss = 0.23342929\n",
      "Iteration 2619, loss = 0.23321926\n",
      "Iteration 2620, loss = 0.23300949\n",
      "Iteration 2621, loss = 0.23279996\n",
      "Iteration 2622, loss = 0.23259069\n",
      "Iteration 2623, loss = 0.23238168\n",
      "Iteration 2624, loss = 0.23217291\n",
      "Iteration 2625, loss = 0.23196440\n",
      "Iteration 2626, loss = 0.23175613\n",
      "Iteration 2627, loss = 0.23154804\n",
      "Iteration 2628, loss = 0.23134005\n",
      "Iteration 2629, loss = 0.23113225\n",
      "Iteration 2630, loss = 0.23092467\n",
      "Iteration 2631, loss = 0.23071732\n",
      "Iteration 2632, loss = 0.23051021\n",
      "Iteration 2633, loss = 0.23030333\n",
      "Iteration 2634, loss = 0.23009669\n",
      "Iteration 2635, loss = 0.22989028\n",
      "Iteration 2636, loss = 0.22968412\n",
      "Iteration 2637, loss = 0.22947819\n",
      "Iteration 2638, loss = 0.22927251\n",
      "Iteration 2639, loss = 0.22906707\n",
      "Iteration 2640, loss = 0.22886187\n",
      "Iteration 2641, loss = 0.22865691\n",
      "Iteration 2642, loss = 0.22845221\n",
      "Iteration 2643, loss = 0.22824777\n",
      "Iteration 2644, loss = 0.22804357\n",
      "Iteration 2645, loss = 0.22783962\n",
      "Iteration 2646, loss = 0.22763591\n",
      "Iteration 2647, loss = 0.22743245\n",
      "Iteration 2648, loss = 0.22722924\n",
      "Iteration 2649, loss = 0.22702627\n",
      "Iteration 2650, loss = 0.22682355\n",
      "Iteration 2651, loss = 0.22662108\n",
      "Iteration 2652, loss = 0.22641885\n",
      "Iteration 2653, loss = 0.22621687\n",
      "Iteration 2654, loss = 0.22601513\n",
      "Iteration 2655, loss = 0.22581364\n",
      "Iteration 2656, loss = 0.22561238\n",
      "Iteration 2657, loss = 0.22541133\n",
      "Iteration 2658, loss = 0.22521050\n",
      "Iteration 2659, loss = 0.22500990\n",
      "Iteration 2660, loss = 0.22480954\n",
      "Iteration 2661, loss = 0.22460942\n",
      "Iteration 2662, loss = 0.22440940\n",
      "Iteration 2663, loss = 0.22420931\n",
      "Iteration 2664, loss = 0.22400938\n",
      "Iteration 2665, loss = 0.22380964\n",
      "Iteration 2666, loss = 0.22361010\n",
      "Iteration 2667, loss = 0.22341066\n",
      "Iteration 2668, loss = 0.22321127\n",
      "Iteration 2669, loss = 0.22301207\n",
      "Iteration 2670, loss = 0.22281295\n",
      "Iteration 2671, loss = 0.22261402\n",
      "Iteration 2672, loss = 0.22241527\n",
      "Iteration 2673, loss = 0.22221671\n",
      "Iteration 2674, loss = 0.22201835\n",
      "Iteration 2675, loss = 0.22182020\n",
      "Iteration 2676, loss = 0.22162231\n",
      "Iteration 2677, loss = 0.22142471\n",
      "Iteration 2678, loss = 0.22122735\n",
      "Iteration 2679, loss = 0.22103021\n",
      "Iteration 2680, loss = 0.22083330\n",
      "Iteration 2681, loss = 0.22063661\n",
      "Iteration 2682, loss = 0.22044016\n",
      "Iteration 2683, loss = 0.22024393\n",
      "Iteration 2684, loss = 0.22004794\n",
      "Iteration 2685, loss = 0.21985217\n",
      "Iteration 2686, loss = 0.21965664\n",
      "Iteration 2687, loss = 0.21946133\n",
      "Iteration 2688, loss = 0.21926626\n",
      "Iteration 2689, loss = 0.21907150\n",
      "Iteration 2690, loss = 0.21887700\n",
      "Iteration 2691, loss = 0.21868266\n",
      "Iteration 2692, loss = 0.21848847\n",
      "Iteration 2693, loss = 0.21829418\n",
      "Iteration 2694, loss = 0.21810014\n",
      "Iteration 2695, loss = 0.21790632\n",
      "Iteration 2696, loss = 0.21771271\n",
      "Iteration 2697, loss = 0.21751931\n",
      "Iteration 2698, loss = 0.21732597\n",
      "Iteration 2699, loss = 0.21713292\n",
      "Iteration 2700, loss = 0.21694010\n",
      "Iteration 2701, loss = 0.21674750\n",
      "Iteration 2702, loss = 0.21655511\n",
      "Iteration 2703, loss = 0.21636304\n",
      "Iteration 2704, loss = 0.21617119\n",
      "Iteration 2705, loss = 0.21597957\n",
      "Iteration 2706, loss = 0.21578817\n",
      "Iteration 2707, loss = 0.21559699\n",
      "Iteration 2708, loss = 0.21540603\n",
      "Iteration 2709, loss = 0.21521531\n",
      "Iteration 2710, loss = 0.21502481\n",
      "Iteration 2711, loss = 0.21483454\n",
      "Iteration 2712, loss = 0.21464450\n",
      "Iteration 2713, loss = 0.21445469\n",
      "Iteration 2714, loss = 0.21426511\n",
      "Iteration 2715, loss = 0.21407576\n",
      "Iteration 2716, loss = 0.21388664\n",
      "Iteration 2717, loss = 0.21369775\n",
      "Iteration 2718, loss = 0.21350910\n",
      "Iteration 2719, loss = 0.21332067\n",
      "Iteration 2720, loss = 0.21313248\n",
      "Iteration 2721, loss = 0.21294452\n",
      "Iteration 2722, loss = 0.21275674\n",
      "Iteration 2723, loss = 0.21256914\n",
      "Iteration 2724, loss = 0.21238175\n",
      "Iteration 2725, loss = 0.21219460\n",
      "Iteration 2726, loss = 0.21200771\n",
      "Iteration 2727, loss = 0.21182105\n",
      "Iteration 2728, loss = 0.21163461\n",
      "Iteration 2729, loss = 0.21144840\n",
      "Iteration 2730, loss = 0.21126242\n",
      "Iteration 2731, loss = 0.21107667\n",
      "Iteration 2732, loss = 0.21089115\n",
      "Iteration 2733, loss = 0.21070585\n",
      "Iteration 2734, loss = 0.21052078\n",
      "Iteration 2735, loss = 0.21033594\n",
      "Iteration 2736, loss = 0.21015133\n",
      "Iteration 2737, loss = 0.20996692\n",
      "Iteration 2738, loss = 0.20978273\n",
      "Iteration 2739, loss = 0.20959875\n",
      "Iteration 2740, loss = 0.20941501\n",
      "Iteration 2741, loss = 0.20923148\n",
      "Iteration 2742, loss = 0.20904817\n",
      "Iteration 2743, loss = 0.20886502\n",
      "Iteration 2744, loss = 0.20868208\n",
      "Iteration 2745, loss = 0.20849936\n",
      "Iteration 2746, loss = 0.20831685\n",
      "Iteration 2747, loss = 0.20813455\n",
      "Iteration 2748, loss = 0.20795248\n",
      "Iteration 2749, loss = 0.20777062\n",
      "Iteration 2750, loss = 0.20758898\n",
      "Iteration 2751, loss = 0.20740755\n",
      "Iteration 2752, loss = 0.20722633\n",
      "Iteration 2753, loss = 0.20704532\n",
      "Iteration 2754, loss = 0.20686452\n",
      "Iteration 2755, loss = 0.20668395\n",
      "Iteration 2756, loss = 0.20650358\n",
      "Iteration 2757, loss = 0.20632351\n",
      "Iteration 2758, loss = 0.20614398\n",
      "Iteration 2759, loss = 0.20596459\n",
      "Iteration 2760, loss = 0.20578538\n",
      "Iteration 2761, loss = 0.20560641\n",
      "Iteration 2762, loss = 0.20542766\n",
      "Iteration 2763, loss = 0.20524914\n",
      "Iteration 2764, loss = 0.20507085\n",
      "Iteration 2765, loss = 0.20489278\n",
      "Iteration 2766, loss = 0.20471494\n",
      "Iteration 2767, loss = 0.20453731\n",
      "Iteration 2768, loss = 0.20435978\n",
      "Iteration 2769, loss = 0.20418229\n",
      "Iteration 2770, loss = 0.20400500\n",
      "Iteration 2771, loss = 0.20382790\n",
      "Iteration 2772, loss = 0.20365101\n",
      "Iteration 2773, loss = 0.20347431\n",
      "Iteration 2774, loss = 0.20329782\n",
      "Iteration 2775, loss = 0.20312153\n",
      "Iteration 2776, loss = 0.20294544\n",
      "Iteration 2777, loss = 0.20276957\n",
      "Iteration 2778, loss = 0.20259391\n",
      "Iteration 2779, loss = 0.20241845\n",
      "Iteration 2780, loss = 0.20224321\n",
      "Iteration 2781, loss = 0.20206817\n",
      "Iteration 2782, loss = 0.20189347\n",
      "Iteration 2783, loss = 0.20171900\n",
      "Iteration 2784, loss = 0.20154476\n",
      "Iteration 2785, loss = 0.20137073\n",
      "Iteration 2786, loss = 0.20119692\n",
      "Iteration 2787, loss = 0.20102333\n",
      "Iteration 2788, loss = 0.20084995\n",
      "Iteration 2789, loss = 0.20067680\n",
      "Iteration 2790, loss = 0.20050386\n",
      "Iteration 2791, loss = 0.20033113\n",
      "Iteration 2792, loss = 0.20015850\n",
      "Iteration 2793, loss = 0.19998599\n",
      "Iteration 2794, loss = 0.19981347\n",
      "Iteration 2795, loss = 0.19964112\n",
      "Iteration 2796, loss = 0.19946894\n",
      "Iteration 2797, loss = 0.19929696\n",
      "Iteration 2798, loss = 0.19912523\n",
      "Iteration 2799, loss = 0.19895369\n",
      "Iteration 2800, loss = 0.19878233\n",
      "Iteration 2801, loss = 0.19861118\n",
      "Iteration 2802, loss = 0.19844021\n",
      "Iteration 2803, loss = 0.19826940\n",
      "Iteration 2804, loss = 0.19809879\n",
      "Iteration 2805, loss = 0.19792838\n",
      "Iteration 2806, loss = 0.19775816\n",
      "Iteration 2807, loss = 0.19758814\n",
      "Iteration 2808, loss = 0.19741880\n",
      "Iteration 2809, loss = 0.19724969\n",
      "Iteration 2810, loss = 0.19708081\n",
      "Iteration 2811, loss = 0.19691214\n",
      "Iteration 2812, loss = 0.19674369\n",
      "Iteration 2813, loss = 0.19657565\n",
      "Iteration 2814, loss = 0.19640790\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 2815, loss = 0.19624035\n",
      "Iteration 2816, loss = 0.19607300\n",
      "Iteration 2817, loss = 0.19590586\n",
      "Iteration 2818, loss = 0.19573893\n",
      "Iteration 2819, loss = 0.19557222\n",
      "Iteration 2820, loss = 0.19540571\n",
      "Iteration 2821, loss = 0.19523942\n",
      "Iteration 2822, loss = 0.19507335\n",
      "Iteration 2823, loss = 0.19490749\n",
      "Iteration 2824, loss = 0.19474184\n",
      "Iteration 2825, loss = 0.19457641\n",
      "Iteration 2826, loss = 0.19441123\n",
      "Iteration 2827, loss = 0.19424627\n",
      "Iteration 2828, loss = 0.19408154\n",
      "Iteration 2829, loss = 0.19391702\n",
      "Iteration 2830, loss = 0.19375273\n",
      "Iteration 2831, loss = 0.19358865\n",
      "Iteration 2832, loss = 0.19342482\n",
      "Iteration 2833, loss = 0.19326112\n",
      "Iteration 2834, loss = 0.19309756\n",
      "Iteration 2835, loss = 0.19293418\n",
      "Iteration 2836, loss = 0.19277086\n",
      "Iteration 2837, loss = 0.19260773\n",
      "Iteration 2838, loss = 0.19244480\n",
      "Iteration 2839, loss = 0.19228207\n",
      "Iteration 2840, loss = 0.19211954\n",
      "Iteration 2841, loss = 0.19195721\n",
      "Iteration 2842, loss = 0.19179509\n",
      "Iteration 2843, loss = 0.19163316\n",
      "Iteration 2844, loss = 0.19147144\n",
      "Iteration 2845, loss = 0.19130993\n",
      "Iteration 2846, loss = 0.19114862\n",
      "Iteration 2847, loss = 0.19098758\n",
      "Iteration 2848, loss = 0.19082677\n",
      "Iteration 2849, loss = 0.19066617\n",
      "Iteration 2850, loss = 0.19050578\n",
      "Iteration 2851, loss = 0.19034561\n",
      "Iteration 2852, loss = 0.19018565\n",
      "Iteration 2853, loss = 0.19002591\n",
      "Iteration 2854, loss = 0.18986638\n",
      "Iteration 2855, loss = 0.18970706\n",
      "Iteration 2856, loss = 0.18954798\n",
      "Iteration 2857, loss = 0.18938913\n",
      "Iteration 2858, loss = 0.18923051\n",
      "Iteration 2859, loss = 0.18907215\n",
      "Iteration 2860, loss = 0.18891400\n",
      "Iteration 2861, loss = 0.18875608\n",
      "Iteration 2862, loss = 0.18859838\n",
      "Iteration 2863, loss = 0.18844092\n",
      "Iteration 2864, loss = 0.18828368\n",
      "Iteration 2865, loss = 0.18812666\n",
      "Iteration 2866, loss = 0.18796985\n",
      "Iteration 2867, loss = 0.18781326\n",
      "Iteration 2868, loss = 0.18765691\n",
      "Iteration 2869, loss = 0.18750078\n",
      "Iteration 2870, loss = 0.18734486\n",
      "Iteration 2871, loss = 0.18718916\n",
      "Iteration 2872, loss = 0.18703368\n",
      "Iteration 2873, loss = 0.18687842\n",
      "Iteration 2874, loss = 0.18672337\n",
      "Iteration 2875, loss = 0.18656855\n",
      "Iteration 2876, loss = 0.18641394\n",
      "Iteration 2877, loss = 0.18625956\n",
      "Iteration 2878, loss = 0.18610537\n",
      "Iteration 2879, loss = 0.18595133\n",
      "Iteration 2880, loss = 0.18579749\n",
      "Iteration 2881, loss = 0.18564385\n",
      "Iteration 2882, loss = 0.18549043\n",
      "Iteration 2883, loss = 0.18533723\n",
      "Iteration 2884, loss = 0.18518423\n",
      "Iteration 2885, loss = 0.18503143\n",
      "Iteration 2886, loss = 0.18487886\n",
      "Iteration 2887, loss = 0.18472649\n",
      "Iteration 2888, loss = 0.18457433\n",
      "Iteration 2889, loss = 0.18442233\n",
      "Iteration 2890, loss = 0.18427048\n",
      "Iteration 2891, loss = 0.18411883\n",
      "Iteration 2892, loss = 0.18396738\n",
      "Iteration 2893, loss = 0.18381613\n",
      "Iteration 2894, loss = 0.18366509\n",
      "Iteration 2895, loss = 0.18351424\n",
      "Iteration 2896, loss = 0.18336360\n",
      "Iteration 2897, loss = 0.18321316\n",
      "Iteration 2898, loss = 0.18306292\n",
      "Iteration 2899, loss = 0.18291289\n",
      "Iteration 2900, loss = 0.18276306\n",
      "Iteration 2901, loss = 0.18261342\n",
      "Iteration 2902, loss = 0.18246399\n",
      "Iteration 2903, loss = 0.18231476\n",
      "Iteration 2904, loss = 0.18216574\n",
      "Iteration 2905, loss = 0.18201691\n",
      "Iteration 2906, loss = 0.18186829\n",
      "Iteration 2907, loss = 0.18171986\n",
      "Iteration 2908, loss = 0.18157163\n",
      "Iteration 2909, loss = 0.18142360\n",
      "Iteration 2910, loss = 0.18127571\n",
      "Iteration 2911, loss = 0.18112785\n",
      "Iteration 2912, loss = 0.18098016\n",
      "Iteration 2913, loss = 0.18083264\n",
      "Iteration 2914, loss = 0.18068532\n",
      "Iteration 2915, loss = 0.18053817\n",
      "Iteration 2916, loss = 0.18039121\n",
      "Iteration 2917, loss = 0.18024442\n",
      "Iteration 2918, loss = 0.18009782\n",
      "Iteration 2919, loss = 0.17995141\n",
      "Iteration 2920, loss = 0.17980518\n",
      "Iteration 2921, loss = 0.17965913\n",
      "Iteration 2922, loss = 0.17951327\n",
      "Iteration 2923, loss = 0.17936759\n",
      "Iteration 2924, loss = 0.17922210\n",
      "Iteration 2925, loss = 0.17907679\n",
      "Iteration 2926, loss = 0.17893167\n",
      "Iteration 2927, loss = 0.17878672\n",
      "Iteration 2928, loss = 0.17864197\n",
      "Iteration 2929, loss = 0.17849739\n",
      "Iteration 2930, loss = 0.17835289\n",
      "Iteration 2931, loss = 0.17820855\n",
      "Iteration 2932, loss = 0.17806439\n",
      "Iteration 2933, loss = 0.17792040\n",
      "Iteration 2934, loss = 0.17777674\n",
      "Iteration 2935, loss = 0.17763327\n",
      "Iteration 2936, loss = 0.17748999\n",
      "Iteration 2937, loss = 0.17734688\n",
      "Iteration 2938, loss = 0.17720397\n",
      "Iteration 2939, loss = 0.17706124\n",
      "Iteration 2940, loss = 0.17691869\n",
      "Iteration 2941, loss = 0.17677633\n",
      "Iteration 2942, loss = 0.17663406\n",
      "Iteration 2943, loss = 0.17649185\n",
      "Iteration 2944, loss = 0.17634979\n",
      "Iteration 2945, loss = 0.17620790\n",
      "Iteration 2946, loss = 0.17606619\n",
      "Iteration 2947, loss = 0.17592463\n",
      "Iteration 2948, loss = 0.17578324\n",
      "Iteration 2949, loss = 0.17564195\n",
      "Iteration 2950, loss = 0.17550080\n",
      "Iteration 2951, loss = 0.17535980\n",
      "Iteration 2952, loss = 0.17521897\n",
      "Iteration 2953, loss = 0.17507835\n",
      "Iteration 2954, loss = 0.17493800\n",
      "Iteration 2955, loss = 0.17479782\n",
      "Iteration 2956, loss = 0.17465784\n",
      "Iteration 2957, loss = 0.17451811\n",
      "Iteration 2958, loss = 0.17437856\n",
      "Iteration 2959, loss = 0.17423920\n",
      "Iteration 2960, loss = 0.17410002\n",
      "Iteration 2961, loss = 0.17396101\n",
      "Iteration 2962, loss = 0.17382220\n",
      "Iteration 2963, loss = 0.17368355\n",
      "Iteration 2964, loss = 0.17354505\n",
      "Iteration 2965, loss = 0.17340674\n",
      "Iteration 2966, loss = 0.17326860\n",
      "Iteration 2967, loss = 0.17313064\n",
      "Iteration 2968, loss = 0.17299286\n",
      "Iteration 2969, loss = 0.17285525\n",
      "Iteration 2970, loss = 0.17271781\n",
      "Iteration 2971, loss = 0.17258056\n",
      "Iteration 2972, loss = 0.17244348\n",
      "Iteration 2973, loss = 0.17230657\n",
      "Iteration 2974, loss = 0.17216970\n",
      "Iteration 2975, loss = 0.17203301\n",
      "Iteration 2976, loss = 0.17189647\n",
      "Iteration 2977, loss = 0.17176009\n",
      "Iteration 2978, loss = 0.17162387\n",
      "Iteration 2979, loss = 0.17148781\n",
      "Iteration 2980, loss = 0.17135192\n",
      "Iteration 2981, loss = 0.17121619\n",
      "Iteration 2982, loss = 0.17108062\n",
      "Iteration 2983, loss = 0.17094521\n",
      "Iteration 2984, loss = 0.17080997\n",
      "Iteration 2985, loss = 0.17067490\n",
      "Iteration 2986, loss = 0.17053998\n",
      "Iteration 2987, loss = 0.17040523\n",
      "Iteration 2988, loss = 0.17027072\n",
      "Iteration 2989, loss = 0.17013679\n",
      "Iteration 2990, loss = 0.17000303\n",
      "Iteration 2991, loss = 0.16986946\n",
      "Iteration 2992, loss = 0.16973608\n",
      "Iteration 2993, loss = 0.16960288\n",
      "Iteration 2994, loss = 0.16946986\n",
      "Iteration 2995, loss = 0.16933703\n",
      "Iteration 2996, loss = 0.16920438\n",
      "Iteration 2997, loss = 0.16907190\n",
      "Iteration 2998, loss = 0.16893961\n",
      "Iteration 2999, loss = 0.16880749\n",
      "Iteration 3000, loss = 0.16867556\n",
      "Iteration 3001, loss = 0.16854380\n",
      "Iteration 3002, loss = 0.16841223\n",
      "Iteration 3003, loss = 0.16828083\n",
      "Iteration 3004, loss = 0.16814960\n",
      "Iteration 3005, loss = 0.16801845\n",
      "Iteration 3006, loss = 0.16788746\n",
      "Iteration 3007, loss = 0.16775662\n",
      "Iteration 3008, loss = 0.16762593\n",
      "Iteration 3009, loss = 0.16749541\n",
      "Iteration 3010, loss = 0.16736505\n",
      "Iteration 3011, loss = 0.16723485\n",
      "Iteration 3012, loss = 0.16710481\n",
      "Iteration 3013, loss = 0.16697492\n",
      "Iteration 3014, loss = 0.16684520\n",
      "Iteration 3015, loss = 0.16671564\n",
      "Iteration 3016, loss = 0.16658623\n",
      "Iteration 3017, loss = 0.16645699\n",
      "Iteration 3018, loss = 0.16632791\n",
      "Iteration 3019, loss = 0.16619899\n",
      "Iteration 3020, loss = 0.16607023\n",
      "Iteration 3021, loss = 0.16594162\n",
      "Iteration 3022, loss = 0.16581318\n",
      "Iteration 3023, loss = 0.16568490\n",
      "Iteration 3024, loss = 0.16555656\n",
      "Iteration 3025, loss = 0.16542825\n",
      "Iteration 3026, loss = 0.16530007\n",
      "Iteration 3027, loss = 0.16517202\n",
      "Iteration 3028, loss = 0.16504411\n",
      "Iteration 3029, loss = 0.16491633\n",
      "Iteration 3030, loss = 0.16478881\n",
      "Iteration 3031, loss = 0.16466155\n",
      "Iteration 3032, loss = 0.16453439\n",
      "Iteration 3033, loss = 0.16440740\n",
      "Iteration 3034, loss = 0.16428055\n",
      "Iteration 3035, loss = 0.16415396\n",
      "Iteration 3036, loss = 0.16402752\n",
      "Iteration 3037, loss = 0.16390126\n",
      "Iteration 3038, loss = 0.16377554\n",
      "Iteration 3039, loss = 0.16365000\n",
      "Iteration 3040, loss = 0.16352477\n",
      "Iteration 3041, loss = 0.16339966\n",
      "Iteration 3042, loss = 0.16327468\n",
      "Iteration 3043, loss = 0.16314984\n",
      "Iteration 3044, loss = 0.16302514\n",
      "Iteration 3045, loss = 0.16290059\n",
      "Iteration 3046, loss = 0.16277620\n",
      "Iteration 3047, loss = 0.16265197\n",
      "Iteration 3048, loss = 0.16252791\n",
      "Iteration 3049, loss = 0.16240401\n",
      "Iteration 3050, loss = 0.16228029\n",
      "Iteration 3051, loss = 0.16215674\n",
      "Iteration 3052, loss = 0.16203338\n",
      "Iteration 3053, loss = 0.16191020\n",
      "Iteration 3054, loss = 0.16178720\n",
      "Iteration 3055, loss = 0.16166449\n",
      "Iteration 3056, loss = 0.16154195\n",
      "Iteration 3057, loss = 0.16141960\n",
      "Iteration 3058, loss = 0.16129743\n",
      "Iteration 3059, loss = 0.16117539\n",
      "Iteration 3060, loss = 0.16105341\n",
      "Iteration 3061, loss = 0.16093159\n",
      "Iteration 3062, loss = 0.16080995\n",
      "Iteration 3063, loss = 0.16068847\n",
      "Iteration 3064, loss = 0.16056716\n",
      "Iteration 3065, loss = 0.16044602\n",
      "Iteration 3066, loss = 0.16032504\n",
      "Iteration 3067, loss = 0.16020423\n",
      "Iteration 3068, loss = 0.16008360\n",
      "Iteration 3069, loss = 0.15996317\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 3070, loss = 0.15984294\n",
      "Iteration 3071, loss = 0.15972288\n",
      "Iteration 3072, loss = 0.15960300\n",
      "Iteration 3073, loss = 0.15948329\n",
      "Iteration 3074, loss = 0.15936375\n",
      "Iteration 3075, loss = 0.15924438\n",
      "Iteration 3076, loss = 0.15912520\n",
      "Iteration 3077, loss = 0.15900619\n",
      "Iteration 3078, loss = 0.15888736\n",
      "Iteration 3079, loss = 0.15876871\n",
      "Iteration 3080, loss = 0.15865024\n",
      "Iteration 3081, loss = 0.15853194\n",
      "Iteration 3082, loss = 0.15841383\n",
      "Iteration 3083, loss = 0.15829589\n",
      "Iteration 3084, loss = 0.15817813\n",
      "Iteration 3085, loss = 0.15806055\n",
      "Iteration 3086, loss = 0.15794315\n",
      "Iteration 3087, loss = 0.15782592\n",
      "Iteration 3088, loss = 0.15770888\n",
      "Iteration 3089, loss = 0.15759200\n",
      "Iteration 3090, loss = 0.15747531\n",
      "Iteration 3091, loss = 0.15735879\n",
      "Iteration 3092, loss = 0.15724245\n",
      "Iteration 3093, loss = 0.15712628\n",
      "Iteration 3094, loss = 0.15701028\n",
      "Iteration 3095, loss = 0.15689446\n",
      "Iteration 3096, loss = 0.15677881\n",
      "Iteration 3097, loss = 0.15666334\n",
      "Iteration 3098, loss = 0.15654804\n",
      "Iteration 3099, loss = 0.15643291\n",
      "Iteration 3100, loss = 0.15631795\n",
      "Iteration 3101, loss = 0.15620316\n",
      "Iteration 3102, loss = 0.15608854\n",
      "Iteration 3103, loss = 0.15597409\n",
      "Iteration 3104, loss = 0.15585980\n",
      "Iteration 3105, loss = 0.15574569\n",
      "Iteration 3106, loss = 0.15563175\n",
      "Iteration 3107, loss = 0.15551796\n",
      "Iteration 3108, loss = 0.15540435\n",
      "Iteration 3109, loss = 0.15529090\n",
      "Iteration 3110, loss = 0.15517761\n",
      "Iteration 3111, loss = 0.15506449\n",
      "Iteration 3112, loss = 0.15495153\n",
      "Iteration 3113, loss = 0.15483874\n",
      "Iteration 3114, loss = 0.15472610\n",
      "Iteration 3115, loss = 0.15461363\n",
      "Iteration 3116, loss = 0.15450132\n",
      "Iteration 3117, loss = 0.15438917\n",
      "Iteration 3118, loss = 0.15427717\n",
      "Iteration 3119, loss = 0.15416534\n",
      "Iteration 3120, loss = 0.15405361\n",
      "Iteration 3121, loss = 0.15394184\n",
      "Iteration 3122, loss = 0.15383020\n",
      "Iteration 3123, loss = 0.15371870\n",
      "Iteration 3124, loss = 0.15360734\n",
      "Iteration 3125, loss = 0.15349611\n",
      "Iteration 3126, loss = 0.15338503\n",
      "Iteration 3127, loss = 0.15327409\n",
      "Iteration 3128, loss = 0.15316330\n",
      "Iteration 3129, loss = 0.15305264\n",
      "Iteration 3130, loss = 0.15294213\n",
      "Iteration 3131, loss = 0.15283176\n",
      "Iteration 3132, loss = 0.15272154\n",
      "Iteration 3133, loss = 0.15261146\n",
      "Iteration 3134, loss = 0.15250152\n",
      "Iteration 3135, loss = 0.15239173\n",
      "Iteration 3136, loss = 0.15228209\n",
      "Iteration 3137, loss = 0.15217259\n",
      "Iteration 3138, loss = 0.15206324\n",
      "Iteration 3139, loss = 0.15195402\n",
      "Iteration 3140, loss = 0.15184496\n",
      "Iteration 3141, loss = 0.15173604\n",
      "Iteration 3142, loss = 0.15162732\n",
      "Iteration 3143, loss = 0.15151887\n",
      "Iteration 3144, loss = 0.15141059\n",
      "Iteration 3145, loss = 0.15130246\n",
      "Iteration 3146, loss = 0.15119449\n",
      "Iteration 3147, loss = 0.15108668\n",
      "Iteration 3148, loss = 0.15097902\n",
      "Iteration 3149, loss = 0.15087151\n",
      "Iteration 3150, loss = 0.15076416\n",
      "Iteration 3151, loss = 0.15065696\n",
      "Iteration 3152, loss = 0.15054991\n",
      "Iteration 3153, loss = 0.15044302\n",
      "Iteration 3154, loss = 0.15033627\n",
      "Iteration 3155, loss = 0.15022967\n",
      "Iteration 3156, loss = 0.15012323\n",
      "Iteration 3157, loss = 0.15001708\n",
      "Iteration 3158, loss = 0.14991106\n",
      "Iteration 3159, loss = 0.14980519\n",
      "Iteration 3160, loss = 0.14969948\n",
      "Iteration 3161, loss = 0.14959391\n",
      "Iteration 3162, loss = 0.14948851\n",
      "Iteration 3163, loss = 0.14938318\n",
      "Iteration 3164, loss = 0.14927798\n",
      "Iteration 3165, loss = 0.14917293\n",
      "Iteration 3166, loss = 0.14906801\n",
      "Iteration 3167, loss = 0.14896325\n",
      "Iteration 3168, loss = 0.14885863\n",
      "Iteration 3169, loss = 0.14875416\n",
      "Iteration 3170, loss = 0.14864974\n",
      "Iteration 3171, loss = 0.14854541\n",
      "Iteration 3172, loss = 0.14844121\n",
      "Iteration 3173, loss = 0.14833715\n",
      "Iteration 3174, loss = 0.14823323\n",
      "Iteration 3175, loss = 0.14812945\n",
      "Iteration 3176, loss = 0.14802579\n",
      "Iteration 3177, loss = 0.14792228\n",
      "Iteration 3178, loss = 0.14781891\n",
      "Iteration 3179, loss = 0.14771568\n",
      "Iteration 3180, loss = 0.14761259\n",
      "Iteration 3181, loss = 0.14750964\n",
      "Iteration 3182, loss = 0.14740682\n",
      "Iteration 3183, loss = 0.14730414\n",
      "Iteration 3184, loss = 0.14720161\n",
      "Iteration 3185, loss = 0.14709922\n",
      "Iteration 3186, loss = 0.14699696\n",
      "Iteration 3187, loss = 0.14689484\n",
      "Iteration 3188, loss = 0.14679287\n",
      "Iteration 3189, loss = 0.14669104\n",
      "Iteration 3190, loss = 0.14658928\n",
      "Iteration 3191, loss = 0.14648756\n",
      "Iteration 3192, loss = 0.14638596\n",
      "Iteration 3193, loss = 0.14628450\n",
      "Iteration 3194, loss = 0.14618316\n",
      "Iteration 3195, loss = 0.14608195\n",
      "Iteration 3196, loss = 0.14598087\n",
      "Iteration 3197, loss = 0.14587991\n",
      "Iteration 3198, loss = 0.14577909\n",
      "Iteration 3199, loss = 0.14567839\n",
      "Iteration 3200, loss = 0.14557782\n",
      "Iteration 3201, loss = 0.14547739\n",
      "Iteration 3202, loss = 0.14537710\n",
      "Iteration 3203, loss = 0.14527693\n",
      "Iteration 3204, loss = 0.14517682\n",
      "Iteration 3205, loss = 0.14507678\n",
      "Iteration 3206, loss = 0.14497687\n",
      "Iteration 3207, loss = 0.14487707\n",
      "Iteration 3208, loss = 0.14477740\n",
      "Iteration 3209, loss = 0.14467785\n",
      "Iteration 3210, loss = 0.14457842\n",
      "Iteration 3211, loss = 0.14447912\n",
      "Iteration 3212, loss = 0.14437994\n",
      "Iteration 3213, loss = 0.14428090\n",
      "Iteration 3214, loss = 0.14418195\n",
      "Iteration 3215, loss = 0.14408311\n",
      "Iteration 3216, loss = 0.14398437\n",
      "Iteration 3217, loss = 0.14388568\n",
      "Iteration 3218, loss = 0.14378710\n",
      "Iteration 3219, loss = 0.14368864\n",
      "Iteration 3220, loss = 0.14359029\n",
      "Iteration 3221, loss = 0.14349207\n",
      "Iteration 3222, loss = 0.14339397\n",
      "Iteration 3223, loss = 0.14329598\n",
      "Iteration 3224, loss = 0.14319811\n",
      "Iteration 3225, loss = 0.14310036\n",
      "Iteration 3226, loss = 0.14300274\n",
      "Iteration 3227, loss = 0.14290524\n",
      "Iteration 3228, loss = 0.14280786\n",
      "Iteration 3229, loss = 0.14271061\n",
      "Iteration 3230, loss = 0.14261348\n",
      "Iteration 3231, loss = 0.14251647\n",
      "Iteration 3232, loss = 0.14241958\n",
      "Iteration 3233, loss = 0.14232282\n",
      "Iteration 3234, loss = 0.14222619\n",
      "Iteration 3235, loss = 0.14213007\n",
      "Iteration 3236, loss = 0.14203411\n",
      "Iteration 3237, loss = 0.14193829\n",
      "Iteration 3238, loss = 0.14184263\n",
      "Iteration 3239, loss = 0.14174728\n",
      "Iteration 3240, loss = 0.14165207\n",
      "Iteration 3241, loss = 0.14155691\n",
      "Iteration 3242, loss = 0.14146173\n",
      "Iteration 3243, loss = 0.14136668\n",
      "Iteration 3244, loss = 0.14127175\n",
      "Iteration 3245, loss = 0.14117695\n",
      "Iteration 3246, loss = 0.14108227\n",
      "Iteration 3247, loss = 0.14098771\n",
      "Iteration 3248, loss = 0.14089328\n",
      "Iteration 3249, loss = 0.14079899\n",
      "Iteration 3250, loss = 0.14070483\n",
      "Iteration 3251, loss = 0.14061080\n",
      "Iteration 3252, loss = 0.14051690\n",
      "Iteration 3253, loss = 0.14042313\n",
      "Iteration 3254, loss = 0.14032949\n",
      "Iteration 3255, loss = 0.14023598\n",
      "Iteration 3256, loss = 0.14014260\n",
      "Iteration 3257, loss = 0.14004936\n",
      "Iteration 3258, loss = 0.13995624\n",
      "Iteration 3259, loss = 0.13986326\n",
      "Iteration 3260, loss = 0.13977040\n",
      "Iteration 3261, loss = 0.13967768\n",
      "Iteration 3262, loss = 0.13958509\n",
      "Iteration 3263, loss = 0.13949263\n",
      "Iteration 3264, loss = 0.13940030\n",
      "Iteration 3265, loss = 0.13930809\n",
      "Iteration 3266, loss = 0.13921602\n",
      "Iteration 3267, loss = 0.13912408\n",
      "Iteration 3268, loss = 0.13903227\n",
      "Iteration 3269, loss = 0.13894058\n",
      "Iteration 3270, loss = 0.13884913\n",
      "Iteration 3271, loss = 0.13875783\n",
      "Iteration 3272, loss = 0.13866668\n",
      "Iteration 3273, loss = 0.13857566\n",
      "Iteration 3274, loss = 0.13848478\n",
      "Iteration 3275, loss = 0.13839403\n",
      "Iteration 3276, loss = 0.13830342\n",
      "Iteration 3277, loss = 0.13821294\n",
      "Iteration 3278, loss = 0.13812254\n",
      "Iteration 3279, loss = 0.13803219\n",
      "Iteration 3280, loss = 0.13794196\n",
      "Iteration 3281, loss = 0.13785184\n",
      "Iteration 3282, loss = 0.13776184\n",
      "Iteration 3283, loss = 0.13767195\n",
      "Iteration 3284, loss = 0.13758219\n",
      "Iteration 3285, loss = 0.13749254\n",
      "Iteration 3286, loss = 0.13740301\n",
      "Iteration 3287, loss = 0.13731359\n",
      "Iteration 3288, loss = 0.13722429\n",
      "Iteration 3289, loss = 0.13713511\n",
      "Iteration 3290, loss = 0.13704605\n",
      "Iteration 3291, loss = 0.13695710\n",
      "Iteration 3292, loss = 0.13686827\n",
      "Iteration 3293, loss = 0.13677955\n",
      "Iteration 3294, loss = 0.13669095\n",
      "Iteration 3295, loss = 0.13660248\n",
      "Iteration 3296, loss = 0.13651426\n",
      "Iteration 3297, loss = 0.13642626\n",
      "Iteration 3298, loss = 0.13633840\n",
      "Iteration 3299, loss = 0.13625067\n",
      "Iteration 3300, loss = 0.13616306\n",
      "Iteration 3301, loss = 0.13607559\n",
      "Iteration 3302, loss = 0.13598825\n",
      "Iteration 3303, loss = 0.13590103\n",
      "Iteration 3304, loss = 0.13581416\n",
      "Iteration 3305, loss = 0.13572746\n",
      "Iteration 3306, loss = 0.13564089\n",
      "Iteration 3307, loss = 0.13555451\n",
      "Iteration 3308, loss = 0.13546831\n",
      "Iteration 3309, loss = 0.13538222\n",
      "Iteration 3310, loss = 0.13529627\n",
      "Iteration 3311, loss = 0.13521045\n",
      "Iteration 3312, loss = 0.13512475\n",
      "Iteration 3313, loss = 0.13503919\n",
      "Iteration 3314, loss = 0.13495376\n",
      "Iteration 3315, loss = 0.13486846\n",
      "Iteration 3316, loss = 0.13478328\n",
      "Iteration 3317, loss = 0.13469824\n",
      "Iteration 3318, loss = 0.13461334\n",
      "Iteration 3319, loss = 0.13452856\n",
      "Iteration 3320, loss = 0.13444386\n",
      "Iteration 3321, loss = 0.13435920\n",
      "Iteration 3322, loss = 0.13427466\n",
      "Iteration 3323, loss = 0.13419023\n",
      "Iteration 3324, loss = 0.13410593\n",
      "Iteration 3325, loss = 0.13402174\n",
      "Iteration 3326, loss = 0.13393768\n",
      "Iteration 3327, loss = 0.13385374\n",
      "Iteration 3328, loss = 0.13376992\n",
      "Iteration 3329, loss = 0.13368622\n",
      "Iteration 3330, loss = 0.13360264\n",
      "Iteration 3331, loss = 0.13351931\n",
      "Iteration 3332, loss = 0.13343609\n",
      "Iteration 3333, loss = 0.13335303\n",
      "Iteration 3334, loss = 0.13327007\n",
      "Iteration 3335, loss = 0.13318721\n",
      "Iteration 3336, loss = 0.13310444\n",
      "Iteration 3337, loss = 0.13302177\n",
      "Iteration 3338, loss = 0.13293929\n",
      "Iteration 3339, loss = 0.13285693\n",
      "Iteration 3340, loss = 0.13277471\n",
      "Iteration 3341, loss = 0.13269263\n",
      "Iteration 3342, loss = 0.13261073\n",
      "Iteration 3343, loss = 0.13252895\n",
      "Iteration 3344, loss = 0.13244729\n",
      "Iteration 3345, loss = 0.13236574\n",
      "Iteration 3346, loss = 0.13228431\n",
      "Iteration 3347, loss = 0.13220301\n",
      "Iteration 3348, loss = 0.13212188\n",
      "Iteration 3349, loss = 0.13204088\n",
      "Iteration 3350, loss = 0.13196000\n",
      "Iteration 3351, loss = 0.13187926\n",
      "Iteration 3352, loss = 0.13179864\n",
      "Iteration 3353, loss = 0.13171817\n",
      "Iteration 3354, loss = 0.13163786\n",
      "Iteration 3355, loss = 0.13155768\n",
      "Iteration 3356, loss = 0.13147763\n",
      "Iteration 3357, loss = 0.13139772\n",
      "Iteration 3358, loss = 0.13131794\n",
      "Iteration 3359, loss = 0.13123829\n",
      "Iteration 3360, loss = 0.13115878\n",
      "Iteration 3361, loss = 0.13107939\n",
      "Iteration 3362, loss = 0.13100014\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 3363, loss = 0.13092102\n",
      "Iteration 3364, loss = 0.13084199\n",
      "Iteration 3365, loss = 0.13076302\n",
      "Iteration 3366, loss = 0.13068418\n",
      "Iteration 3367, loss = 0.13060545\n",
      "Iteration 3368, loss = 0.13052683\n",
      "Iteration 3369, loss = 0.13044836\n",
      "Iteration 3370, loss = 0.13037000\n",
      "Iteration 3371, loss = 0.13029177\n",
      "Iteration 3372, loss = 0.13021368\n",
      "Iteration 3373, loss = 0.13013571\n",
      "Iteration 3374, loss = 0.13005788\n",
      "Iteration 3375, loss = 0.12998016\n",
      "Iteration 3376, loss = 0.12990257\n",
      "Iteration 3377, loss = 0.12982512\n",
      "Iteration 3378, loss = 0.12974778\n",
      "Iteration 3379, loss = 0.12967057\n",
      "Iteration 3380, loss = 0.12959349\n",
      "Iteration 3381, loss = 0.12951653\n",
      "Iteration 3382, loss = 0.12943970\n",
      "Iteration 3383, loss = 0.12936300\n",
      "Iteration 3384, loss = 0.12928642\n",
      "Iteration 3385, loss = 0.12920997\n",
      "Iteration 3386, loss = 0.12913364\n",
      "Iteration 3387, loss = 0.12905743\n",
      "Iteration 3388, loss = 0.12898136\n",
      "Iteration 3389, loss = 0.12890540\n",
      "Iteration 3390, loss = 0.12882957\n",
      "Iteration 3391, loss = 0.12875386\n",
      "Iteration 3392, loss = 0.12867828\n",
      "Iteration 3393, loss = 0.12860282\n",
      "Iteration 3394, loss = 0.12852748\n",
      "Iteration 3395, loss = 0.12845227\n",
      "Iteration 3396, loss = 0.12837718\n",
      "Iteration 3397, loss = 0.12830221\n",
      "Iteration 3398, loss = 0.12822736\n",
      "Iteration 3399, loss = 0.12815263\n",
      "Iteration 3400, loss = 0.12807803\n",
      "Iteration 3401, loss = 0.12800354\n",
      "Iteration 3402, loss = 0.12792917\n",
      "Iteration 3403, loss = 0.12785492\n",
      "Iteration 3404, loss = 0.12778079\n",
      "Iteration 3405, loss = 0.12770678\n",
      "Iteration 3406, loss = 0.12763289\n",
      "Iteration 3407, loss = 0.12755907\n",
      "Iteration 3408, loss = 0.12748518\n",
      "Iteration 3409, loss = 0.12741138\n",
      "Iteration 3410, loss = 0.12733768\n",
      "Iteration 3411, loss = 0.12726410\n",
      "Iteration 3412, loss = 0.12719062\n",
      "Iteration 3413, loss = 0.12711725\n",
      "Iteration 3414, loss = 0.12704399\n",
      "Iteration 3415, loss = 0.12697083\n",
      "Iteration 3416, loss = 0.12689777\n",
      "Iteration 3417, loss = 0.12682482\n",
      "Iteration 3418, loss = 0.12675198\n",
      "Iteration 3419, loss = 0.12667924\n",
      "Iteration 3420, loss = 0.12660661\n",
      "Iteration 3421, loss = 0.12653408\n",
      "Iteration 3422, loss = 0.12646166\n",
      "Iteration 3423, loss = 0.12638934\n",
      "Iteration 3424, loss = 0.12631713\n",
      "Iteration 3425, loss = 0.12624502\n",
      "Iteration 3426, loss = 0.12617302\n",
      "Iteration 3427, loss = 0.12610113\n",
      "Iteration 3428, loss = 0.12602933\n",
      "Iteration 3429, loss = 0.12595765\n",
      "Iteration 3430, loss = 0.12588606\n",
      "Iteration 3431, loss = 0.12581458\n",
      "Iteration 3432, loss = 0.12574320\n",
      "Iteration 3433, loss = 0.12567193\n",
      "Iteration 3434, loss = 0.12560076\n",
      "Iteration 3435, loss = 0.12552969\n",
      "Iteration 3436, loss = 0.12545872\n",
      "Iteration 3437, loss = 0.12538785\n",
      "Iteration 3438, loss = 0.12531709\n",
      "Iteration 3439, loss = 0.12524642\n",
      "Iteration 3440, loss = 0.12517586\n",
      "Iteration 3441, loss = 0.12510539\n",
      "Iteration 3442, loss = 0.12503503\n",
      "Iteration 3443, loss = 0.12496476\n",
      "Iteration 3444, loss = 0.12489459\n",
      "Iteration 3445, loss = 0.12482452\n",
      "Iteration 3446, loss = 0.12475455\n",
      "Iteration 3447, loss = 0.12468467\n",
      "Iteration 3448, loss = 0.12461490\n",
      "Iteration 3449, loss = 0.12454537\n",
      "Iteration 3450, loss = 0.12447620\n",
      "Iteration 3451, loss = 0.12440712\n",
      "Iteration 3452, loss = 0.12433813\n",
      "Iteration 3453, loss = 0.12426923\n",
      "Iteration 3454, loss = 0.12420042\n",
      "Iteration 3455, loss = 0.12413170\n",
      "Iteration 3456, loss = 0.12406307\n",
      "Iteration 3457, loss = 0.12399455\n",
      "Iteration 3458, loss = 0.12392612\n",
      "Iteration 3459, loss = 0.12385780\n",
      "Iteration 3460, loss = 0.12378958\n",
      "Iteration 3461, loss = 0.12372147\n",
      "Iteration 3462, loss = 0.12365346\n",
      "Iteration 3463, loss = 0.12358557\n",
      "Iteration 3464, loss = 0.12351779\n",
      "Iteration 3465, loss = 0.12345013\n",
      "Iteration 3466, loss = 0.12338257\n",
      "Iteration 3467, loss = 0.12331513\n",
      "Iteration 3468, loss = 0.12324780\n",
      "Iteration 3469, loss = 0.12318058\n",
      "Iteration 3470, loss = 0.12311348\n",
      "Iteration 3471, loss = 0.12304649\n",
      "Iteration 3472, loss = 0.12297961\n",
      "Iteration 3473, loss = 0.12291284\n",
      "Iteration 3474, loss = 0.12284618\n",
      "Iteration 3475, loss = 0.12277964\n",
      "Iteration 3476, loss = 0.12271320\n",
      "Iteration 3477, loss = 0.12264688\n",
      "Iteration 3478, loss = 0.12258067\n",
      "Iteration 3479, loss = 0.12251457\n",
      "Iteration 3480, loss = 0.12244858\n",
      "Iteration 3481, loss = 0.12238270\n",
      "Iteration 3482, loss = 0.12231695\n",
      "Iteration 3483, loss = 0.12225132\n",
      "Iteration 3484, loss = 0.12218580\n",
      "Iteration 3485, loss = 0.12212038\n",
      "Iteration 3486, loss = 0.12205489\n",
      "Iteration 3487, loss = 0.12198950\n",
      "Iteration 3488, loss = 0.12192420\n",
      "Iteration 3489, loss = 0.12185900\n",
      "Iteration 3490, loss = 0.12179390\n",
      "Iteration 3491, loss = 0.12172875\n",
      "Iteration 3492, loss = 0.12166360\n",
      "Iteration 3493, loss = 0.12159853\n",
      "Iteration 3494, loss = 0.12153354\n",
      "Iteration 3495, loss = 0.12146863\n",
      "Iteration 3496, loss = 0.12140381\n",
      "Iteration 3497, loss = 0.12133906\n",
      "Iteration 3498, loss = 0.12127441\n",
      "Iteration 3499, loss = 0.12120984\n",
      "Iteration 3500, loss = 0.12114536\n",
      "Iteration 3501, loss = 0.12108098\n",
      "Iteration 3502, loss = 0.12101668\n",
      "Iteration 3503, loss = 0.12095247\n",
      "Iteration 3504, loss = 0.12088835\n",
      "Iteration 3505, loss = 0.12082432\n",
      "Iteration 3506, loss = 0.12076039\n",
      "Iteration 3507, loss = 0.12069654\n",
      "Iteration 3508, loss = 0.12063279\n",
      "Iteration 3509, loss = 0.12056914\n",
      "Iteration 3510, loss = 0.12050557\n",
      "Iteration 3511, loss = 0.12044210\n",
      "Iteration 3512, loss = 0.12037871\n",
      "Iteration 3513, loss = 0.12031542\n",
      "Iteration 3514, loss = 0.12025223\n",
      "Iteration 3515, loss = 0.12018912\n",
      "Iteration 3516, loss = 0.12012610\n",
      "Iteration 3517, loss = 0.12006318\n",
      "Iteration 3518, loss = 0.12000035\n",
      "Iteration 3519, loss = 0.11993760\n",
      "Iteration 3520, loss = 0.11987495\n",
      "Iteration 3521, loss = 0.11981239\n",
      "Iteration 3522, loss = 0.11974991\n",
      "Iteration 3523, loss = 0.11968753\n",
      "Iteration 3524, loss = 0.11962524\n",
      "Iteration 3525, loss = 0.11956303\n",
      "Iteration 3526, loss = 0.11950091\n",
      "Iteration 3527, loss = 0.11943888\n",
      "Iteration 3528, loss = 0.11937694\n",
      "Iteration 3529, loss = 0.11931508\n",
      "Iteration 3530, loss = 0.11925331\n",
      "Iteration 3531, loss = 0.11919163\n",
      "Iteration 3532, loss = 0.11913004\n",
      "Iteration 3533, loss = 0.11906855\n",
      "Iteration 3534, loss = 0.11900714\n",
      "Iteration 3535, loss = 0.11894582\n",
      "Iteration 3536, loss = 0.11888459\n",
      "Iteration 3537, loss = 0.11882344\n",
      "Iteration 3538, loss = 0.11876238\n",
      "Iteration 3539, loss = 0.11870140\n",
      "Iteration 3540, loss = 0.11864050\n",
      "Iteration 3541, loss = 0.11857969\n",
      "Iteration 3542, loss = 0.11851896\n",
      "Iteration 3543, loss = 0.11845831\n",
      "Iteration 3544, loss = 0.11839775\n",
      "Iteration 3545, loss = 0.11833726\n",
      "Iteration 3546, loss = 0.11827686\n",
      "Iteration 3547, loss = 0.11821654\n",
      "Iteration 3548, loss = 0.11815630\n",
      "Iteration 3549, loss = 0.11809626\n",
      "Iteration 3550, loss = 0.11803638\n",
      "Iteration 3551, loss = 0.11797658\n",
      "Iteration 3552, loss = 0.11791687\n",
      "Iteration 3553, loss = 0.11785726\n",
      "Iteration 3554, loss = 0.11779773\n",
      "Iteration 3555, loss = 0.11773828\n",
      "Iteration 3556, loss = 0.11767893\n",
      "Iteration 3557, loss = 0.11761966\n",
      "Iteration 3558, loss = 0.11756048\n",
      "Iteration 3559, loss = 0.11750138\n",
      "Iteration 3560, loss = 0.11744238\n",
      "Iteration 3561, loss = 0.11738345\n",
      "Iteration 3562, loss = 0.11732461\n",
      "Iteration 3563, loss = 0.11726586\n",
      "Iteration 3564, loss = 0.11720719\n",
      "Iteration 3565, loss = 0.11714860\n",
      "Iteration 3566, loss = 0.11709010\n",
      "Iteration 3567, loss = 0.11703168\n",
      "Iteration 3568, loss = 0.11697335\n",
      "Iteration 3569, loss = 0.11691509\n",
      "Iteration 3570, loss = 0.11685692\n",
      "Iteration 3571, loss = 0.11679883\n",
      "Iteration 3572, loss = 0.11674082\n",
      "Iteration 3573, loss = 0.11668289\n",
      "Iteration 3574, loss = 0.11662504\n",
      "Iteration 3575, loss = 0.11656727\n",
      "Iteration 3576, loss = 0.11650958\n",
      "Iteration 3577, loss = 0.11645197\n",
      "Iteration 3578, loss = 0.11639444\n",
      "Iteration 3579, loss = 0.11633699\n",
      "Iteration 3580, loss = 0.11627962\n",
      "Iteration 3581, loss = 0.11622232\n",
      "Iteration 3582, loss = 0.11616510\n",
      "Iteration 3583, loss = 0.11610796\n",
      "Iteration 3584, loss = 0.11605089\n",
      "Iteration 3585, loss = 0.11599390\n",
      "Iteration 3586, loss = 0.11593700\n",
      "Iteration 3587, loss = 0.11588020\n",
      "Iteration 3588, loss = 0.11582348\n",
      "Iteration 3589, loss = 0.11576683\n",
      "Iteration 3590, loss = 0.11571026\n",
      "Iteration 3591, loss = 0.11565377\n",
      "Iteration 3592, loss = 0.11559737\n",
      "Iteration 3593, loss = 0.11554107\n",
      "Iteration 3594, loss = 0.11548482\n",
      "Iteration 3595, loss = 0.11542865\n",
      "Iteration 3596, loss = 0.11537255\n",
      "Iteration 3597, loss = 0.11531659\n",
      "Iteration 3598, loss = 0.11526087\n",
      "Iteration 3599, loss = 0.11520523\n",
      "Iteration 3600, loss = 0.11514960\n",
      "Iteration 3601, loss = 0.11509405\n",
      "Iteration 3602, loss = 0.11503856\n",
      "Iteration 3603, loss = 0.11498316\n",
      "Iteration 3604, loss = 0.11492783\n",
      "Iteration 3605, loss = 0.11487258\n",
      "Iteration 3606, loss = 0.11481740\n",
      "Iteration 3607, loss = 0.11476231\n",
      "Iteration 3608, loss = 0.11470733\n",
      "Iteration 3609, loss = 0.11465242\n",
      "Iteration 3610, loss = 0.11459759\n",
      "Iteration 3611, loss = 0.11454284\n",
      "Iteration 3612, loss = 0.11448817\n",
      "Iteration 3613, loss = 0.11443357\n",
      "Iteration 3614, loss = 0.11437906\n",
      "Iteration 3615, loss = 0.11432462\n",
      "Iteration 3616, loss = 0.11427026\n",
      "Iteration 3617, loss = 0.11421597\n",
      "Iteration 3618, loss = 0.11416177\n",
      "Iteration 3619, loss = 0.11410763\n",
      "Iteration 3620, loss = 0.11405358\n",
      "Iteration 3621, loss = 0.11399960\n",
      "Iteration 3622, loss = 0.11394570\n",
      "Iteration 3623, loss = 0.11389187\n",
      "Iteration 3624, loss = 0.11383812\n",
      "Iteration 3625, loss = 0.11378445\n",
      "Iteration 3626, loss = 0.11373085\n",
      "Iteration 3627, loss = 0.11367732\n",
      "Iteration 3628, loss = 0.11362387\n",
      "Iteration 3629, loss = 0.11357049\n",
      "Iteration 3630, loss = 0.11351719\n",
      "Iteration 3631, loss = 0.11346396\n",
      "Iteration 3632, loss = 0.11341080\n",
      "Iteration 3633, loss = 0.11335772\n",
      "Iteration 3634, loss = 0.11330473\n",
      "Iteration 3635, loss = 0.11325181\n",
      "Iteration 3636, loss = 0.11319896\n",
      "Iteration 3637, loss = 0.11314619\n",
      "Iteration 3638, loss = 0.11309349\n",
      "Iteration 3639, loss = 0.11304086\n",
      "Iteration 3640, loss = 0.11298830\n",
      "Iteration 3641, loss = 0.11293581\n",
      "Iteration 3642, loss = 0.11288339\n",
      "Iteration 3643, loss = 0.11283104\n",
      "Iteration 3644, loss = 0.11277876\n",
      "Iteration 3645, loss = 0.11272655\n",
      "Iteration 3646, loss = 0.11267441\n",
      "Iteration 3647, loss = 0.11262233\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 3648, loss = 0.11257032\n",
      "Iteration 3649, loss = 0.11251838\n",
      "Iteration 3650, loss = 0.11246651\n",
      "Iteration 3651, loss = 0.11241470\n",
      "Iteration 3652, loss = 0.11236296\n",
      "Iteration 3653, loss = 0.11231128\n",
      "Iteration 3654, loss = 0.11225967\n",
      "Iteration 3655, loss = 0.11220812\n",
      "Iteration 3656, loss = 0.11215664\n",
      "Iteration 3657, loss = 0.11210522\n",
      "Iteration 3658, loss = 0.11205387\n",
      "Iteration 3659, loss = 0.11200259\n",
      "Iteration 3660, loss = 0.11195137\n",
      "Iteration 3661, loss = 0.11190021\n",
      "Iteration 3662, loss = 0.11184912\n",
      "Iteration 3663, loss = 0.11179809\n",
      "Iteration 3664, loss = 0.11174712\n",
      "Iteration 3665, loss = 0.11169622\n",
      "Iteration 3666, loss = 0.11164537\n",
      "Iteration 3667, loss = 0.11159459\n",
      "Iteration 3668, loss = 0.11154386\n",
      "Iteration 3669, loss = 0.11149320\n",
      "Iteration 3670, loss = 0.11144260\n",
      "Iteration 3671, loss = 0.11139206\n",
      "Iteration 3672, loss = 0.11134158\n",
      "Iteration 3673, loss = 0.11129116\n",
      "Iteration 3674, loss = 0.11124082\n",
      "Iteration 3675, loss = 0.11119053\n",
      "Iteration 3676, loss = 0.11114019\n",
      "Iteration 3677, loss = 0.11108988\n",
      "Iteration 3678, loss = 0.11103962\n",
      "Iteration 3679, loss = 0.11098941\n",
      "Iteration 3680, loss = 0.11093924\n",
      "Iteration 3681, loss = 0.11088911\n",
      "Iteration 3682, loss = 0.11083904\n",
      "Iteration 3683, loss = 0.11078902\n",
      "Iteration 3684, loss = 0.11073908\n",
      "Iteration 3685, loss = 0.11068919\n",
      "Iteration 3686, loss = 0.11063935\n",
      "Iteration 3687, loss = 0.11058956\n",
      "Iteration 3688, loss = 0.11053982\n",
      "Iteration 3689, loss = 0.11049014\n",
      "Iteration 3690, loss = 0.11044050\n",
      "Iteration 3691, loss = 0.11039092\n",
      "Iteration 3692, loss = 0.11034139\n",
      "Iteration 3693, loss = 0.11029190\n",
      "Iteration 3694, loss = 0.11024247\n",
      "Iteration 3695, loss = 0.11019306\n",
      "Iteration 3696, loss = 0.11014369\n",
      "Iteration 3697, loss = 0.11009437\n",
      "Iteration 3698, loss = 0.11004509\n",
      "Iteration 3699, loss = 0.10999586\n",
      "Iteration 3700, loss = 0.10994668\n",
      "Iteration 3701, loss = 0.10989754\n",
      "Iteration 3702, loss = 0.10984846\n",
      "Iteration 3703, loss = 0.10979942\n",
      "Iteration 3704, loss = 0.10975043\n",
      "Iteration 3705, loss = 0.10970149\n",
      "Iteration 3706, loss = 0.10965259\n",
      "Iteration 3707, loss = 0.10960375\n",
      "Iteration 3708, loss = 0.10955495\n",
      "Iteration 3709, loss = 0.10950620\n",
      "Iteration 3710, loss = 0.10945752\n",
      "Iteration 3711, loss = 0.10940905\n",
      "Iteration 3712, loss = 0.10936064\n",
      "Iteration 3713, loss = 0.10931231\n",
      "Iteration 3714, loss = 0.10926404\n",
      "Iteration 3715, loss = 0.10921583\n",
      "Iteration 3716, loss = 0.10916775\n",
      "Iteration 3717, loss = 0.10911976\n",
      "Iteration 3718, loss = 0.10907183\n",
      "Iteration 3719, loss = 0.10902397\n",
      "Iteration 3720, loss = 0.10897616\n",
      "Iteration 3721, loss = 0.10892841\n",
      "Iteration 3722, loss = 0.10888072\n",
      "Iteration 3723, loss = 0.10883309\n",
      "Iteration 3724, loss = 0.10878552\n",
      "Iteration 3725, loss = 0.10873800\n",
      "Iteration 3726, loss = 0.10869053\n",
      "Iteration 3727, loss = 0.10864312\n",
      "Iteration 3728, loss = 0.10859576\n",
      "Iteration 3729, loss = 0.10854846\n",
      "Iteration 3730, loss = 0.10850124\n",
      "Iteration 3731, loss = 0.10845413\n",
      "Iteration 3732, loss = 0.10840708\n",
      "Iteration 3733, loss = 0.10836001\n",
      "Iteration 3734, loss = 0.10831298\n",
      "Iteration 3735, loss = 0.10826601\n",
      "Iteration 3736, loss = 0.10821908\n",
      "Iteration 3737, loss = 0.10817221\n",
      "Iteration 3738, loss = 0.10812544\n",
      "Iteration 3739, loss = 0.10807874\n",
      "Iteration 3740, loss = 0.10803208\n",
      "Iteration 3741, loss = 0.10798548\n",
      "Iteration 3742, loss = 0.10793893\n",
      "Iteration 3743, loss = 0.10789243\n",
      "Iteration 3744, loss = 0.10784598\n",
      "Iteration 3745, loss = 0.10779959\n",
      "Iteration 3746, loss = 0.10775325\n",
      "Iteration 3747, loss = 0.10770694\n",
      "Iteration 3748, loss = 0.10766069\n",
      "Iteration 3749, loss = 0.10761448\n",
      "Iteration 3750, loss = 0.10756831\n",
      "Iteration 3751, loss = 0.10752220\n",
      "Iteration 3752, loss = 0.10747613\n",
      "Iteration 3753, loss = 0.10743011\n",
      "Iteration 3754, loss = 0.10738414\n",
      "Iteration 3755, loss = 0.10733821\n",
      "Iteration 3756, loss = 0.10729233\n",
      "Iteration 3757, loss = 0.10724650\n",
      "Iteration 3758, loss = 0.10720071\n",
      "Iteration 3759, loss = 0.10715497\n",
      "Iteration 3760, loss = 0.10710928\n",
      "Iteration 3761, loss = 0.10706363\n",
      "Iteration 3762, loss = 0.10701803\n",
      "Iteration 3763, loss = 0.10697247\n",
      "Iteration 3764, loss = 0.10692696\n",
      "Iteration 3765, loss = 0.10688150\n",
      "Iteration 3766, loss = 0.10683608\n",
      "Iteration 3767, loss = 0.10679070\n",
      "Iteration 3768, loss = 0.10674537\n",
      "Iteration 3769, loss = 0.10670009\n",
      "Iteration 3770, loss = 0.10665485\n",
      "Iteration 3771, loss = 0.10660965\n",
      "Iteration 3772, loss = 0.10656450\n",
      "Iteration 3773, loss = 0.10651939\n",
      "Iteration 3774, loss = 0.10647433\n",
      "Iteration 3775, loss = 0.10642931\n",
      "Iteration 3776, loss = 0.10638434\n",
      "Iteration 3777, loss = 0.10633940\n",
      "Iteration 3778, loss = 0.10629453\n",
      "Iteration 3779, loss = 0.10624969\n",
      "Iteration 3780, loss = 0.10620490\n",
      "Iteration 3781, loss = 0.10616016\n",
      "Iteration 3782, loss = 0.10611545\n",
      "Iteration 3783, loss = 0.10607077\n",
      "Iteration 3784, loss = 0.10602614\n",
      "Iteration 3785, loss = 0.10598155\n",
      "Iteration 3786, loss = 0.10593700\n",
      "Iteration 3787, loss = 0.10589249\n",
      "Iteration 3788, loss = 0.10584803\n",
      "Iteration 3789, loss = 0.10580360\n",
      "Iteration 3790, loss = 0.10575922\n",
      "Iteration 3791, loss = 0.10571488\n",
      "Iteration 3792, loss = 0.10567059\n",
      "Iteration 3793, loss = 0.10562633\n",
      "Iteration 3794, loss = 0.10558211\n",
      "Iteration 3795, loss = 0.10553796\n",
      "Iteration 3796, loss = 0.10549388\n",
      "Iteration 3797, loss = 0.10544985\n",
      "Iteration 3798, loss = 0.10540587\n",
      "Iteration 3799, loss = 0.10536193\n",
      "Iteration 3800, loss = 0.10531804\n",
      "Iteration 3801, loss = 0.10527419\n",
      "Iteration 3802, loss = 0.10523038\n",
      "Iteration 3803, loss = 0.10518662\n",
      "Iteration 3804, loss = 0.10514290\n",
      "Iteration 3805, loss = 0.10509922\n",
      "Iteration 3806, loss = 0.10505559\n",
      "Iteration 3807, loss = 0.10501199\n",
      "Iteration 3808, loss = 0.10496844\n",
      "Iteration 3809, loss = 0.10492493\n",
      "Iteration 3810, loss = 0.10488146\n",
      "Iteration 3811, loss = 0.10483804\n",
      "Iteration 3812, loss = 0.10479467\n",
      "Iteration 3813, loss = 0.10475136\n",
      "Iteration 3814, loss = 0.10470809\n",
      "Iteration 3815, loss = 0.10466486\n",
      "Iteration 3816, loss = 0.10462167\n",
      "Iteration 3817, loss = 0.10457852\n",
      "Iteration 3818, loss = 0.10453541\n",
      "Iteration 3819, loss = 0.10449234\n",
      "Iteration 3820, loss = 0.10444931\n",
      "Iteration 3821, loss = 0.10440632\n",
      "Iteration 3822, loss = 0.10436338\n",
      "Iteration 3823, loss = 0.10432043\n",
      "Iteration 3824, loss = 0.10427745\n",
      "Iteration 3825, loss = 0.10423450\n",
      "Iteration 3826, loss = 0.10419158\n",
      "Iteration 3827, loss = 0.10414869\n",
      "Iteration 3828, loss = 0.10410584\n",
      "Iteration 3829, loss = 0.10406301\n",
      "Iteration 3830, loss = 0.10402022\n",
      "Iteration 3831, loss = 0.10397746\n",
      "Iteration 3832, loss = 0.10393473\n",
      "Iteration 3833, loss = 0.10389204\n",
      "Iteration 3834, loss = 0.10384938\n",
      "Iteration 3835, loss = 0.10380676\n",
      "Iteration 3836, loss = 0.10376417\n",
      "Iteration 3837, loss = 0.10372162\n",
      "Iteration 3838, loss = 0.10367910\n",
      "Iteration 3839, loss = 0.10363662\n",
      "Iteration 3840, loss = 0.10359417\n",
      "Iteration 3841, loss = 0.10355176\n",
      "Iteration 3842, loss = 0.10350938\n",
      "Iteration 3843, loss = 0.10346704\n",
      "Iteration 3844, loss = 0.10342474\n",
      "Iteration 3845, loss = 0.10338247\n",
      "Iteration 3846, loss = 0.10334023\n",
      "Iteration 3847, loss = 0.10329803\n",
      "Iteration 3848, loss = 0.10325587\n",
      "Iteration 3849, loss = 0.10321374\n",
      "Iteration 3850, loss = 0.10317165\n",
      "Iteration 3851, loss = 0.10312960\n",
      "Iteration 3852, loss = 0.10308758\n",
      "Iteration 3853, loss = 0.10304560\n",
      "Iteration 3854, loss = 0.10300365\n",
      "Iteration 3855, loss = 0.10296199\n",
      "Iteration 3856, loss = 0.10292038\n",
      "Iteration 3857, loss = 0.10287883\n",
      "Iteration 3858, loss = 0.10283732\n",
      "Iteration 3859, loss = 0.10279586\n",
      "Iteration 3860, loss = 0.10275444\n",
      "Iteration 3861, loss = 0.10271308\n",
      "Iteration 3862, loss = 0.10267175\n",
      "Iteration 3863, loss = 0.10263047\n",
      "Iteration 3864, loss = 0.10258923\n",
      "Iteration 3865, loss = 0.10254803\n",
      "Iteration 3866, loss = 0.10250687\n",
      "Iteration 3867, loss = 0.10246576\n",
      "Iteration 3868, loss = 0.10242468\n",
      "Iteration 3869, loss = 0.10238364\n",
      "Iteration 3870, loss = 0.10234265\n",
      "Iteration 3871, loss = 0.10230169\n",
      "Iteration 3872, loss = 0.10226076\n",
      "Iteration 3873, loss = 0.10221988\n",
      "Iteration 3874, loss = 0.10217903\n",
      "Iteration 3875, loss = 0.10213822\n",
      "Iteration 3876, loss = 0.10209745\n",
      "Iteration 3877, loss = 0.10205671\n",
      "Iteration 3878, loss = 0.10201601\n",
      "Iteration 3879, loss = 0.10197534\n",
      "Iteration 3880, loss = 0.10193472\n",
      "Iteration 3881, loss = 0.10189413\n",
      "Iteration 3882, loss = 0.10185359\n",
      "Iteration 3883, loss = 0.10181308\n",
      "Iteration 3884, loss = 0.10177261\n",
      "Iteration 3885, loss = 0.10173217\n",
      "Iteration 3886, loss = 0.10169177\n",
      "Iteration 3887, loss = 0.10165140\n",
      "Iteration 3888, loss = 0.10161107\n",
      "Iteration 3889, loss = 0.10157078\n",
      "Iteration 3890, loss = 0.10153060\n",
      "Iteration 3891, loss = 0.10149049\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 3892, loss = 0.10145042\n",
      "Iteration 3893, loss = 0.10141039\n",
      "Iteration 3894, loss = 0.10137041\n",
      "Iteration 3895, loss = 0.10133046\n",
      "Iteration 3896, loss = 0.10129056\n",
      "Iteration 3897, loss = 0.10125081\n",
      "Iteration 3898, loss = 0.10121110\n",
      "Iteration 3899, loss = 0.10117144\n",
      "Iteration 3900, loss = 0.10113182\n",
      "Iteration 3901, loss = 0.10109225\n",
      "Iteration 3902, loss = 0.10105271\n",
      "Iteration 3903, loss = 0.10101323\n",
      "Iteration 3904, loss = 0.10097378\n",
      "Iteration 3905, loss = 0.10093438\n",
      "Iteration 3906, loss = 0.10089501\n",
      "Iteration 3907, loss = 0.10085568\n",
      "Iteration 3908, loss = 0.10081639\n",
      "Iteration 3909, loss = 0.10077714\n",
      "Iteration 3910, loss = 0.10073792\n",
      "Iteration 3911, loss = 0.10069874\n",
      "Iteration 3912, loss = 0.10065959\n",
      "Iteration 3913, loss = 0.10062048\n",
      "Iteration 3914, loss = 0.10058140\n",
      "Iteration 3915, loss = 0.10054236\n",
      "Iteration 3916, loss = 0.10050335\n",
      "Iteration 3917, loss = 0.10046438\n",
      "Iteration 3918, loss = 0.10042544\n",
      "Iteration 3919, loss = 0.10038653\n",
      "Iteration 3920, loss = 0.10034765\n",
      "Iteration 3921, loss = 0.10030881\n",
      "Iteration 3922, loss = 0.10027000\n",
      "Iteration 3923, loss = 0.10023121\n",
      "Iteration 3924, loss = 0.10019243\n",
      "Iteration 3925, loss = 0.10015368\n",
      "Iteration 3926, loss = 0.10011496\n",
      "Iteration 3927, loss = 0.10007628\n",
      "Iteration 3928, loss = 0.10003762\n",
      "Iteration 3929, loss = 0.09999899\n",
      "Iteration 3930, loss = 0.09996039\n",
      "Iteration 3931, loss = 0.09992222\n",
      "Iteration 3932, loss = 0.09988412\n",
      "Iteration 3933, loss = 0.09984608\n",
      "Iteration 3934, loss = 0.09980809\n",
      "Iteration 3935, loss = 0.09977014\n",
      "Iteration 3936, loss = 0.09973225\n",
      "Iteration 3937, loss = 0.09969440\n",
      "Iteration 3938, loss = 0.09965659\n",
      "Iteration 3939, loss = 0.09961883\n",
      "Iteration 3940, loss = 0.09958111\n",
      "Iteration 3941, loss = 0.09954343\n",
      "Iteration 3942, loss = 0.09950580\n",
      "Iteration 3943, loss = 0.09946820\n",
      "Iteration 3944, loss = 0.09943064\n",
      "Iteration 3945, loss = 0.09939312\n",
      "Iteration 3946, loss = 0.09935564\n",
      "Iteration 3947, loss = 0.09931820\n",
      "Iteration 3948, loss = 0.09928079\n",
      "Iteration 3949, loss = 0.09924342\n",
      "Iteration 3950, loss = 0.09920609\n",
      "Iteration 3951, loss = 0.09916879\n",
      "Iteration 3952, loss = 0.09913153\n",
      "Iteration 3953, loss = 0.09909430\n",
      "Iteration 3954, loss = 0.09905711\n",
      "Iteration 3955, loss = 0.09901995\n",
      "Iteration 3956, loss = 0.09898282\n",
      "Iteration 3957, loss = 0.09894573\n",
      "Iteration 3958, loss = 0.09890867\n",
      "Iteration 3959, loss = 0.09887165\n",
      "Iteration 3960, loss = 0.09883465\n",
      "Iteration 3961, loss = 0.09879770\n",
      "Iteration 3962, loss = 0.09876077\n",
      "Iteration 3963, loss = 0.09872388\n",
      "Iteration 3964, loss = 0.09868701\n",
      "Iteration 3965, loss = 0.09865018\n",
      "Iteration 3966, loss = 0.09861339\n",
      "Iteration 3967, loss = 0.09857662\n",
      "Iteration 3968, loss = 0.09853988\n",
      "Iteration 3969, loss = 0.09850318\n",
      "Iteration 3970, loss = 0.09846651\n",
      "Iteration 3971, loss = 0.09842987\n",
      "Iteration 3972, loss = 0.09839326\n",
      "Iteration 3973, loss = 0.09835668\n",
      "Iteration 3974, loss = 0.09832013\n",
      "Iteration 3975, loss = 0.09828361\n",
      "Iteration 3976, loss = 0.09824711\n",
      "Iteration 3977, loss = 0.09821065\n",
      "Iteration 3978, loss = 0.09817422\n",
      "Iteration 3979, loss = 0.09813782\n",
      "Iteration 3980, loss = 0.09810144\n",
      "Iteration 3981, loss = 0.09806510\n",
      "Iteration 3982, loss = 0.09802879\n",
      "Iteration 3983, loss = 0.09799250\n",
      "Iteration 3984, loss = 0.09795625\n",
      "Iteration 3985, loss = 0.09792002\n",
      "Iteration 3986, loss = 0.09788382\n",
      "Iteration 3987, loss = 0.09784766\n",
      "Iteration 3988, loss = 0.09781152\n",
      "Iteration 3989, loss = 0.09777544\n",
      "Iteration 3990, loss = 0.09773995\n",
      "Iteration 3991, loss = 0.09770453\n",
      "Iteration 3992, loss = 0.09766918\n",
      "Iteration 3993, loss = 0.09763389\n",
      "Iteration 3994, loss = 0.09759866\n",
      "Iteration 3995, loss = 0.09756349\n",
      "Iteration 3996, loss = 0.09752837\n",
      "Iteration 3997, loss = 0.09749329\n",
      "Iteration 3998, loss = 0.09745827\n",
      "Iteration 3999, loss = 0.09742328\n",
      "Iteration 4000, loss = 0.09738835\n",
      "Iteration 4001, loss = 0.09735345\n",
      "Iteration 4002, loss = 0.09731859\n",
      "Iteration 4003, loss = 0.09728377\n",
      "Iteration 4004, loss = 0.09724899\n",
      "Iteration 4005, loss = 0.09721424\n",
      "Iteration 4006, loss = 0.09717953\n",
      "Iteration 4007, loss = 0.09714486\n",
      "Iteration 4008, loss = 0.09711021\n",
      "Iteration 4009, loss = 0.09707560\n",
      "Iteration 4010, loss = 0.09704102\n",
      "Iteration 4011, loss = 0.09700647\n",
      "Iteration 4012, loss = 0.09697195\n",
      "Iteration 4013, loss = 0.09693746\n",
      "Iteration 4014, loss = 0.09690296\n",
      "Iteration 4015, loss = 0.09686849\n",
      "Iteration 4016, loss = 0.09683404\n",
      "Iteration 4017, loss = 0.09679962\n",
      "Iteration 4018, loss = 0.09676522\n",
      "Iteration 4019, loss = 0.09673084\n",
      "Iteration 4020, loss = 0.09669649\n",
      "Iteration 4021, loss = 0.09666216\n",
      "Iteration 4022, loss = 0.09662786\n",
      "Iteration 4023, loss = 0.09659358\n",
      "Iteration 4024, loss = 0.09655933\n",
      "Iteration 4025, loss = 0.09652510\n",
      "Iteration 4026, loss = 0.09649089\n",
      "Iteration 4027, loss = 0.09645671\n",
      "Iteration 4028, loss = 0.09642255\n",
      "Iteration 4029, loss = 0.09638841\n",
      "Iteration 4030, loss = 0.09635430\n",
      "Iteration 4031, loss = 0.09632021\n",
      "Iteration 4032, loss = 0.09628618\n",
      "Iteration 4033, loss = 0.09625218\n",
      "Iteration 4034, loss = 0.09621820\n",
      "Iteration 4035, loss = 0.09618425\n",
      "Iteration 4036, loss = 0.09615033\n",
      "Iteration 4037, loss = 0.09611643\n",
      "Iteration 4038, loss = 0.09608256\n",
      "Iteration 4039, loss = 0.09604871\n",
      "Iteration 4040, loss = 0.09601489\n",
      "Iteration 4041, loss = 0.09598109\n",
      "Iteration 4042, loss = 0.09594731\n",
      "Iteration 4043, loss = 0.09591357\n",
      "Iteration 4044, loss = 0.09587984\n",
      "Iteration 4045, loss = 0.09584614\n",
      "Iteration 4046, loss = 0.09581246\n",
      "Iteration 4047, loss = 0.09577881\n",
      "Iteration 4048, loss = 0.09574518\n",
      "Iteration 4049, loss = 0.09571156\n",
      "Iteration 4050, loss = 0.09567797\n",
      "Iteration 4051, loss = 0.09564440\n",
      "Iteration 4052, loss = 0.09561086\n",
      "Iteration 4053, loss = 0.09557734\n",
      "Iteration 4054, loss = 0.09554384\n",
      "Iteration 4055, loss = 0.09551036\n",
      "Iteration 4056, loss = 0.09547689\n",
      "Iteration 4057, loss = 0.09544344\n",
      "Iteration 4058, loss = 0.09541001\n",
      "Iteration 4059, loss = 0.09537661\n",
      "Iteration 4060, loss = 0.09534323\n",
      "Iteration 4061, loss = 0.09530987\n",
      "Iteration 4062, loss = 0.09527654\n",
      "Iteration 4063, loss = 0.09524323\n",
      "Iteration 4064, loss = 0.09520999\n",
      "Iteration 4065, loss = 0.09517677\n",
      "Iteration 4066, loss = 0.09514358\n",
      "Iteration 4067, loss = 0.09511041\n",
      "Iteration 4068, loss = 0.09507726\n",
      "Iteration 4069, loss = 0.09504415\n",
      "Iteration 4070, loss = 0.09501105\n",
      "Iteration 4071, loss = 0.09497798\n",
      "Iteration 4072, loss = 0.09494493\n",
      "Iteration 4073, loss = 0.09491190\n",
      "Iteration 4074, loss = 0.09487890\n",
      "Iteration 4075, loss = 0.09484592\n",
      "Iteration 4076, loss = 0.09481297\n",
      "Iteration 4077, loss = 0.09478003\n",
      "Iteration 4078, loss = 0.09474712\n",
      "Iteration 4079, loss = 0.09471423\n",
      "Iteration 4080, loss = 0.09468136\n",
      "Iteration 4081, loss = 0.09464852\n",
      "Iteration 4082, loss = 0.09461571\n",
      "Iteration 4083, loss = 0.09458292\n",
      "Iteration 4084, loss = 0.09455015\n",
      "Iteration 4085, loss = 0.09451749\n",
      "Iteration 4086, loss = 0.09448487\n",
      "Iteration 4087, loss = 0.09445228\n",
      "Iteration 4088, loss = 0.09441962\n",
      "Iteration 4089, loss = 0.09438698\n",
      "Iteration 4090, loss = 0.09435436\n",
      "Iteration 4091, loss = 0.09432175\n",
      "Iteration 4092, loss = 0.09428917\n",
      "Iteration 4093, loss = 0.09425660\n",
      "Iteration 4094, loss = 0.09422406\n",
      "Iteration 4095, loss = 0.09419153\n",
      "Iteration 4096, loss = 0.09415902\n",
      "Iteration 4097, loss = 0.09412653\n",
      "Iteration 4098, loss = 0.09409407\n",
      "Iteration 4099, loss = 0.09406162\n",
      "Iteration 4100, loss = 0.09402919\n",
      "Iteration 4101, loss = 0.09399678\n",
      "Iteration 4102, loss = 0.09396438\n",
      "Iteration 4103, loss = 0.09393201\n",
      "Iteration 4104, loss = 0.09389966\n",
      "Iteration 4105, loss = 0.09386733\n",
      "Iteration 4106, loss = 0.09383503\n",
      "Iteration 4107, loss = 0.09380275\n",
      "Iteration 4108, loss = 0.09377049\n",
      "Iteration 4109, loss = 0.09373825\n",
      "Iteration 4110, loss = 0.09370603\n",
      "Iteration 4111, loss = 0.09367383\n",
      "Iteration 4112, loss = 0.09364166\n",
      "Iteration 4113, loss = 0.09360950\n",
      "Iteration 4114, loss = 0.09357736\n",
      "Iteration 4115, loss = 0.09354525\n",
      "Iteration 4116, loss = 0.09351330\n",
      "Iteration 4117, loss = 0.09348149\n",
      "Iteration 4118, loss = 0.09344972\n",
      "Iteration 4119, loss = 0.09341798\n",
      "Iteration 4120, loss = 0.09338628\n",
      "Iteration 4121, loss = 0.09335461\n",
      "Iteration 4122, loss = 0.09332297\n",
      "Iteration 4123, loss = 0.09329137\n",
      "Iteration 4124, loss = 0.09325979\n",
      "Iteration 4125, loss = 0.09322824\n",
      "Iteration 4126, loss = 0.09319672\n",
      "Iteration 4127, loss = 0.09316522\n",
      "Iteration 4128, loss = 0.09313375\n",
      "Iteration 4129, loss = 0.09310231\n",
      "Iteration 4130, loss = 0.09307089\n",
      "Iteration 4131, loss = 0.09303949\n",
      "Iteration 4132, loss = 0.09300811\n",
      "Iteration 4133, loss = 0.09297675\n",
      "Iteration 4134, loss = 0.09294542\n",
      "Iteration 4135, loss = 0.09291410\n",
      "Iteration 4136, loss = 0.09288281\n",
      "Iteration 4137, loss = 0.09285154\n",
      "Iteration 4138, loss = 0.09282029\n",
      "Iteration 4139, loss = 0.09278906\n",
      "Iteration 4140, loss = 0.09275792\n",
      "Iteration 4141, loss = 0.09272686\n",
      "Iteration 4142, loss = 0.09269581\n",
      "Iteration 4143, loss = 0.09266479\n",
      "Iteration 4144, loss = 0.09263380\n",
      "Iteration 4145, loss = 0.09260283\n",
      "Iteration 4146, loss = 0.09257188\n",
      "Iteration 4147, loss = 0.09254095\n",
      "Iteration 4148, loss = 0.09251005\n",
      "Iteration 4149, loss = 0.09247917\n",
      "Iteration 4150, loss = 0.09244831\n",
      "Iteration 4151, loss = 0.09241747\n",
      "Iteration 4152, loss = 0.09238665\n",
      "Iteration 4153, loss = 0.09235586\n",
      "Iteration 4154, loss = 0.09232508\n",
      "Iteration 4155, loss = 0.09229432\n",
      "Iteration 4156, loss = 0.09226358\n",
      "Iteration 4157, loss = 0.09223286\n",
      "Iteration 4158, loss = 0.09220216\n",
      "Iteration 4159, loss = 0.09217147\n",
      "Iteration 4160, loss = 0.09214081\n",
      "Iteration 4161, loss = 0.09211016\n",
      "Iteration 4162, loss = 0.09207951\n",
      "Iteration 4163, loss = 0.09204886\n",
      "Iteration 4164, loss = 0.09201822\n",
      "Iteration 4165, loss = 0.09198760\n",
      "Iteration 4166, loss = 0.09195699\n",
      "Iteration 4167, loss = 0.09192639\n",
      "Iteration 4168, loss = 0.09189581\n",
      "Iteration 4169, loss = 0.09186525\n",
      "Iteration 4170, loss = 0.09183471\n",
      "Iteration 4171, loss = 0.09180418\n",
      "Iteration 4172, loss = 0.09177366\n",
      "Iteration 4173, loss = 0.09174317\n",
      "Iteration 4174, loss = 0.09171269\n",
      "Iteration 4175, loss = 0.09168223\n",
      "Iteration 4176, loss = 0.09165178\n",
      "Iteration 4177, loss = 0.09162136\n",
      "Iteration 4178, loss = 0.09159095\n",
      "Iteration 4179, loss = 0.09156055\n",
      "Iteration 4180, loss = 0.09153018\n",
      "Iteration 4181, loss = 0.09149981\n",
      "Iteration 4182, loss = 0.09146947\n",
      "Iteration 4183, loss = 0.09143914\n",
      "Iteration 4184, loss = 0.09140883\n",
      "Iteration 4185, loss = 0.09137853\n",
      "Iteration 4186, loss = 0.09134826\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 4187, loss = 0.09131800\n",
      "Iteration 4188, loss = 0.09128775\n",
      "Iteration 4189, loss = 0.09125753\n",
      "Iteration 4190, loss = 0.09122732\n",
      "Iteration 4191, loss = 0.09119713\n",
      "Iteration 4192, loss = 0.09116695\n",
      "Iteration 4193, loss = 0.09113680\n",
      "Iteration 4194, loss = 0.09110666\n",
      "Iteration 4195, loss = 0.09107653\n",
      "Iteration 4196, loss = 0.09104643\n",
      "Iteration 4197, loss = 0.09101634\n",
      "Iteration 4198, loss = 0.09098627\n",
      "Iteration 4199, loss = 0.09095621\n",
      "Iteration 4200, loss = 0.09092617\n",
      "Iteration 4201, loss = 0.09089615\n",
      "Iteration 4202, loss = 0.09086615\n",
      "Iteration 4203, loss = 0.09083616\n",
      "Iteration 4204, loss = 0.09080619\n",
      "Iteration 4205, loss = 0.09077623\n",
      "Iteration 4206, loss = 0.09074629\n",
      "Iteration 4207, loss = 0.09071637\n",
      "Iteration 4208, loss = 0.09068646\n",
      "Iteration 4209, loss = 0.09065658\n",
      "Iteration 4210, loss = 0.09062670\n",
      "Iteration 4211, loss = 0.09059687\n",
      "Iteration 4212, loss = 0.09056707\n",
      "Iteration 4213, loss = 0.09053728\n",
      "Iteration 4214, loss = 0.09050752\n",
      "Iteration 4215, loss = 0.09047776\n",
      "Iteration 4216, loss = 0.09044802\n",
      "Iteration 4217, loss = 0.09041830\n",
      "Iteration 4218, loss = 0.09038859\n",
      "Iteration 4219, loss = 0.09035890\n",
      "Iteration 4220, loss = 0.09032923\n",
      "Iteration 4221, loss = 0.09029957\n",
      "Iteration 4222, loss = 0.09026992\n",
      "Iteration 4223, loss = 0.09024029\n",
      "Iteration 4224, loss = 0.09021068\n",
      "Iteration 4225, loss = 0.09018108\n",
      "Iteration 4226, loss = 0.09015150\n",
      "Iteration 4227, loss = 0.09012193\n",
      "Iteration 4228, loss = 0.09009238\n",
      "Iteration 4229, loss = 0.09006285\n",
      "Iteration 4230, loss = 0.09003333\n",
      "Iteration 4231, loss = 0.09000383\n",
      "Iteration 4232, loss = 0.08997434\n",
      "Iteration 4233, loss = 0.08994487\n",
      "Iteration 4234, loss = 0.08991542\n",
      "Iteration 4235, loss = 0.08988599\n",
      "Iteration 4236, loss = 0.08985657\n",
      "Iteration 4237, loss = 0.08982717\n",
      "Iteration 4238, loss = 0.08979779\n",
      "Iteration 4239, loss = 0.08976842\n",
      "Iteration 4240, loss = 0.08973907\n",
      "Iteration 4241, loss = 0.08970973\n",
      "Iteration 4242, loss = 0.08968041\n",
      "Iteration 4243, loss = 0.08965111\n",
      "Iteration 4244, loss = 0.08962183\n",
      "Iteration 4245, loss = 0.08959257\n",
      "Iteration 4246, loss = 0.08956331\n",
      "Iteration 4247, loss = 0.08953407\n",
      "Iteration 4248, loss = 0.08950484\n",
      "Iteration 4249, loss = 0.08947563\n",
      "Iteration 4250, loss = 0.08944644\n",
      "Iteration 4251, loss = 0.08941726\n",
      "Iteration 4252, loss = 0.08938810\n",
      "Iteration 4253, loss = 0.08935896\n",
      "Iteration 4254, loss = 0.08932983\n",
      "Iteration 4255, loss = 0.08930071\n",
      "Iteration 4256, loss = 0.08927161\n",
      "Iteration 4257, loss = 0.08924252\n",
      "Iteration 4258, loss = 0.08921345\n",
      "Iteration 4259, loss = 0.08918439\n",
      "Iteration 4260, loss = 0.08915534\n",
      "Iteration 4261, loss = 0.08912631\n",
      "Iteration 4262, loss = 0.08909728\n",
      "Iteration 4263, loss = 0.08906828\n",
      "Iteration 4264, loss = 0.08903929\n",
      "Iteration 4265, loss = 0.08901031\n",
      "Iteration 4266, loss = 0.08898135\n",
      "Iteration 4267, loss = 0.08895244\n",
      "Iteration 4268, loss = 0.08892363\n",
      "Iteration 4269, loss = 0.08889484\n",
      "Iteration 4270, loss = 0.08886607\n",
      "Iteration 4271, loss = 0.08883732\n",
      "Iteration 4272, loss = 0.08880860\n",
      "Iteration 4273, loss = 0.08877989\n",
      "Iteration 4274, loss = 0.08875121\n",
      "Iteration 4275, loss = 0.08872254\n",
      "Iteration 4276, loss = 0.08869389\n",
      "Iteration 4277, loss = 0.08866526\n",
      "Iteration 4278, loss = 0.08863665\n",
      "Iteration 4279, loss = 0.08860806\n",
      "Iteration 4280, loss = 0.08857948\n",
      "Iteration 4281, loss = 0.08855092\n",
      "Iteration 4282, loss = 0.08852238\n",
      "Iteration 4283, loss = 0.08849385\n",
      "Iteration 4284, loss = 0.08846534\n",
      "Iteration 4285, loss = 0.08843685\n",
      "Iteration 4286, loss = 0.08840837\n",
      "Iteration 4287, loss = 0.08837991\n",
      "Iteration 4288, loss = 0.08835146\n",
      "Iteration 4289, loss = 0.08832302\n",
      "Iteration 4290, loss = 0.08829460\n",
      "Iteration 4291, loss = 0.08826620\n",
      "Iteration 4292, loss = 0.08823781\n",
      "Iteration 4293, loss = 0.08820943\n",
      "Iteration 4294, loss = 0.08818107\n",
      "Iteration 4295, loss = 0.08815275\n",
      "Iteration 4296, loss = 0.08812453\n",
      "Iteration 4297, loss = 0.08809632\n",
      "Iteration 4298, loss = 0.08806814\n",
      "Iteration 4299, loss = 0.08803997\n",
      "Iteration 4300, loss = 0.08801183\n",
      "Iteration 4301, loss = 0.08798371\n",
      "Iteration 4302, loss = 0.08795560\n",
      "Iteration 4303, loss = 0.08792752\n",
      "Iteration 4304, loss = 0.08789945\n",
      "Iteration 4305, loss = 0.08787166\n",
      "Iteration 4306, loss = 0.08784404\n",
      "Iteration 4307, loss = 0.08781645\n",
      "Iteration 4308, loss = 0.08778890\n",
      "Iteration 4309, loss = 0.08776138\n",
      "Iteration 4310, loss = 0.08773389\n",
      "Iteration 4311, loss = 0.08770643\n",
      "Iteration 4312, loss = 0.08767900\n",
      "Iteration 4313, loss = 0.08765160\n",
      "Iteration 4314, loss = 0.08762422\n",
      "Iteration 4315, loss = 0.08759687\n",
      "Iteration 4316, loss = 0.08756954\n",
      "Iteration 4317, loss = 0.08754223\n",
      "Iteration 4318, loss = 0.08751494\n",
      "Iteration 4319, loss = 0.08748767\n",
      "Iteration 4320, loss = 0.08746042\n",
      "Iteration 4321, loss = 0.08743320\n",
      "Iteration 4322, loss = 0.08740599\n",
      "Iteration 4323, loss = 0.08737880\n",
      "Iteration 4324, loss = 0.08735163\n",
      "Iteration 4325, loss = 0.08732448\n",
      "Iteration 4326, loss = 0.08729734\n",
      "Iteration 4327, loss = 0.08727022\n",
      "Iteration 4328, loss = 0.08724311\n",
      "Iteration 4329, loss = 0.08721603\n",
      "Iteration 4330, loss = 0.08718896\n",
      "Iteration 4331, loss = 0.08716190\n",
      "Iteration 4332, loss = 0.08713486\n",
      "Iteration 4333, loss = 0.08710783\n",
      "Iteration 4334, loss = 0.08708082\n",
      "Iteration 4335, loss = 0.08705383\n",
      "Iteration 4336, loss = 0.08702685\n",
      "Iteration 4337, loss = 0.08699988\n",
      "Iteration 4338, loss = 0.08697293\n",
      "Iteration 4339, loss = 0.08694599\n",
      "Iteration 4340, loss = 0.08691907\n",
      "Iteration 4341, loss = 0.08689216\n",
      "Iteration 4342, loss = 0.08686527\n",
      "Iteration 4343, loss = 0.08683839\n",
      "Iteration 4344, loss = 0.08681152\n",
      "Iteration 4345, loss = 0.08678467\n",
      "Iteration 4346, loss = 0.08675783\n",
      "Iteration 4347, loss = 0.08673100\n",
      "Iteration 4348, loss = 0.08670419\n",
      "Iteration 4349, loss = 0.08667739\n",
      "Iteration 4350, loss = 0.08665061\n",
      "Iteration 4351, loss = 0.08662384\n",
      "Iteration 4352, loss = 0.08659708\n",
      "Iteration 4353, loss = 0.08657033\n",
      "Iteration 4354, loss = 0.08654360\n",
      "Iteration 4355, loss = 0.08651688\n",
      "Iteration 4356, loss = 0.08649017\n",
      "Iteration 4357, loss = 0.08646348\n",
      "Iteration 4358, loss = 0.08643683\n",
      "Iteration 4359, loss = 0.08641021\n",
      "Iteration 4360, loss = 0.08638361\n",
      "Iteration 4361, loss = 0.08635702\n",
      "Iteration 4362, loss = 0.08633044\n",
      "Iteration 4363, loss = 0.08630391\n",
      "Iteration 4364, loss = 0.08627740\n",
      "Iteration 4365, loss = 0.08625090\n",
      "Iteration 4366, loss = 0.08622443\n",
      "Iteration 4367, loss = 0.08619797\n",
      "Iteration 4368, loss = 0.08617152\n",
      "Iteration 4369, loss = 0.08614511\n",
      "Iteration 4370, loss = 0.08611871\n",
      "Iteration 4371, loss = 0.08609234\n",
      "Iteration 4372, loss = 0.08606598\n",
      "Iteration 4373, loss = 0.08603963\n",
      "Iteration 4374, loss = 0.08601330\n",
      "Iteration 4375, loss = 0.08598699\n",
      "Iteration 4376, loss = 0.08596069\n",
      "Iteration 4377, loss = 0.08593441\n",
      "Iteration 4378, loss = 0.08590814\n",
      "Iteration 4379, loss = 0.08588188\n",
      "Iteration 4380, loss = 0.08585564\n",
      "Iteration 4381, loss = 0.08582941\n",
      "Iteration 4382, loss = 0.08580319\n",
      "Iteration 4383, loss = 0.08577699\n",
      "Iteration 4384, loss = 0.08575080\n",
      "Iteration 4385, loss = 0.08572462\n",
      "Iteration 4386, loss = 0.08569845\n",
      "Iteration 4387, loss = 0.08567230\n",
      "Iteration 4388, loss = 0.08564616\n",
      "Iteration 4389, loss = 0.08562004\n",
      "Iteration 4390, loss = 0.08559392\n",
      "Iteration 4391, loss = 0.08556782\n",
      "Iteration 4392, loss = 0.08554173\n",
      "Iteration 4393, loss = 0.08551565\n",
      "Iteration 4394, loss = 0.08548958\n",
      "Iteration 4395, loss = 0.08546354\n",
      "Iteration 4396, loss = 0.08543750\n",
      "Iteration 4397, loss = 0.08541148\n",
      "Iteration 4398, loss = 0.08538547\n",
      "Iteration 4399, loss = 0.08535948\n",
      "Iteration 4400, loss = 0.08533349\n",
      "Iteration 4401, loss = 0.08530752\n",
      "Iteration 4402, loss = 0.08528156\n",
      "Iteration 4403, loss = 0.08525561\n",
      "Iteration 4404, loss = 0.08522967\n",
      "Iteration 4405, loss = 0.08520374\n",
      "Iteration 4406, loss = 0.08517783\n",
      "Iteration 4407, loss = 0.08515192\n",
      "Iteration 4408, loss = 0.08512603\n",
      "Iteration 4409, loss = 0.08510015\n",
      "Iteration 4410, loss = 0.08507428\n",
      "Iteration 4411, loss = 0.08504842\n",
      "Iteration 4412, loss = 0.08502267\n",
      "Iteration 4413, loss = 0.08499703\n",
      "Iteration 4414, loss = 0.08497142\n",
      "Iteration 4415, loss = 0.08494583\n",
      "Iteration 4416, loss = 0.08492027\n",
      "Iteration 4417, loss = 0.08489473\n",
      "Iteration 4418, loss = 0.08486921\n",
      "Iteration 4419, loss = 0.08484370\n",
      "Iteration 4420, loss = 0.08481822\n",
      "Iteration 4421, loss = 0.08479275\n",
      "Iteration 4422, loss = 0.08476730\n",
      "Iteration 4423, loss = 0.08474187\n",
      "Iteration 4424, loss = 0.08471645\n",
      "Iteration 4425, loss = 0.08469105\n",
      "Iteration 4426, loss = 0.08466566\n",
      "Iteration 4427, loss = 0.08464029\n",
      "Iteration 4428, loss = 0.08461492\n",
      "Iteration 4429, loss = 0.08458958\n",
      "Iteration 4430, loss = 0.08456424\n",
      "Iteration 4431, loss = 0.08453892\n",
      "Iteration 4432, loss = 0.08451361\n",
      "Iteration 4433, loss = 0.08448831\n",
      "Iteration 4434, loss = 0.08446302\n",
      "Iteration 4435, loss = 0.08443775\n",
      "Iteration 4436, loss = 0.08441248\n",
      "Iteration 4437, loss = 0.08438724\n",
      "Iteration 4438, loss = 0.08436202\n",
      "Iteration 4439, loss = 0.08433681\n",
      "Iteration 4440, loss = 0.08431162\n",
      "Iteration 4441, loss = 0.08428643\n",
      "Iteration 4442, loss = 0.08426125\n",
      "Iteration 4443, loss = 0.08423609\n",
      "Iteration 4444, loss = 0.08421096\n",
      "Iteration 4445, loss = 0.08418584\n",
      "Iteration 4446, loss = 0.08416073\n",
      "Iteration 4447, loss = 0.08413564\n",
      "Iteration 4448, loss = 0.08411055\n",
      "Iteration 4449, loss = 0.08408548\n",
      "Iteration 4450, loss = 0.08406042\n",
      "Iteration 4451, loss = 0.08403536\n",
      "Iteration 4452, loss = 0.08401032\n",
      "Iteration 4453, loss = 0.08398529\n",
      "Iteration 4454, loss = 0.08396027\n",
      "Iteration 4455, loss = 0.08393527\n",
      "Iteration 4456, loss = 0.08391027\n",
      "Iteration 4457, loss = 0.08388528\n",
      "Iteration 4458, loss = 0.08386030\n",
      "Iteration 4459, loss = 0.08383533\n",
      "Iteration 4460, loss = 0.08381037\n",
      "Iteration 4461, loss = 0.08378542\n",
      "Iteration 4462, loss = 0.08376049\n",
      "Iteration 4463, loss = 0.08373556\n",
      "Iteration 4464, loss = 0.08371063\n",
      "Iteration 4465, loss = 0.08368572\n",
      "Iteration 4466, loss = 0.08366082\n",
      "Iteration 4467, loss = 0.08363592\n",
      "Iteration 4468, loss = 0.08361104\n",
      "Iteration 4469, loss = 0.08358616\n",
      "Iteration 4470, loss = 0.08356124\n",
      "Iteration 4471, loss = 0.08353635\n",
      "Iteration 4472, loss = 0.08351146\n",
      "Iteration 4473, loss = 0.08348659\n",
      "Iteration 4474, loss = 0.08346172\n",
      "Iteration 4475, loss = 0.08343686\n",
      "Iteration 4476, loss = 0.08341201\n",
      "Iteration 4477, loss = 0.08338717\n",
      "Iteration 4478, loss = 0.08336233\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 4479, loss = 0.08333751\n",
      "Iteration 4480, loss = 0.08331269\n",
      "Iteration 4481, loss = 0.08328788\n",
      "Iteration 4482, loss = 0.08326308\n",
      "Iteration 4483, loss = 0.08323829\n",
      "Iteration 4484, loss = 0.08321350\n",
      "Iteration 4485, loss = 0.08318873\n",
      "Iteration 4486, loss = 0.08316396\n",
      "Iteration 4487, loss = 0.08313920\n",
      "Iteration 4488, loss = 0.08311446\n",
      "Iteration 4489, loss = 0.08308973\n",
      "Iteration 4490, loss = 0.08306501\n",
      "Iteration 4491, loss = 0.08304031\n",
      "Iteration 4492, loss = 0.08301561\n",
      "Iteration 4493, loss = 0.08299092\n",
      "Iteration 4494, loss = 0.08296624\n",
      "Iteration 4495, loss = 0.08294158\n",
      "Iteration 4496, loss = 0.08291692\n",
      "Iteration 4497, loss = 0.08289227\n",
      "Iteration 4498, loss = 0.08286762\n",
      "Iteration 4499, loss = 0.08284300\n",
      "Iteration 4500, loss = 0.08281837\n",
      "Iteration 4501, loss = 0.08279375\n",
      "Iteration 4502, loss = 0.08276914\n",
      "Iteration 4503, loss = 0.08274454\n",
      "Iteration 4504, loss = 0.08271994\n",
      "Iteration 4505, loss = 0.08269535\n",
      "Iteration 4506, loss = 0.08267077\n",
      "Iteration 4507, loss = 0.08264620\n",
      "Iteration 4508, loss = 0.08262163\n",
      "Iteration 4509, loss = 0.08259708\n",
      "Iteration 4510, loss = 0.08257253\n",
      "Iteration 4511, loss = 0.08254799\n",
      "Iteration 4512, loss = 0.08252346\n",
      "Iteration 4513, loss = 0.08249894\n",
      "Iteration 4514, loss = 0.08247443\n",
      "Iteration 4515, loss = 0.08244992\n",
      "Iteration 4516, loss = 0.08242543\n",
      "Iteration 4517, loss = 0.08240094\n",
      "Iteration 4518, loss = 0.08237646\n",
      "Iteration 4519, loss = 0.08235199\n",
      "Iteration 4520, loss = 0.08232753\n",
      "Iteration 4521, loss = 0.08230307\n",
      "Iteration 4522, loss = 0.08227863\n",
      "Iteration 4523, loss = 0.08225419\n",
      "Iteration 4524, loss = 0.08222976\n",
      "Iteration 4525, loss = 0.08220534\n",
      "Iteration 4526, loss = 0.08218095\n",
      "Iteration 4527, loss = 0.08215656\n",
      "Iteration 4528, loss = 0.08213217\n",
      "Iteration 4529, loss = 0.08210780\n",
      "Iteration 4530, loss = 0.08208344\n",
      "Iteration 4531, loss = 0.08205909\n",
      "Iteration 4532, loss = 0.08203474\n",
      "Iteration 4533, loss = 0.08201040\n",
      "Iteration 4534, loss = 0.08198606\n",
      "Iteration 4535, loss = 0.08196170\n",
      "Iteration 4536, loss = 0.08193734\n",
      "Iteration 4537, loss = 0.08191299\n",
      "Iteration 4538, loss = 0.08188864\n",
      "Iteration 4539, loss = 0.08186430\n",
      "Iteration 4540, loss = 0.08183996\n",
      "Iteration 4541, loss = 0.08181564\n",
      "Iteration 4542, loss = 0.08179131\n",
      "Iteration 4543, loss = 0.08176700\n",
      "Iteration 4544, loss = 0.08174269\n",
      "Iteration 4545, loss = 0.08171838\n",
      "Iteration 4546, loss = 0.08169409\n",
      "Iteration 4547, loss = 0.08166978\n",
      "Iteration 4548, loss = 0.08164546\n",
      "Iteration 4549, loss = 0.08162115\n",
      "Iteration 4550, loss = 0.08159685\n",
      "Iteration 4551, loss = 0.08157254\n",
      "Iteration 4552, loss = 0.08154825\n",
      "Iteration 4553, loss = 0.08152396\n",
      "Iteration 4554, loss = 0.08149967\n",
      "Iteration 4555, loss = 0.08147540\n",
      "Iteration 4556, loss = 0.08145112\n",
      "Iteration 4557, loss = 0.08142690\n",
      "Iteration 4558, loss = 0.08140269\n",
      "Iteration 4559, loss = 0.08137849\n",
      "Iteration 4560, loss = 0.08135430\n",
      "Iteration 4561, loss = 0.08133013\n",
      "Iteration 4562, loss = 0.08130596\n",
      "Iteration 4563, loss = 0.08128180\n",
      "Iteration 4564, loss = 0.08125765\n",
      "Iteration 4565, loss = 0.08123351\n",
      "Iteration 4566, loss = 0.08120938\n",
      "Iteration 4567, loss = 0.08118534\n",
      "Iteration 4568, loss = 0.08116132\n",
      "Iteration 4569, loss = 0.08113732\n",
      "Iteration 4570, loss = 0.08111333\n",
      "Iteration 4571, loss = 0.08108936\n",
      "Iteration 4572, loss = 0.08106540\n",
      "Iteration 4573, loss = 0.08104145\n",
      "Iteration 4574, loss = 0.08101752\n",
      "Iteration 4575, loss = 0.08099360\n",
      "Iteration 4576, loss = 0.08096969\n",
      "Iteration 4577, loss = 0.08094579\n",
      "Iteration 4578, loss = 0.08092194\n",
      "Iteration 4579, loss = 0.08089815\n",
      "Iteration 4580, loss = 0.08087438\n",
      "Iteration 4581, loss = 0.08085062\n",
      "Iteration 4582, loss = 0.08082688\n",
      "Iteration 4583, loss = 0.08080316\n",
      "Iteration 4584, loss = 0.08077944\n",
      "Iteration 4585, loss = 0.08075574\n",
      "Iteration 4586, loss = 0.08073205\n",
      "Iteration 4587, loss = 0.08070838\n",
      "Iteration 4588, loss = 0.08068471\n",
      "Iteration 4589, loss = 0.08066106\n",
      "Iteration 4590, loss = 0.08063739\n",
      "Iteration 4591, loss = 0.08061373\n",
      "Iteration 4592, loss = 0.08059008\n",
      "Iteration 4593, loss = 0.08056644\n",
      "Iteration 4594, loss = 0.08054281\n",
      "Iteration 4595, loss = 0.08051918\n",
      "Iteration 4596, loss = 0.08049556\n",
      "Iteration 4597, loss = 0.08047197\n",
      "Iteration 4598, loss = 0.08044833\n",
      "Iteration 4599, loss = 0.08042469\n",
      "Iteration 4600, loss = 0.08040106\n",
      "Iteration 4601, loss = 0.08037744\n",
      "Iteration 4602, loss = 0.08035381\n",
      "Iteration 4603, loss = 0.08033017\n",
      "Iteration 4604, loss = 0.08030653\n",
      "Iteration 4605, loss = 0.08028289\n",
      "Iteration 4606, loss = 0.08025927\n",
      "Iteration 4607, loss = 0.08023564\n",
      "Iteration 4608, loss = 0.08021202\n",
      "Iteration 4609, loss = 0.08018840\n",
      "Iteration 4610, loss = 0.08016479\n",
      "Iteration 4611, loss = 0.08014119\n",
      "Iteration 4612, loss = 0.08011759\n",
      "Iteration 4613, loss = 0.08009400\n",
      "Iteration 4614, loss = 0.08007041\n",
      "Iteration 4615, loss = 0.08004683\n",
      "Iteration 4616, loss = 0.08002325\n",
      "Iteration 4617, loss = 0.07999968\n",
      "Iteration 4618, loss = 0.07997612\n",
      "Iteration 4619, loss = 0.07995256\n",
      "Iteration 4620, loss = 0.07992902\n",
      "Iteration 4621, loss = 0.07990550\n",
      "Iteration 4622, loss = 0.07988198\n",
      "Iteration 4623, loss = 0.07985847\n",
      "Iteration 4624, loss = 0.07983497\n",
      "Iteration 4625, loss = 0.07981148\n",
      "Iteration 4626, loss = 0.07978799\n",
      "Iteration 4627, loss = 0.07976452\n",
      "Iteration 4628, loss = 0.07974105\n",
      "Iteration 4629, loss = 0.07971759\n",
      "Iteration 4630, loss = 0.07969413\n",
      "Iteration 4631, loss = 0.07967069\n",
      "Iteration 4632, loss = 0.07964725\n",
      "Iteration 4633, loss = 0.07962381\n",
      "Iteration 4634, loss = 0.07960036\n",
      "Iteration 4635, loss = 0.07957694\n",
      "Iteration 4636, loss = 0.07955353\n",
      "Iteration 4637, loss = 0.07953012\n",
      "Iteration 4638, loss = 0.07950672\n",
      "Iteration 4639, loss = 0.07948332\n",
      "Iteration 4640, loss = 0.07945994\n",
      "Iteration 4641, loss = 0.07943721\n",
      "Iteration 4642, loss = 0.07941450\n",
      "Iteration 4643, loss = 0.07939181\n",
      "Iteration 4644, loss = 0.07936913\n",
      "Iteration 4645, loss = 0.07934647\n",
      "Iteration 4646, loss = 0.07932382\n",
      "Iteration 4647, loss = 0.07930119\n",
      "Iteration 4648, loss = 0.07927857\n",
      "Iteration 4649, loss = 0.07925597\n",
      "Iteration 4650, loss = 0.07923337\n",
      "Iteration 4651, loss = 0.07921079\n",
      "Iteration 4652, loss = 0.07918823\n",
      "Iteration 4653, loss = 0.07916567\n",
      "Iteration 4654, loss = 0.07914313\n",
      "Iteration 4655, loss = 0.07912060\n",
      "Iteration 4656, loss = 0.07909808\n",
      "Iteration 4657, loss = 0.07907558\n",
      "Iteration 4658, loss = 0.07905309\n",
      "Iteration 4659, loss = 0.07903062\n",
      "Iteration 4660, loss = 0.07900815\n",
      "Iteration 4661, loss = 0.07898570\n",
      "Iteration 4662, loss = 0.07896325\n",
      "Iteration 4663, loss = 0.07894082\n",
      "Iteration 4664, loss = 0.07891840\n",
      "Iteration 4665, loss = 0.07889598\n",
      "Iteration 4666, loss = 0.07887358\n",
      "Iteration 4667, loss = 0.07885119\n",
      "Iteration 4668, loss = 0.07882881\n",
      "Iteration 4669, loss = 0.07880643\n",
      "Iteration 4670, loss = 0.07878407\n",
      "Iteration 4671, loss = 0.07876171\n",
      "Iteration 4672, loss = 0.07873937\n",
      "Iteration 4673, loss = 0.07871703\n",
      "Iteration 4674, loss = 0.07869471\n",
      "Iteration 4675, loss = 0.07867239\n",
      "Iteration 4676, loss = 0.07865008\n",
      "Iteration 4677, loss = 0.07862778\n",
      "Iteration 4678, loss = 0.07860549\n",
      "Iteration 4679, loss = 0.07858321\n",
      "Iteration 4680, loss = 0.07856094\n",
      "Iteration 4681, loss = 0.07853868\n",
      "Iteration 4682, loss = 0.07851643\n",
      "Iteration 4683, loss = 0.07849419\n",
      "Iteration 4684, loss = 0.07847195\n",
      "Iteration 4685, loss = 0.07844973\n",
      "Iteration 4686, loss = 0.07842751\n",
      "Iteration 4687, loss = 0.07840531\n",
      "Iteration 4688, loss = 0.07838311\n",
      "Iteration 4689, loss = 0.07836092\n",
      "Iteration 4690, loss = 0.07833874\n",
      "Iteration 4691, loss = 0.07831658\n",
      "Iteration 4692, loss = 0.07829442\n",
      "Iteration 4693, loss = 0.07827227\n",
      "Iteration 4694, loss = 0.07825013\n",
      "Iteration 4695, loss = 0.07822800\n",
      "Iteration 4696, loss = 0.07820588\n",
      "Iteration 4697, loss = 0.07818377\n",
      "Iteration 4698, loss = 0.07816167\n",
      "Iteration 4699, loss = 0.07813957\n",
      "Iteration 4700, loss = 0.07811749\n",
      "Iteration 4701, loss = 0.07809541\n",
      "Iteration 4702, loss = 0.07807334\n",
      "Iteration 4703, loss = 0.07805128\n",
      "Iteration 4704, loss = 0.07802922\n",
      "Iteration 4705, loss = 0.07800718\n",
      "Iteration 4706, loss = 0.07798514\n",
      "Iteration 4707, loss = 0.07796311\n",
      "Iteration 4708, loss = 0.07794109\n",
      "Iteration 4709, loss = 0.07791907\n",
      "Iteration 4710, loss = 0.07789706\n",
      "Iteration 4711, loss = 0.07787503\n",
      "Iteration 4712, loss = 0.07785301\n",
      "Iteration 4713, loss = 0.07783099\n",
      "Iteration 4714, loss = 0.07780898\n",
      "Iteration 4715, loss = 0.07778698\n",
      "Iteration 4716, loss = 0.07776498\n",
      "Iteration 4717, loss = 0.07774299\n",
      "Iteration 4718, loss = 0.07772100\n",
      "Iteration 4719, loss = 0.07769902\n",
      "Iteration 4720, loss = 0.07767705\n",
      "Iteration 4721, loss = 0.07765508\n",
      "Iteration 4722, loss = 0.07763312\n",
      "Iteration 4723, loss = 0.07761117\n",
      "Iteration 4724, loss = 0.07758922\n",
      "Iteration 4725, loss = 0.07756729\n",
      "Iteration 4726, loss = 0.07754535\n",
      "Iteration 4727, loss = 0.07752343\n",
      "Iteration 4728, loss = 0.07750151\n",
      "Iteration 4729, loss = 0.07747962\n",
      "Iteration 4730, loss = 0.07745776\n",
      "Iteration 4731, loss = 0.07743591\n",
      "Iteration 4732, loss = 0.07741408\n",
      "Iteration 4733, loss = 0.07739225\n",
      "Iteration 4734, loss = 0.07737056\n",
      "Iteration 4735, loss = 0.07734904\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 4736, loss = 0.07732755\n",
      "Iteration 4737, loss = 0.07730608\n",
      "Iteration 4738, loss = 0.07728469\n",
      "Iteration 4739, loss = 0.07726348\n",
      "Iteration 4740, loss = 0.07724230\n",
      "Iteration 4741, loss = 0.07722114\n",
      "Iteration 4742, loss = 0.07720000\n",
      "Iteration 4743, loss = 0.07717889\n",
      "Iteration 4744, loss = 0.07715779\n",
      "Iteration 4745, loss = 0.07713675\n",
      "Iteration 4746, loss = 0.07711573\n",
      "Iteration 4747, loss = 0.07709474\n",
      "Iteration 4748, loss = 0.07707376\n",
      "Iteration 4749, loss = 0.07705281\n",
      "Iteration 4750, loss = 0.07703187\n",
      "Iteration 4751, loss = 0.07701094\n",
      "Iteration 4752, loss = 0.07699003\n",
      "Iteration 4753, loss = 0.07696913\n",
      "Iteration 4754, loss = 0.07694825\n",
      "Iteration 4755, loss = 0.07692738\n",
      "Iteration 4756, loss = 0.07690654\n",
      "Iteration 4757, loss = 0.07688571\n",
      "Iteration 4758, loss = 0.07686489\n",
      "Iteration 4759, loss = 0.07684408\n",
      "Iteration 4760, loss = 0.07682328\n",
      "Iteration 4761, loss = 0.07680249\n",
      "Iteration 4762, loss = 0.07678171\n",
      "Iteration 4763, loss = 0.07676094\n",
      "Iteration 4764, loss = 0.07674018\n",
      "Iteration 4765, loss = 0.07671943\n",
      "Iteration 4766, loss = 0.07669868\n",
      "Iteration 4767, loss = 0.07667794\n",
      "Iteration 4768, loss = 0.07665721\n",
      "Iteration 4769, loss = 0.07663649\n",
      "Iteration 4770, loss = 0.07661577\n",
      "Iteration 4771, loss = 0.07659505\n",
      "Iteration 4772, loss = 0.07657434\n",
      "Iteration 4773, loss = 0.07655364\n",
      "Iteration 4774, loss = 0.07653295\n",
      "Iteration 4775, loss = 0.07651226\n",
      "Iteration 4776, loss = 0.07649158\n",
      "Iteration 4777, loss = 0.07647091\n",
      "Iteration 4778, loss = 0.07645024\n",
      "Iteration 4779, loss = 0.07642956\n",
      "Iteration 4780, loss = 0.07640889\n",
      "Iteration 4781, loss = 0.07638822\n",
      "Iteration 4782, loss = 0.07636755\n",
      "Iteration 4783, loss = 0.07634689\n",
      "Iteration 4784, loss = 0.07632624\n",
      "Iteration 4785, loss = 0.07630561\n",
      "Iteration 4786, loss = 0.07628499\n",
      "Iteration 4787, loss = 0.07626437\n",
      "Iteration 4788, loss = 0.07624376\n",
      "Iteration 4789, loss = 0.07622316\n",
      "Iteration 4790, loss = 0.07620256\n",
      "Iteration 4791, loss = 0.07618197\n",
      "Iteration 4792, loss = 0.07616138\n",
      "Iteration 4793, loss = 0.07614080\n",
      "Iteration 4794, loss = 0.07612023\n",
      "Iteration 4795, loss = 0.07609966\n",
      "Iteration 4796, loss = 0.07607910\n",
      "Iteration 4797, loss = 0.07605854\n",
      "Iteration 4798, loss = 0.07603800\n",
      "Iteration 4799, loss = 0.07601748\n",
      "Iteration 4800, loss = 0.07599697\n",
      "Iteration 4801, loss = 0.07597646\n",
      "Iteration 4802, loss = 0.07595596\n",
      "Iteration 4803, loss = 0.07593547\n",
      "Iteration 4804, loss = 0.07591498\n",
      "Iteration 4805, loss = 0.07589450\n",
      "Iteration 4806, loss = 0.07587402\n",
      "Iteration 4807, loss = 0.07585356\n",
      "Iteration 4808, loss = 0.07583310\n",
      "Iteration 4809, loss = 0.07581264\n",
      "Iteration 4810, loss = 0.07579212\n",
      "Iteration 4811, loss = 0.07577152\n",
      "Iteration 4812, loss = 0.07575091\n",
      "Iteration 4813, loss = 0.07573028\n",
      "Iteration 4814, loss = 0.07570965\n",
      "Iteration 4815, loss = 0.07568902\n",
      "Iteration 4816, loss = 0.07566839\n",
      "Iteration 4817, loss = 0.07564777\n",
      "Iteration 4818, loss = 0.07562716\n",
      "Iteration 4819, loss = 0.07560654\n",
      "Iteration 4820, loss = 0.07558592\n",
      "Iteration 4821, loss = 0.07556530\n",
      "Iteration 4822, loss = 0.07554468\n",
      "Iteration 4823, loss = 0.07552406\n",
      "Iteration 4824, loss = 0.07550345\n",
      "Iteration 4825, loss = 0.07548284\n",
      "Iteration 4826, loss = 0.07546223\n",
      "Iteration 4827, loss = 0.07544162\n",
      "Iteration 4828, loss = 0.07542101\n",
      "Iteration 4829, loss = 0.07540041\n",
      "Iteration 4830, loss = 0.07537981\n",
      "Iteration 4831, loss = 0.07535922\n",
      "Iteration 4832, loss = 0.07533863\n",
      "Iteration 4833, loss = 0.07531804\n",
      "Iteration 4834, loss = 0.07529746\n",
      "Iteration 4835, loss = 0.07527688\n",
      "Iteration 4836, loss = 0.07525630\n",
      "Iteration 4837, loss = 0.07523573\n",
      "Iteration 4838, loss = 0.07521517\n",
      "Iteration 4839, loss = 0.07519461\n",
      "Iteration 4840, loss = 0.07517405\n",
      "Iteration 4841, loss = 0.07515350\n",
      "Iteration 4842, loss = 0.07513296\n",
      "Iteration 4843, loss = 0.07511242\n",
      "Iteration 4844, loss = 0.07509188\n",
      "Iteration 4845, loss = 0.07507135\n",
      "Iteration 4846, loss = 0.07505082\n",
      "Iteration 4847, loss = 0.07503030\n",
      "Iteration 4848, loss = 0.07500979\n",
      "Iteration 4849, loss = 0.07498928\n",
      "Iteration 4850, loss = 0.07496877\n",
      "Iteration 4851, loss = 0.07494827\n",
      "Iteration 4852, loss = 0.07492777\n",
      "Iteration 4853, loss = 0.07490728\n",
      "Iteration 4854, loss = 0.07488679\n",
      "Iteration 4855, loss = 0.07486631\n",
      "Iteration 4856, loss = 0.07484584\n",
      "Iteration 4857, loss = 0.07482536\n",
      "Iteration 4858, loss = 0.07480490\n",
      "Iteration 4859, loss = 0.07478444\n",
      "Iteration 4860, loss = 0.07476398\n",
      "Iteration 4861, loss = 0.07474353\n",
      "Iteration 4862, loss = 0.07472308\n",
      "Iteration 4863, loss = 0.07470264\n",
      "Iteration 4864, loss = 0.07468220\n",
      "Iteration 4865, loss = 0.07466178\n",
      "Iteration 4866, loss = 0.07464137\n",
      "Iteration 4867, loss = 0.07462097\n",
      "Iteration 4868, loss = 0.07460057\n",
      "Iteration 4869, loss = 0.07458018\n",
      "Iteration 4870, loss = 0.07455980\n",
      "Iteration 4871, loss = 0.07453943\n",
      "Iteration 4872, loss = 0.07451908\n",
      "Iteration 4873, loss = 0.07449873\n",
      "Iteration 4874, loss = 0.07447839\n",
      "Iteration 4875, loss = 0.07445806\n",
      "Iteration 4876, loss = 0.07443774\n",
      "Iteration 4877, loss = 0.07441742\n",
      "Iteration 4878, loss = 0.07439711\n",
      "Iteration 4879, loss = 0.07437680\n",
      "Iteration 4880, loss = 0.07435650\n",
      "Iteration 4881, loss = 0.07433621\n",
      "Iteration 4882, loss = 0.07431592\n",
      "Iteration 4883, loss = 0.07429562\n",
      "Iteration 4884, loss = 0.07427531\n",
      "Iteration 4885, loss = 0.07425500\n",
      "Iteration 4886, loss = 0.07423469\n",
      "Iteration 4887, loss = 0.07421438\n",
      "Iteration 4888, loss = 0.07419408\n",
      "Iteration 4889, loss = 0.07417377\n",
      "Iteration 4890, loss = 0.07415347\n",
      "Iteration 4891, loss = 0.07413317\n",
      "Iteration 4892, loss = 0.07411288\n",
      "Iteration 4893, loss = 0.07409258\n",
      "Iteration 4894, loss = 0.07407230\n",
      "Iteration 4895, loss = 0.07405201\n",
      "Iteration 4896, loss = 0.07403173\n",
      "Iteration 4897, loss = 0.07401146\n",
      "Iteration 4898, loss = 0.07399120\n",
      "Iteration 4899, loss = 0.07397095\n",
      "Iteration 4900, loss = 0.07395070\n",
      "Iteration 4901, loss = 0.07393046\n",
      "Iteration 4902, loss = 0.07391023\n",
      "Iteration 4903, loss = 0.07389000\n",
      "Iteration 4904, loss = 0.07386977\n",
      "Iteration 4905, loss = 0.07384955\n",
      "Iteration 4906, loss = 0.07382931\n",
      "Iteration 4907, loss = 0.07380907\n",
      "Iteration 4908, loss = 0.07378882\n",
      "Iteration 4909, loss = 0.07376858\n",
      "Iteration 4910, loss = 0.07374833\n",
      "Iteration 4911, loss = 0.07372809\n",
      "Iteration 4912, loss = 0.07370786\n",
      "Iteration 4913, loss = 0.07368762\n",
      "Iteration 4914, loss = 0.07366739\n",
      "Iteration 4915, loss = 0.07364716\n",
      "Iteration 4916, loss = 0.07362693\n",
      "Iteration 4917, loss = 0.07360671\n",
      "Iteration 4918, loss = 0.07358648\n",
      "Iteration 4919, loss = 0.07356627\n",
      "Iteration 4920, loss = 0.07354606\n",
      "Iteration 4921, loss = 0.07352585\n",
      "Iteration 4922, loss = 0.07350564\n",
      "Iteration 4923, loss = 0.07348544\n",
      "Iteration 4924, loss = 0.07346524\n",
      "Iteration 4925, loss = 0.07344505\n",
      "Iteration 4926, loss = 0.07342486\n",
      "Iteration 4927, loss = 0.07340468\n",
      "Iteration 4928, loss = 0.07338450\n",
      "Iteration 4929, loss = 0.07336433\n",
      "Iteration 4930, loss = 0.07334416\n",
      "Iteration 4931, loss = 0.07332399\n",
      "Iteration 4932, loss = 0.07330383\n",
      "Iteration 4933, loss = 0.07328367\n",
      "Iteration 4934, loss = 0.07326351\n",
      "Iteration 4935, loss = 0.07324340\n",
      "Iteration 4936, loss = 0.07322328\n",
      "Iteration 4937, loss = 0.07320318\n",
      "Iteration 4938, loss = 0.07318308\n",
      "Iteration 4939, loss = 0.07316299\n",
      "Iteration 4940, loss = 0.07314290\n",
      "Iteration 4941, loss = 0.07312281\n",
      "Iteration 4942, loss = 0.07310268\n",
      "Iteration 4943, loss = 0.07308254\n",
      "Iteration 4944, loss = 0.07306241\n",
      "Iteration 4945, loss = 0.07304227\n",
      "Iteration 4946, loss = 0.07302213\n",
      "Iteration 4947, loss = 0.07300199\n",
      "Iteration 4948, loss = 0.07298185\n",
      "Iteration 4949, loss = 0.07296172\n",
      "Iteration 4950, loss = 0.07294158\n",
      "Iteration 4951, loss = 0.07292145\n",
      "Iteration 4952, loss = 0.07290131\n",
      "Iteration 4953, loss = 0.07288119\n",
      "Iteration 4954, loss = 0.07286106\n",
      "Iteration 4955, loss = 0.07284094\n",
      "Iteration 4956, loss = 0.07282082\n",
      "Iteration 4957, loss = 0.07280070\n",
      "Iteration 4958, loss = 0.07278059\n",
      "Iteration 4959, loss = 0.07276049\n",
      "Iteration 4960, loss = 0.07274038\n",
      "Iteration 4961, loss = 0.07272028\n",
      "Iteration 4962, loss = 0.07270019\n",
      "Iteration 4963, loss = 0.07268010\n",
      "Iteration 4964, loss = 0.07266001\n",
      "Iteration 4965, loss = 0.07263993\n",
      "Iteration 4966, loss = 0.07261985\n",
      "Iteration 4967, loss = 0.07259978\n",
      "Iteration 4968, loss = 0.07257971\n",
      "Iteration 4969, loss = 0.07255964\n",
      "Iteration 4970, loss = 0.07253959\n",
      "Iteration 4971, loss = 0.07251953\n",
      "Iteration 4972, loss = 0.07249948\n",
      "Iteration 4973, loss = 0.07247944\n",
      "Iteration 4974, loss = 0.07245940\n",
      "Iteration 4975, loss = 0.07243936\n",
      "Iteration 4976, loss = 0.07241933\n",
      "Iteration 4977, loss = 0.07239930\n",
      "Iteration 4978, loss = 0.07237928\n",
      "Iteration 4979, loss = 0.07235933\n",
      "Iteration 4980, loss = 0.07233938\n",
      "Iteration 4981, loss = 0.07231945\n",
      "Iteration 4982, loss = 0.07229952\n",
      "Iteration 4983, loss = 0.07227960\n",
      "Iteration 4984, loss = 0.07225969\n",
      "Iteration 4985, loss = 0.07223979\n",
      "Iteration 4986, loss = 0.07221989\n",
      "Iteration 4987, loss = 0.07220000\n",
      "Iteration 4988, loss = 0.07218012\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 4989, loss = 0.07216024\n",
      "Iteration 4990, loss = 0.07214037\n",
      "Iteration 4991, loss = 0.07212051\n",
      "Iteration 4992, loss = 0.07210066\n",
      "Iteration 4993, loss = 0.07208083\n",
      "Iteration 4994, loss = 0.07206101\n",
      "Iteration 4995, loss = 0.07204119\n",
      "Iteration 4996, loss = 0.07202138\n",
      "Iteration 4997, loss = 0.07200158\n",
      "Iteration 4998, loss = 0.07198179\n",
      "Iteration 4999, loss = 0.07196200\n",
      "Iteration 5000, loss = 0.07194222\n",
      "Iteration 5001, loss = 0.07192245\n",
      "Iteration 5002, loss = 0.07190268\n",
      "Iteration 5003, loss = 0.07188291\n",
      "Iteration 5004, loss = 0.07186316\n",
      "Iteration 5005, loss = 0.07184341\n",
      "Iteration 5006, loss = 0.07182366\n",
      "Iteration 5007, loss = 0.07180392\n",
      "Iteration 5008, loss = 0.07178418\n",
      "Iteration 5009, loss = 0.07176445\n",
      "Iteration 5010, loss = 0.07174473\n",
      "Iteration 5011, loss = 0.07172501\n",
      "Iteration 5012, loss = 0.07170530\n",
      "Iteration 5013, loss = 0.07168559\n",
      "Iteration 5014, loss = 0.07166588\n",
      "Iteration 5015, loss = 0.07164619\n",
      "Iteration 5016, loss = 0.07162649\n",
      "Iteration 5017, loss = 0.07160681\n",
      "Iteration 5018, loss = 0.07158712\n",
      "Iteration 5019, loss = 0.07156744\n",
      "Iteration 5020, loss = 0.07154777\n",
      "Iteration 5021, loss = 0.07152818\n",
      "Iteration 5022, loss = 0.07150864\n",
      "Iteration 5023, loss = 0.07148911\n",
      "Iteration 5024, loss = 0.07146960\n",
      "Iteration 5025, loss = 0.07145009\n",
      "Iteration 5026, loss = 0.07143059\n",
      "Iteration 5027, loss = 0.07141111\n",
      "Iteration 5028, loss = 0.07139163\n",
      "Iteration 5029, loss = 0.07137216\n",
      "Iteration 5030, loss = 0.07135269\n",
      "Iteration 5031, loss = 0.07133324\n",
      "Iteration 5032, loss = 0.07131379\n",
      "Iteration 5033, loss = 0.07129435\n",
      "Iteration 5034, loss = 0.07127492\n",
      "Iteration 5035, loss = 0.07125549\n",
      "Iteration 5036, loss = 0.07123607\n",
      "Iteration 5037, loss = 0.07121665\n",
      "Iteration 5038, loss = 0.07119724\n",
      "Iteration 5039, loss = 0.07117783\n",
      "Iteration 5040, loss = 0.07115838\n",
      "Iteration 5041, loss = 0.07113893\n",
      "Iteration 5042, loss = 0.07111948\n",
      "Iteration 5043, loss = 0.07110004\n",
      "Iteration 5044, loss = 0.07108059\n",
      "Iteration 5045, loss = 0.07106115\n",
      "Iteration 5046, loss = 0.07104170\n",
      "Iteration 5047, loss = 0.07102223\n",
      "Iteration 5048, loss = 0.07100276\n",
      "Iteration 5049, loss = 0.07098330\n",
      "Iteration 5050, loss = 0.07096383\n",
      "Iteration 5051, loss = 0.07094436\n",
      "Iteration 5052, loss = 0.07092490\n",
      "Iteration 5053, loss = 0.07090543\n",
      "Iteration 5054, loss = 0.07088597\n",
      "Iteration 5055, loss = 0.07086651\n",
      "Iteration 5056, loss = 0.07084705\n",
      "Iteration 5057, loss = 0.07082760\n",
      "Iteration 5058, loss = 0.07080815\n",
      "Iteration 5059, loss = 0.07078870\n",
      "Iteration 5060, loss = 0.07076925\n",
      "Iteration 5061, loss = 0.07074981\n",
      "Iteration 5062, loss = 0.07073037\n",
      "Iteration 5063, loss = 0.07071093\n",
      "Iteration 5064, loss = 0.07069150\n",
      "Iteration 5065, loss = 0.07067207\n",
      "Iteration 5066, loss = 0.07065265\n",
      "Iteration 5067, loss = 0.07063323\n",
      "Iteration 5068, loss = 0.07061381\n",
      "Iteration 5069, loss = 0.07059440\n",
      "Iteration 5070, loss = 0.07057499\n",
      "Iteration 5071, loss = 0.07055554\n",
      "Iteration 5072, loss = 0.07053608\n",
      "Iteration 5073, loss = 0.07051662\n",
      "Iteration 5074, loss = 0.07049717\n",
      "Iteration 5075, loss = 0.07047771\n",
      "Iteration 5076, loss = 0.07045826\n",
      "Iteration 5077, loss = 0.07043881\n",
      "Iteration 5078, loss = 0.07041936\n",
      "Iteration 5079, loss = 0.07039992\n",
      "Iteration 5080, loss = 0.07038047\n",
      "Iteration 5081, loss = 0.07036103\n",
      "Iteration 5082, loss = 0.07034159\n",
      "Iteration 5083, loss = 0.07032215\n",
      "Iteration 5084, loss = 0.07030272\n",
      "Iteration 5085, loss = 0.07028329\n",
      "Iteration 5086, loss = 0.07026386\n",
      "Iteration 5087, loss = 0.07024443\n",
      "Iteration 5088, loss = 0.07022501\n",
      "Iteration 5089, loss = 0.07020560\n",
      "Iteration 5090, loss = 0.07018619\n",
      "Iteration 5091, loss = 0.07016678\n",
      "Iteration 5092, loss = 0.07014737\n",
      "Iteration 5093, loss = 0.07012797\n",
      "Iteration 5094, loss = 0.07010857\n",
      "Iteration 5095, loss = 0.07008918\n",
      "Iteration 5096, loss = 0.07006979\n",
      "Iteration 5097, loss = 0.07005041\n",
      "Iteration 5098, loss = 0.07003103\n",
      "Iteration 5099, loss = 0.07001165\n",
      "Iteration 5100, loss = 0.06999227\n",
      "Iteration 5101, loss = 0.06997289\n",
      "Iteration 5102, loss = 0.06995352\n",
      "Iteration 5103, loss = 0.06993415\n",
      "Iteration 5104, loss = 0.06991479\n",
      "Iteration 5105, loss = 0.06989543\n",
      "Iteration 5106, loss = 0.06987608\n",
      "Iteration 5107, loss = 0.06985673\n",
      "Iteration 5108, loss = 0.06983740\n",
      "Iteration 5109, loss = 0.06981807\n",
      "Iteration 5110, loss = 0.06979874\n",
      "Iteration 5111, loss = 0.06977942\n",
      "Iteration 5112, loss = 0.06976011\n",
      "Iteration 5113, loss = 0.06974080\n",
      "Iteration 5114, loss = 0.06972153\n",
      "Iteration 5115, loss = 0.06970227\n",
      "Iteration 5116, loss = 0.06968301\n",
      "Iteration 5117, loss = 0.06966376\n",
      "Iteration 5118, loss = 0.06964452\n",
      "Iteration 5119, loss = 0.06962528\n",
      "Iteration 5120, loss = 0.06960605\n",
      "Iteration 5121, loss = 0.06958684\n",
      "Iteration 5122, loss = 0.06956768\n",
      "Iteration 5123, loss = 0.06954850\n",
      "Iteration 5124, loss = 0.06952933\n",
      "Iteration 5125, loss = 0.06951016\n",
      "Iteration 5126, loss = 0.06949100\n",
      "Iteration 5127, loss = 0.06947186\n",
      "Iteration 5128, loss = 0.06945273\n",
      "Iteration 5129, loss = 0.06943360\n",
      "Iteration 5130, loss = 0.06941449\n",
      "Iteration 5131, loss = 0.06939538\n",
      "Iteration 5132, loss = 0.06937624\n",
      "Iteration 5133, loss = 0.06935710\n",
      "Iteration 5134, loss = 0.06933795\n",
      "Iteration 5135, loss = 0.06931881\n",
      "Iteration 5136, loss = 0.06929967\n",
      "Iteration 5137, loss = 0.06928053\n",
      "Iteration 5138, loss = 0.06926139\n",
      "Iteration 5139, loss = 0.06924226\n",
      "Iteration 5140, loss = 0.06922313\n",
      "Iteration 5141, loss = 0.06920401\n",
      "Iteration 5142, loss = 0.06918489\n",
      "Iteration 5143, loss = 0.06916577\n",
      "Iteration 5144, loss = 0.06914659\n",
      "Iteration 5145, loss = 0.06912736\n",
      "Iteration 5146, loss = 0.06910813\n",
      "Iteration 5147, loss = 0.06908889\n",
      "Iteration 5148, loss = 0.06906965\n",
      "Iteration 5149, loss = 0.06905041\n",
      "Iteration 5150, loss = 0.06903116\n",
      "Iteration 5151, loss = 0.06901192\n",
      "Iteration 5152, loss = 0.06899267\n",
      "Iteration 5153, loss = 0.06897343\n",
      "Iteration 5154, loss = 0.06895418\n",
      "Iteration 5155, loss = 0.06893494\n",
      "Iteration 5156, loss = 0.06891570\n",
      "Iteration 5157, loss = 0.06889646\n",
      "Iteration 5158, loss = 0.06887723\n",
      "Iteration 5159, loss = 0.06885799\n",
      "Iteration 5160, loss = 0.06883876\n",
      "Iteration 5161, loss = 0.06881953\n",
      "Iteration 5162, loss = 0.06880031\n",
      "Iteration 5163, loss = 0.06878109\n",
      "Iteration 5164, loss = 0.06876187\n",
      "Iteration 5165, loss = 0.06874265\n",
      "Iteration 5166, loss = 0.06872344\n",
      "Iteration 5167, loss = 0.06870423\n",
      "Iteration 5168, loss = 0.06868503\n",
      "Iteration 5169, loss = 0.06866583\n",
      "Iteration 5170, loss = 0.06864664\n",
      "Iteration 5171, loss = 0.06862745\n",
      "Iteration 5172, loss = 0.06860826\n",
      "Iteration 5173, loss = 0.06858908\n",
      "Iteration 5174, loss = 0.06856994\n",
      "Iteration 5175, loss = 0.06855085\n",
      "Iteration 5176, loss = 0.06853166\n",
      "Iteration 5177, loss = 0.06851249\n",
      "Iteration 5178, loss = 0.06849328\n",
      "Iteration 5179, loss = 0.06847404\n",
      "Iteration 5180, loss = 0.06845480\n",
      "Iteration 5181, loss = 0.06843559\n",
      "Iteration 5182, loss = 0.06841638\n",
      "Iteration 5183, loss = 0.06839721\n",
      "Iteration 5184, loss = 0.06837804\n",
      "Iteration 5185, loss = 0.06835887\n",
      "Iteration 5186, loss = 0.06833971\n",
      "Iteration 5187, loss = 0.06832055\n",
      "Iteration 5188, loss = 0.06830139\n",
      "Iteration 5189, loss = 0.06828224\n",
      "Iteration 5190, loss = 0.06826309\n",
      "Iteration 5191, loss = 0.06824392\n",
      "Iteration 5192, loss = 0.06822477\n",
      "Iteration 5193, loss = 0.06820565\n",
      "Iteration 5194, loss = 0.06818652\n",
      "Iteration 5195, loss = 0.06816736\n",
      "Iteration 5196, loss = 0.06814819\n",
      "Iteration 5197, loss = 0.06812901\n",
      "Iteration 5198, loss = 0.06810983\n",
      "Iteration 5199, loss = 0.06809066\n",
      "Iteration 5200, loss = 0.06807146\n",
      "Iteration 5201, loss = 0.06805223\n",
      "Iteration 5202, loss = 0.06803318\n",
      "Iteration 5203, loss = 0.06801413\n",
      "Iteration 5204, loss = 0.06799508\n",
      "Iteration 5205, loss = 0.06797603\n",
      "Iteration 5206, loss = 0.06795699\n",
      "Iteration 5207, loss = 0.06793794\n",
      "Iteration 5208, loss = 0.06791890\n",
      "Iteration 5209, loss = 0.06789990\n",
      "Iteration 5210, loss = 0.06788093\n",
      "Iteration 5211, loss = 0.06786198\n",
      "Iteration 5212, loss = 0.06784311\n",
      "Iteration 5213, loss = 0.06782426\n",
      "Iteration 5214, loss = 0.06780543\n",
      "Iteration 5215, loss = 0.06778661\n",
      "Iteration 5216, loss = 0.06776780\n",
      "Iteration 5217, loss = 0.06774901\n",
      "Iteration 5218, loss = 0.06773023\n",
      "Iteration 5219, loss = 0.06771146\n",
      "Iteration 5220, loss = 0.06769270\n",
      "Iteration 5221, loss = 0.06767396\n",
      "Iteration 5222, loss = 0.06765522\n",
      "Iteration 5223, loss = 0.06763648\n",
      "Iteration 5224, loss = 0.06761772\n",
      "Iteration 5225, loss = 0.06759897\n",
      "Iteration 5226, loss = 0.06758022\n",
      "Iteration 5227, loss = 0.06756149\n",
      "Iteration 5228, loss = 0.06754275\n",
      "Iteration 5229, loss = 0.06752403\n",
      "Iteration 5230, loss = 0.06750531\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 5231, loss = 0.06748660\n",
      "Iteration 5232, loss = 0.06746792\n",
      "Iteration 5233, loss = 0.06744925\n",
      "Iteration 5234, loss = 0.06743058\n",
      "Iteration 5235, loss = 0.06741192\n",
      "Iteration 5236, loss = 0.06739327\n",
      "Iteration 5237, loss = 0.06737461\n",
      "Iteration 5238, loss = 0.06735592\n",
      "Iteration 5239, loss = 0.06733724\n",
      "Iteration 5240, loss = 0.06731856\n",
      "Iteration 5241, loss = 0.06729988\n",
      "Iteration 5242, loss = 0.06728121\n",
      "Iteration 5243, loss = 0.06726259\n",
      "Iteration 5244, loss = 0.06724398\n",
      "Iteration 5245, loss = 0.06722538\n",
      "Iteration 5246, loss = 0.06720679\n",
      "Iteration 5247, loss = 0.06718821\n",
      "Iteration 5248, loss = 0.06716964\n",
      "Iteration 5249, loss = 0.06715110\n",
      "Iteration 5250, loss = 0.06713259\n",
      "Iteration 5251, loss = 0.06711408\n",
      "Iteration 5252, loss = 0.06709559\n",
      "Iteration 5253, loss = 0.06707711\n",
      "Iteration 5254, loss = 0.06705864\n",
      "Iteration 5255, loss = 0.06704023\n",
      "Iteration 5256, loss = 0.06702183\n",
      "Iteration 5257, loss = 0.06700345\n",
      "Iteration 5258, loss = 0.06698507\n",
      "Iteration 5259, loss = 0.06696671\n",
      "Iteration 5260, loss = 0.06694842\n",
      "Iteration 5261, loss = 0.06693018\n",
      "Iteration 5262, loss = 0.06691195\n",
      "Iteration 5263, loss = 0.06689374\n",
      "Iteration 5264, loss = 0.06687553\n",
      "Iteration 5265, loss = 0.06685736\n",
      "Iteration 5266, loss = 0.06683921\n",
      "Iteration 5267, loss = 0.06682107\n",
      "Iteration 5268, loss = 0.06680294\n",
      "Iteration 5269, loss = 0.06678482\n",
      "Iteration 5270, loss = 0.06676671\n",
      "Iteration 5271, loss = 0.06674861\n",
      "Iteration 5272, loss = 0.06673052\n",
      "Iteration 5273, loss = 0.06671244\n",
      "Iteration 5274, loss = 0.06669437\n",
      "Iteration 5275, loss = 0.06667631\n",
      "Iteration 5276, loss = 0.06665825\n",
      "Iteration 5277, loss = 0.06664020\n",
      "Iteration 5278, loss = 0.06662216\n",
      "Iteration 5279, loss = 0.06660413\n",
      "Iteration 5280, loss = 0.06658607\n",
      "Iteration 5281, loss = 0.06656800\n",
      "Iteration 5282, loss = 0.06654993\n",
      "Iteration 5283, loss = 0.06653187\n",
      "Iteration 5284, loss = 0.06651381\n",
      "Iteration 5285, loss = 0.06649575\n",
      "Iteration 5286, loss = 0.06647770\n",
      "Iteration 5287, loss = 0.06645965\n",
      "Iteration 5288, loss = 0.06644160\n",
      "Iteration 5289, loss = 0.06642356\n",
      "Iteration 5290, loss = 0.06640552\n",
      "Iteration 5291, loss = 0.06638749\n",
      "Iteration 5292, loss = 0.06636946\n",
      "Iteration 5293, loss = 0.06635143\n",
      "Iteration 5294, loss = 0.06633341\n",
      "Iteration 5295, loss = 0.06631540\n",
      "Iteration 5296, loss = 0.06629738\n",
      "Iteration 5297, loss = 0.06627938\n",
      "Iteration 5298, loss = 0.06626138\n",
      "Iteration 5299, loss = 0.06624338\n",
      "Iteration 5300, loss = 0.06622539\n",
      "Iteration 5301, loss = 0.06620740\n",
      "Iteration 5302, loss = 0.06618942\n",
      "Iteration 5303, loss = 0.06617144\n",
      "Iteration 5304, loss = 0.06615347\n",
      "Iteration 5305, loss = 0.06613551\n",
      "Iteration 5306, loss = 0.06611754\n",
      "Iteration 5307, loss = 0.06609959\n",
      "Iteration 5308, loss = 0.06608164\n",
      "Iteration 5309, loss = 0.06606369\n",
      "Iteration 5310, loss = 0.06604574\n",
      "Iteration 5311, loss = 0.06602778\n",
      "Iteration 5312, loss = 0.06600983\n",
      "Iteration 5313, loss = 0.06599188\n",
      "Iteration 5314, loss = 0.06597394\n",
      "Iteration 5315, loss = 0.06595605\n",
      "Iteration 5316, loss = 0.06593820\n",
      "Iteration 5317, loss = 0.06592036\n",
      "Iteration 5318, loss = 0.06590253\n",
      "Iteration 5319, loss = 0.06588471\n",
      "Iteration 5320, loss = 0.06586690\n",
      "Iteration 5321, loss = 0.06584909\n",
      "Iteration 5322, loss = 0.06583130\n",
      "Iteration 5323, loss = 0.06581351\n",
      "Iteration 5324, loss = 0.06579573\n",
      "Iteration 5325, loss = 0.06577795\n",
      "Iteration 5326, loss = 0.06576018\n",
      "Iteration 5327, loss = 0.06574242\n",
      "Iteration 5328, loss = 0.06572467\n",
      "Iteration 5329, loss = 0.06570692\n",
      "Iteration 5330, loss = 0.06568918\n",
      "Iteration 5331, loss = 0.06567145\n",
      "Iteration 5332, loss = 0.06565372\n",
      "Iteration 5333, loss = 0.06563599\n",
      "Iteration 5334, loss = 0.06561826\n",
      "Iteration 5335, loss = 0.06560054\n",
      "Iteration 5336, loss = 0.06558280\n",
      "Iteration 5337, loss = 0.06556506\n",
      "Iteration 5338, loss = 0.06554732\n",
      "Iteration 5339, loss = 0.06552959\n",
      "Iteration 5340, loss = 0.06551185\n",
      "Iteration 5341, loss = 0.06549413\n",
      "Iteration 5342, loss = 0.06547640\n",
      "Iteration 5343, loss = 0.06545868\n",
      "Iteration 5344, loss = 0.06544096\n",
      "Iteration 5345, loss = 0.06542324\n",
      "Iteration 5346, loss = 0.06540552\n",
      "Iteration 5347, loss = 0.06538781\n",
      "Iteration 5348, loss = 0.06537010\n",
      "Iteration 5349, loss = 0.06535239\n",
      "Iteration 5350, loss = 0.06533469\n",
      "Iteration 5351, loss = 0.06531699\n",
      "Iteration 5352, loss = 0.06529930\n",
      "Iteration 5353, loss = 0.06528161\n",
      "Iteration 5354, loss = 0.06526393\n",
      "Iteration 5355, loss = 0.06524625\n",
      "Iteration 5356, loss = 0.06522857\n",
      "Iteration 5357, loss = 0.06521090\n",
      "Iteration 5358, loss = 0.06519323\n",
      "Iteration 5359, loss = 0.06517557\n",
      "Iteration 5360, loss = 0.06515791\n",
      "Iteration 5361, loss = 0.06514026\n",
      "Iteration 5362, loss = 0.06512261\n",
      "Iteration 5363, loss = 0.06510498\n",
      "Iteration 5364, loss = 0.06508736\n",
      "Iteration 5365, loss = 0.06506975\n",
      "Iteration 5366, loss = 0.06505214\n",
      "Iteration 5367, loss = 0.06503454\n",
      "Iteration 5368, loss = 0.06501695\n",
      "Iteration 5369, loss = 0.06499936\n",
      "Iteration 5370, loss = 0.06498177\n",
      "Iteration 5371, loss = 0.06496418\n",
      "Iteration 5372, loss = 0.06494658\n",
      "Iteration 5373, loss = 0.06492894\n",
      "Iteration 5374, loss = 0.06491130\n",
      "Iteration 5375, loss = 0.06489365\n",
      "Iteration 5376, loss = 0.06487600\n",
      "Iteration 5377, loss = 0.06485833\n",
      "Iteration 5378, loss = 0.06484069\n",
      "Iteration 5379, loss = 0.06482314\n",
      "Iteration 5380, loss = 0.06480559\n",
      "Iteration 5381, loss = 0.06478804\n",
      "Iteration 5382, loss = 0.06477051\n",
      "Iteration 5383, loss = 0.06475298\n",
      "Iteration 5384, loss = 0.06473546\n",
      "Iteration 5385, loss = 0.06471795\n",
      "Iteration 5386, loss = 0.06470044\n",
      "Iteration 5387, loss = 0.06468294\n",
      "Iteration 5388, loss = 0.06466544\n",
      "Iteration 5389, loss = 0.06464795\n",
      "Iteration 5390, loss = 0.06463047\n",
      "Iteration 5391, loss = 0.06461299\n",
      "Iteration 5392, loss = 0.06459552\n",
      "Iteration 5393, loss = 0.06457805\n",
      "Iteration 5394, loss = 0.06456059\n",
      "Iteration 5395, loss = 0.06454315\n",
      "Iteration 5396, loss = 0.06452574\n",
      "Iteration 5397, loss = 0.06450833\n",
      "Iteration 5398, loss = 0.06449093\n",
      "Iteration 5399, loss = 0.06447354\n",
      "Iteration 5400, loss = 0.06445615\n",
      "Iteration 5401, loss = 0.06443878\n",
      "Iteration 5402, loss = 0.06442141\n",
      "Iteration 5403, loss = 0.06440404\n",
      "Iteration 5404, loss = 0.06438668\n",
      "Iteration 5405, loss = 0.06436932\n",
      "Iteration 5406, loss = 0.06435197\n",
      "Iteration 5407, loss = 0.06433462\n",
      "Iteration 5408, loss = 0.06431728\n",
      "Iteration 5409, loss = 0.06429995\n",
      "Iteration 5410, loss = 0.06428259\n",
      "Iteration 5411, loss = 0.06426523\n",
      "Iteration 5412, loss = 0.06424788\n",
      "Iteration 5413, loss = 0.06423052\n",
      "Iteration 5414, loss = 0.06421318\n",
      "Iteration 5415, loss = 0.06419585\n",
      "Iteration 5416, loss = 0.06417848\n",
      "Iteration 5417, loss = 0.06416109\n",
      "Iteration 5418, loss = 0.06414371\n",
      "Iteration 5419, loss = 0.06412632\n",
      "Iteration 5420, loss = 0.06410893\n",
      "Iteration 5421, loss = 0.06409154\n",
      "Iteration 5422, loss = 0.06407415\n",
      "Iteration 5423, loss = 0.06405676\n",
      "Iteration 5424, loss = 0.06403938\n",
      "Iteration 5425, loss = 0.06402199\n",
      "Iteration 5426, loss = 0.06400461\n",
      "Iteration 5427, loss = 0.06398723\n",
      "Iteration 5428, loss = 0.06396985\n",
      "Iteration 5429, loss = 0.06395248\n",
      "Iteration 5430, loss = 0.06393511\n",
      "Iteration 5431, loss = 0.06391774\n",
      "Iteration 5432, loss = 0.06390037\n",
      "Iteration 5433, loss = 0.06388301\n",
      "Iteration 5434, loss = 0.06386566\n",
      "Iteration 5435, loss = 0.06384833\n",
      "Iteration 5436, loss = 0.06383104\n",
      "Iteration 5437, loss = 0.06381374\n",
      "Iteration 5438, loss = 0.06379643\n",
      "Iteration 5439, loss = 0.06377911\n",
      "Iteration 5440, loss = 0.06376180\n",
      "Iteration 5441, loss = 0.06374450\n",
      "Iteration 5442, loss = 0.06372720\n",
      "Iteration 5443, loss = 0.06370991\n",
      "Iteration 5444, loss = 0.06369263\n",
      "Iteration 5445, loss = 0.06367533\n",
      "Iteration 5446, loss = 0.06365802\n",
      "Iteration 5447, loss = 0.06364072\n",
      "Iteration 5448, loss = 0.06362342\n",
      "Iteration 5449, loss = 0.06360613\n",
      "Iteration 5450, loss = 0.06358883\n",
      "Iteration 5451, loss = 0.06357154\n",
      "Iteration 5452, loss = 0.06355426\n",
      "Iteration 5453, loss = 0.06353697\n",
      "Iteration 5454, loss = 0.06351969\n",
      "Iteration 5455, loss = 0.06350242\n",
      "Iteration 5456, loss = 0.06348515\n",
      "Iteration 5457, loss = 0.06346789\n",
      "Iteration 5458, loss = 0.06345069\n",
      "Iteration 5459, loss = 0.06343351\n",
      "Iteration 5460, loss = 0.06341636\n",
      "Iteration 5461, loss = 0.06339920\n",
      "Iteration 5462, loss = 0.06338207\n",
      "Iteration 5463, loss = 0.06336496\n",
      "Iteration 5464, loss = 0.06334781\n",
      "Iteration 5465, loss = 0.06333065\n",
      "Iteration 5466, loss = 0.06331351\n",
      "Iteration 5467, loss = 0.06329636\n",
      "Iteration 5468, loss = 0.06327922\n",
      "Iteration 5469, loss = 0.06326209\n",
      "Iteration 5470, loss = 0.06324495\n",
      "Iteration 5471, loss = 0.06322783\n",
      "Iteration 5472, loss = 0.06321071\n",
      "Iteration 5473, loss = 0.06319360\n",
      "Iteration 5474, loss = 0.06317650\n",
      "Iteration 5475, loss = 0.06315940\n",
      "Iteration 5476, loss = 0.06314230\n",
      "Iteration 5477, loss = 0.06312521\n",
      "Iteration 5478, loss = 0.06310813\n",
      "Iteration 5479, loss = 0.06309105\n",
      "Iteration 5480, loss = 0.06307398\n",
      "Iteration 5481, loss = 0.06305697\n",
      "Iteration 5482, loss = 0.06304016\n",
      "Iteration 5483, loss = 0.06302337\n",
      "Iteration 5484, loss = 0.06300660\n",
      "Iteration 5485, loss = 0.06298985\n",
      "Iteration 5486, loss = 0.06297312\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 5487, loss = 0.06295641\n",
      "Iteration 5488, loss = 0.06293967\n",
      "Iteration 5489, loss = 0.06292292\n",
      "Iteration 5490, loss = 0.06290619\n",
      "Iteration 5491, loss = 0.06288956\n",
      "Iteration 5492, loss = 0.06287295\n",
      "Iteration 5493, loss = 0.06285635\n",
      "Iteration 5494, loss = 0.06283977\n",
      "Iteration 5495, loss = 0.06282319\n",
      "Iteration 5496, loss = 0.06280663\n",
      "Iteration 5497, loss = 0.06279009\n",
      "Iteration 5498, loss = 0.06277355\n",
      "Iteration 5499, loss = 0.06275703\n",
      "Iteration 5500, loss = 0.06274051\n",
      "Iteration 5501, loss = 0.06272401\n",
      "Iteration 5502, loss = 0.06270752\n",
      "Iteration 5503, loss = 0.06269103\n",
      "Iteration 5504, loss = 0.06267455\n",
      "Iteration 5505, loss = 0.06265807\n",
      "Iteration 5506, loss = 0.06264156\n",
      "Iteration 5507, loss = 0.06262506\n",
      "Iteration 5508, loss = 0.06260856\n",
      "Iteration 5509, loss = 0.06259206\n",
      "Iteration 5510, loss = 0.06257557\n",
      "Iteration 5511, loss = 0.06255908\n",
      "Iteration 5512, loss = 0.06254259\n",
      "Iteration 5513, loss = 0.06252611\n",
      "Iteration 5514, loss = 0.06250967\n",
      "Iteration 5515, loss = 0.06249323\n",
      "Iteration 5516, loss = 0.06247679\n",
      "Iteration 5517, loss = 0.06246035\n",
      "Iteration 5518, loss = 0.06244392\n",
      "Iteration 5519, loss = 0.06242749\n",
      "Iteration 5520, loss = 0.06241106\n",
      "Iteration 5521, loss = 0.06239464\n",
      "Iteration 5522, loss = 0.06237823\n",
      "Iteration 5523, loss = 0.06236182\n",
      "Iteration 5524, loss = 0.06234543\n",
      "Iteration 5525, loss = 0.06232906\n",
      "Iteration 5526, loss = 0.06231269\n",
      "Iteration 5527, loss = 0.06229633\n",
      "Iteration 5528, loss = 0.06227997\n",
      "Iteration 5529, loss = 0.06226362\n",
      "Iteration 5530, loss = 0.06224729\n",
      "Iteration 5531, loss = 0.06223097\n",
      "Iteration 5532, loss = 0.06221466\n",
      "Iteration 5533, loss = 0.06219835\n",
      "Iteration 5534, loss = 0.06218205\n",
      "Iteration 5535, loss = 0.06216576\n",
      "Iteration 5536, loss = 0.06214947\n",
      "Iteration 5537, loss = 0.06213319\n",
      "Iteration 5538, loss = 0.06211692\n",
      "Iteration 5539, loss = 0.06210064\n",
      "Iteration 5540, loss = 0.06208438\n",
      "Iteration 5541, loss = 0.06206813\n",
      "Iteration 5542, loss = 0.06205188\n",
      "Iteration 5543, loss = 0.06203560\n",
      "Iteration 5544, loss = 0.06201931\n",
      "Iteration 5545, loss = 0.06200303\n",
      "Iteration 5546, loss = 0.06198674\n",
      "Iteration 5547, loss = 0.06197046\n",
      "Iteration 5548, loss = 0.06195418\n",
      "Iteration 5549, loss = 0.06193790\n",
      "Iteration 5550, loss = 0.06192162\n",
      "Iteration 5551, loss = 0.06190534\n",
      "Iteration 5552, loss = 0.06188907\n",
      "Iteration 5553, loss = 0.06187280\n",
      "Iteration 5554, loss = 0.06185653\n",
      "Iteration 5555, loss = 0.06184027\n",
      "Iteration 5556, loss = 0.06182401\n",
      "Iteration 5557, loss = 0.06180776\n",
      "Iteration 5558, loss = 0.06179150\n",
      "Iteration 5559, loss = 0.06177526\n",
      "Iteration 5560, loss = 0.06175901\n",
      "Iteration 5561, loss = 0.06174277\n",
      "Iteration 5562, loss = 0.06172654\n",
      "Iteration 5563, loss = 0.06171031\n",
      "Iteration 5564, loss = 0.06169408\n",
      "Iteration 5565, loss = 0.06167782\n",
      "Iteration 5566, loss = 0.06166156\n",
      "Iteration 5567, loss = 0.06164531\n",
      "Iteration 5568, loss = 0.06162906\n",
      "Iteration 5569, loss = 0.06161277\n",
      "Iteration 5570, loss = 0.06159648\n",
      "Iteration 5571, loss = 0.06158019\n",
      "Iteration 5572, loss = 0.06156392\n",
      "Iteration 5573, loss = 0.06154770\n",
      "Iteration 5574, loss = 0.06153148\n",
      "Iteration 5575, loss = 0.06151527\n",
      "Iteration 5576, loss = 0.06149907\n",
      "Iteration 5577, loss = 0.06148288\n",
      "Iteration 5578, loss = 0.06146669\n",
      "Iteration 5579, loss = 0.06145050\n",
      "Iteration 5580, loss = 0.06143432\n",
      "Iteration 5581, loss = 0.06141807\n",
      "Iteration 5582, loss = 0.06140182\n",
      "Iteration 5583, loss = 0.06138556\n",
      "Iteration 5584, loss = 0.06136930\n",
      "Iteration 5585, loss = 0.06135304\n",
      "Iteration 5586, loss = 0.06133678\n",
      "Iteration 5587, loss = 0.06132052\n",
      "Iteration 5588, loss = 0.06130426\n",
      "Iteration 5589, loss = 0.06128800\n",
      "Iteration 5590, loss = 0.06127174\n",
      "Iteration 5591, loss = 0.06125543\n",
      "Iteration 5592, loss = 0.06123906\n",
      "Iteration 5593, loss = 0.06122269\n",
      "Iteration 5594, loss = 0.06120631\n",
      "Iteration 5595, loss = 0.06118992\n",
      "Iteration 5596, loss = 0.06117353\n",
      "Iteration 5597, loss = 0.06115713\n",
      "Iteration 5598, loss = 0.06114073\n",
      "Iteration 5599, loss = 0.06112433\n",
      "Iteration 5600, loss = 0.06110793\n",
      "Iteration 5601, loss = 0.06109153\n",
      "Iteration 5602, loss = 0.06107514\n",
      "Iteration 5603, loss = 0.06105874\n",
      "Iteration 5604, loss = 0.06104235\n",
      "Iteration 5605, loss = 0.06102600\n",
      "Iteration 5606, loss = 0.06100966\n",
      "Iteration 5607, loss = 0.06099333\n",
      "Iteration 5608, loss = 0.06097701\n",
      "Iteration 5609, loss = 0.06096069\n",
      "Iteration 5610, loss = 0.06094438\n",
      "Iteration 5611, loss = 0.06092810\n",
      "Iteration 5612, loss = 0.06091186\n",
      "Iteration 5613, loss = 0.06089552\n",
      "Iteration 5614, loss = 0.06087913\n",
      "Iteration 5615, loss = 0.06086274\n",
      "Iteration 5616, loss = 0.06084634\n",
      "Iteration 5617, loss = 0.06082993\n",
      "Iteration 5618, loss = 0.06081353\n",
      "Iteration 5619, loss = 0.06079712\n",
      "Iteration 5620, loss = 0.06078072\n",
      "Iteration 5621, loss = 0.06076430\n",
      "Iteration 5622, loss = 0.06074788\n",
      "Iteration 5623, loss = 0.06073145\n",
      "Iteration 5624, loss = 0.06071502\n",
      "Iteration 5625, loss = 0.06069860\n",
      "Iteration 5626, loss = 0.06068218\n",
      "Iteration 5627, loss = 0.06066576\n",
      "Iteration 5628, loss = 0.06064934\n",
      "Iteration 5629, loss = 0.06063293\n",
      "Iteration 5630, loss = 0.06061652\n",
      "Iteration 5631, loss = 0.06060018\n",
      "Iteration 5632, loss = 0.06058383\n",
      "Iteration 5633, loss = 0.06056745\n",
      "Iteration 5634, loss = 0.06055101\n",
      "Iteration 5635, loss = 0.06053457\n",
      "Iteration 5636, loss = 0.06051812\n",
      "Iteration 5637, loss = 0.06050166\n",
      "Iteration 5638, loss = 0.06048520\n",
      "Iteration 5639, loss = 0.06046874\n",
      "Iteration 5640, loss = 0.06045229\n",
      "Iteration 5641, loss = 0.06043585\n",
      "Iteration 5642, loss = 0.06041942\n",
      "Iteration 5643, loss = 0.06040299\n",
      "Iteration 5644, loss = 0.06038659\n",
      "Iteration 5645, loss = 0.06037022\n",
      "Iteration 5646, loss = 0.06035385\n",
      "Iteration 5647, loss = 0.06033748\n",
      "Iteration 5648, loss = 0.06032111\n",
      "Iteration 5649, loss = 0.06030469\n",
      "Iteration 5650, loss = 0.06028825\n",
      "Iteration 5651, loss = 0.06027181\n",
      "Iteration 5652, loss = 0.06025536\n",
      "Iteration 5653, loss = 0.06023891\n",
      "Iteration 5654, loss = 0.06022248\n",
      "Iteration 5655, loss = 0.06020607\n",
      "Iteration 5656, loss = 0.06018964\n",
      "Iteration 5657, loss = 0.06017320\n",
      "Iteration 5658, loss = 0.06015676\n",
      "Iteration 5659, loss = 0.06014034\n",
      "Iteration 5660, loss = 0.06012391\n",
      "Iteration 5661, loss = 0.06010750\n",
      "Iteration 5662, loss = 0.06009109\n",
      "Iteration 5663, loss = 0.06007469\n",
      "Iteration 5664, loss = 0.06005828\n",
      "Iteration 5665, loss = 0.06004187\n",
      "Iteration 5666, loss = 0.06002547\n",
      "Iteration 5667, loss = 0.06000908\n",
      "Iteration 5668, loss = 0.05999270\n",
      "Iteration 5669, loss = 0.05997632\n",
      "Iteration 5670, loss = 0.05995995\n",
      "Iteration 5671, loss = 0.05994378\n",
      "Iteration 5672, loss = 0.05992777\n",
      "Iteration 5673, loss = 0.05991178\n",
      "Iteration 5674, loss = 0.05989581\n",
      "Iteration 5675, loss = 0.05987985\n",
      "Iteration 5676, loss = 0.05986390\n",
      "Iteration 5677, loss = 0.05984798\n",
      "Iteration 5678, loss = 0.05983208\n",
      "Iteration 5679, loss = 0.05981619\n",
      "Iteration 5680, loss = 0.05980031\n",
      "Iteration 5681, loss = 0.05978444\n",
      "Iteration 5682, loss = 0.05976860\n",
      "Iteration 5683, loss = 0.05975276\n",
      "Iteration 5684, loss = 0.05973693\n",
      "Iteration 5685, loss = 0.05972111\n",
      "Iteration 5686, loss = 0.05970530\n",
      "Iteration 5687, loss = 0.05968951\n",
      "Iteration 5688, loss = 0.05967372\n",
      "Iteration 5689, loss = 0.05965794\n",
      "Iteration 5690, loss = 0.05964217\n",
      "Iteration 5691, loss = 0.05962642\n",
      "Iteration 5692, loss = 0.05961068\n",
      "Iteration 5693, loss = 0.05959495\n",
      "Iteration 5694, loss = 0.05957923\n",
      "Iteration 5695, loss = 0.05956351\n",
      "Iteration 5696, loss = 0.05954781\n",
      "Iteration 5697, loss = 0.05953211\n",
      "Iteration 5698, loss = 0.05951641\n",
      "Iteration 5699, loss = 0.05950073\n",
      "Iteration 5700, loss = 0.05948506\n",
      "Iteration 5701, loss = 0.05946939\n",
      "Iteration 5702, loss = 0.05945372\n",
      "Iteration 5703, loss = 0.05943806\n",
      "Iteration 5704, loss = 0.05942242\n",
      "Iteration 5705, loss = 0.05940678\n",
      "Iteration 5706, loss = 0.05939116\n",
      "Iteration 5707, loss = 0.05937553\n",
      "Iteration 5708, loss = 0.05935992\n",
      "Iteration 5709, loss = 0.05934431\n",
      "Iteration 5710, loss = 0.05932871\n",
      "Iteration 5711, loss = 0.05931311\n",
      "Iteration 5712, loss = 0.05929753\n",
      "Iteration 5713, loss = 0.05928195\n",
      "Iteration 5714, loss = 0.05926637\n",
      "Iteration 5715, loss = 0.05925080\n",
      "Iteration 5716, loss = 0.05923524\n",
      "Iteration 5717, loss = 0.05921968\n",
      "Iteration 5718, loss = 0.05920413\n",
      "Iteration 5719, loss = 0.05918858\n",
      "Iteration 5720, loss = 0.05917304\n",
      "Iteration 5721, loss = 0.05915752\n",
      "Iteration 5722, loss = 0.05914199\n",
      "Iteration 5723, loss = 0.05912647\n",
      "Iteration 5724, loss = 0.05911096\n",
      "Iteration 5725, loss = 0.05909545\n",
      "Iteration 5726, loss = 0.05907995\n",
      "Iteration 5727, loss = 0.05906447\n",
      "Iteration 5728, loss = 0.05904898\n",
      "Iteration 5729, loss = 0.05903350\n",
      "Iteration 5730, loss = 0.05901803\n",
      "Iteration 5731, loss = 0.05900256\n",
      "Iteration 5732, loss = 0.05898711\n",
      "Iteration 5733, loss = 0.05897166\n",
      "Iteration 5734, loss = 0.05895620\n",
      "Iteration 5735, loss = 0.05894077\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 5736, loss = 0.05892535\n",
      "Iteration 5737, loss = 0.05890992\n",
      "Iteration 5738, loss = 0.05889450\n",
      "Iteration 5739, loss = 0.05887909\n",
      "Iteration 5740, loss = 0.05886368\n",
      "Iteration 5741, loss = 0.05884834\n",
      "Iteration 5742, loss = 0.05883312\n",
      "Iteration 5743, loss = 0.05881788\n",
      "Iteration 5744, loss = 0.05880266\n",
      "Iteration 5745, loss = 0.05878744\n",
      "Iteration 5746, loss = 0.05877237\n",
      "Iteration 5747, loss = 0.05875733\n",
      "Iteration 5748, loss = 0.05874232\n",
      "Iteration 5749, loss = 0.05872733\n",
      "Iteration 5750, loss = 0.05871237\n",
      "Iteration 5751, loss = 0.05869744\n",
      "Iteration 5752, loss = 0.05868252\n",
      "Iteration 5753, loss = 0.05866761\n",
      "Iteration 5754, loss = 0.05865272\n",
      "Iteration 5755, loss = 0.05863782\n",
      "Iteration 5756, loss = 0.05862291\n",
      "Iteration 5757, loss = 0.05860802\n",
      "Iteration 5758, loss = 0.05859313\n",
      "Iteration 5759, loss = 0.05857826\n",
      "Iteration 5760, loss = 0.05856332\n",
      "Iteration 5761, loss = 0.05854818\n",
      "Iteration 5762, loss = 0.05853300\n",
      "Iteration 5763, loss = 0.05851782\n",
      "Iteration 5764, loss = 0.05850263\n",
      "Iteration 5765, loss = 0.05848743\n",
      "Iteration 5766, loss = 0.05847221\n",
      "Iteration 5767, loss = 0.05845699\n",
      "Iteration 5768, loss = 0.05844177\n",
      "Iteration 5769, loss = 0.05842654\n",
      "Iteration 5770, loss = 0.05841134\n",
      "Iteration 5771, loss = 0.05839613\n",
      "Iteration 5772, loss = 0.05838095\n",
      "Iteration 5773, loss = 0.05836580\n",
      "Iteration 5774, loss = 0.05835065\n",
      "Iteration 5775, loss = 0.05833552\n",
      "Iteration 5776, loss = 0.05832041\n",
      "Iteration 5777, loss = 0.05830530\n",
      "Iteration 5778, loss = 0.05829020\n",
      "Iteration 5779, loss = 0.05827512\n",
      "Iteration 5780, loss = 0.05826004\n",
      "Iteration 5781, loss = 0.05824496\n",
      "Iteration 5782, loss = 0.05822988\n",
      "Iteration 5783, loss = 0.05821482\n",
      "Iteration 5784, loss = 0.05819977\n",
      "Iteration 5785, loss = 0.05818472\n",
      "Iteration 5786, loss = 0.05816969\n",
      "Iteration 5787, loss = 0.05815466\n",
      "Iteration 5788, loss = 0.05813963\n",
      "Iteration 5789, loss = 0.05812460\n",
      "Iteration 5790, loss = 0.05810958\n",
      "Iteration 5791, loss = 0.05809459\n",
      "Iteration 5792, loss = 0.05807960\n",
      "Iteration 5793, loss = 0.05806460\n",
      "Iteration 5794, loss = 0.05804965\n",
      "Iteration 5795, loss = 0.05803487\n",
      "Iteration 5796, loss = 0.05802010\n",
      "Iteration 5797, loss = 0.05800535\n",
      "Iteration 5798, loss = 0.05799061\n",
      "Iteration 5799, loss = 0.05797587\n",
      "Iteration 5800, loss = 0.05796116\n",
      "Iteration 5801, loss = 0.05794648\n",
      "Iteration 5802, loss = 0.05793177\n",
      "Iteration 5803, loss = 0.05791708\n",
      "Iteration 5804, loss = 0.05790239\n",
      "Iteration 5805, loss = 0.05788771\n",
      "Iteration 5806, loss = 0.05787304\n",
      "Iteration 5807, loss = 0.05785838\n",
      "Iteration 5808, loss = 0.05784374\n",
      "Iteration 5809, loss = 0.05782911\n",
      "Iteration 5810, loss = 0.05781447\n",
      "Iteration 5811, loss = 0.05779984\n",
      "Iteration 5812, loss = 0.05778522\n",
      "Iteration 5813, loss = 0.05777062\n",
      "Iteration 5814, loss = 0.05775603\n",
      "Iteration 5815, loss = 0.05774147\n",
      "Iteration 5816, loss = 0.05772697\n",
      "Iteration 5817, loss = 0.05771248\n",
      "Iteration 5818, loss = 0.05769799\n",
      "Iteration 5819, loss = 0.05768351\n",
      "Iteration 5820, loss = 0.05766903\n",
      "Iteration 5821, loss = 0.05765457\n",
      "Iteration 5822, loss = 0.05764015\n",
      "Iteration 5823, loss = 0.05762575\n",
      "Iteration 5824, loss = 0.05761134\n",
      "Iteration 5825, loss = 0.05759695\n",
      "Iteration 5826, loss = 0.05758264\n",
      "Iteration 5827, loss = 0.05756836\n",
      "Iteration 5828, loss = 0.05755409\n",
      "Iteration 5829, loss = 0.05753983\n",
      "Iteration 5830, loss = 0.05752557\n",
      "Iteration 5831, loss = 0.05751132\n",
      "Iteration 5832, loss = 0.05749707\n",
      "Iteration 5833, loss = 0.05748282\n",
      "Iteration 5834, loss = 0.05746855\n",
      "Iteration 5835, loss = 0.05745426\n",
      "Iteration 5836, loss = 0.05743999\n",
      "Iteration 5837, loss = 0.05742572\n",
      "Iteration 5838, loss = 0.05741145\n",
      "Iteration 5839, loss = 0.05739719\n",
      "Iteration 5840, loss = 0.05738292\n",
      "Iteration 5841, loss = 0.05736867\n",
      "Iteration 5842, loss = 0.05735441\n",
      "Iteration 5843, loss = 0.05734017\n",
      "Iteration 5844, loss = 0.05732593\n",
      "Iteration 5845, loss = 0.05731169\n",
      "Iteration 5846, loss = 0.05729745\n",
      "Iteration 5847, loss = 0.05728324\n",
      "Iteration 5848, loss = 0.05726904\n",
      "Iteration 5849, loss = 0.05725486\n",
      "Iteration 5850, loss = 0.05724069\n",
      "Iteration 5851, loss = 0.05722653\n",
      "Iteration 5852, loss = 0.05721237\n",
      "Iteration 5853, loss = 0.05719821\n",
      "Iteration 5854, loss = 0.05718406\n",
      "Iteration 5855, loss = 0.05716991\n",
      "Iteration 5856, loss = 0.05715577\n",
      "Iteration 5857, loss = 0.05714163\n",
      "Iteration 5858, loss = 0.05712750\n",
      "Iteration 5859, loss = 0.05711338\n",
      "Iteration 5860, loss = 0.05709925\n",
      "Iteration 5861, loss = 0.05708514\n",
      "Iteration 5862, loss = 0.05707103\n",
      "Iteration 5863, loss = 0.05705694\n",
      "Iteration 5864, loss = 0.05704284\n",
      "Iteration 5865, loss = 0.05702875\n",
      "Iteration 5866, loss = 0.05701466\n",
      "Iteration 5867, loss = 0.05700059\n",
      "Iteration 5868, loss = 0.05698652\n",
      "Iteration 5869, loss = 0.05697243\n",
      "Iteration 5870, loss = 0.05695834\n",
      "Iteration 5871, loss = 0.05694425\n",
      "Iteration 5872, loss = 0.05693017\n",
      "Iteration 5873, loss = 0.05691609\n",
      "Iteration 5874, loss = 0.05690203\n",
      "Iteration 5875, loss = 0.05688798\n",
      "Iteration 5876, loss = 0.05687392\n",
      "Iteration 5877, loss = 0.05685986\n",
      "Iteration 5878, loss = 0.05684582\n",
      "Iteration 5879, loss = 0.05683177\n",
      "Iteration 5880, loss = 0.05681773\n",
      "Iteration 5881, loss = 0.05680369\n",
      "Iteration 5882, loss = 0.05678966\n",
      "Iteration 5883, loss = 0.05677563\n",
      "Iteration 5884, loss = 0.05676160\n",
      "Iteration 5885, loss = 0.05674759\n",
      "Iteration 5886, loss = 0.05673358\n",
      "Iteration 5887, loss = 0.05671959\n",
      "Iteration 5888, loss = 0.05670558\n",
      "Iteration 5889, loss = 0.05669159\n",
      "Iteration 5890, loss = 0.05667760\n",
      "Iteration 5891, loss = 0.05666362\n",
      "Iteration 5892, loss = 0.05664963\n",
      "Iteration 5893, loss = 0.05663565\n",
      "Iteration 5894, loss = 0.05662167\n",
      "Iteration 5895, loss = 0.05660769\n",
      "Iteration 5896, loss = 0.05659372\n",
      "Iteration 5897, loss = 0.05657976\n",
      "Iteration 5898, loss = 0.05656579\n",
      "Iteration 5899, loss = 0.05655184\n",
      "Iteration 5900, loss = 0.05653789\n",
      "Iteration 5901, loss = 0.05652395\n",
      "Iteration 5902, loss = 0.05651001\n",
      "Iteration 5903, loss = 0.05649608\n",
      "Iteration 5904, loss = 0.05648217\n",
      "Iteration 5905, loss = 0.05646827\n",
      "Iteration 5906, loss = 0.05645438\n",
      "Iteration 5907, loss = 0.05644050\n",
      "Iteration 5908, loss = 0.05642662\n",
      "Iteration 5909, loss = 0.05641275\n",
      "Iteration 5910, loss = 0.05639888\n",
      "Iteration 5911, loss = 0.05638502\n",
      "Iteration 5912, loss = 0.05637117\n",
      "Iteration 5913, loss = 0.05635733\n",
      "Iteration 5914, loss = 0.05634349\n",
      "Iteration 5915, loss = 0.05632965\n",
      "Iteration 5916, loss = 0.05631582\n",
      "Iteration 5917, loss = 0.05630200\n",
      "Iteration 5918, loss = 0.05628818\n",
      "Iteration 5919, loss = 0.05627437\n",
      "Iteration 5920, loss = 0.05626057\n",
      "Iteration 5921, loss = 0.05624678\n",
      "Iteration 5922, loss = 0.05623299\n",
      "Iteration 5923, loss = 0.05621920\n",
      "Iteration 5924, loss = 0.05620541\n",
      "Iteration 5925, loss = 0.05619163\n",
      "Iteration 5926, loss = 0.05617786\n",
      "Iteration 5927, loss = 0.05616409\n",
      "Iteration 5928, loss = 0.05615033\n",
      "Iteration 5929, loss = 0.05613657\n",
      "Iteration 5930, loss = 0.05612282\n",
      "Iteration 5931, loss = 0.05610908\n",
      "Iteration 5932, loss = 0.05609534\n",
      "Iteration 5933, loss = 0.05608161\n",
      "Iteration 5934, loss = 0.05606787\n",
      "Iteration 5935, loss = 0.05605414\n",
      "Iteration 5936, loss = 0.05604040\n",
      "Iteration 5937, loss = 0.05602668\n",
      "Iteration 5938, loss = 0.05601296\n",
      "Iteration 5939, loss = 0.05599924\n",
      "Iteration 5940, loss = 0.05598553\n",
      "Iteration 5941, loss = 0.05597182\n",
      "Iteration 5942, loss = 0.05595811\n",
      "Iteration 5943, loss = 0.05594442\n",
      "Iteration 5944, loss = 0.05593072\n",
      "Iteration 5945, loss = 0.05591704\n",
      "Iteration 5946, loss = 0.05590336\n",
      "Iteration 5947, loss = 0.05588969\n",
      "Iteration 5948, loss = 0.05587602\n",
      "Iteration 5949, loss = 0.05586236\n",
      "Iteration 5950, loss = 0.05584870\n",
      "Iteration 5951, loss = 0.05583505\n",
      "Iteration 5952, loss = 0.05582140\n",
      "Iteration 5953, loss = 0.05580776\n",
      "Iteration 5954, loss = 0.05579412\n",
      "Iteration 5955, loss = 0.05578049\n",
      "Iteration 5956, loss = 0.05576687\n",
      "Iteration 5957, loss = 0.05575325\n",
      "Iteration 5958, loss = 0.05573963\n",
      "Iteration 5959, loss = 0.05572604\n",
      "Iteration 5960, loss = 0.05571249\n",
      "Iteration 5961, loss = 0.05569896\n",
      "Iteration 5962, loss = 0.05568543\n",
      "Iteration 5963, loss = 0.05567192\n",
      "Iteration 5964, loss = 0.05565842\n",
      "Iteration 5965, loss = 0.05564492\n",
      "Iteration 5966, loss = 0.05563144\n",
      "Iteration 5967, loss = 0.05561796\n",
      "Iteration 5968, loss = 0.05560449\n",
      "Iteration 5969, loss = 0.05559103\n",
      "Iteration 5970, loss = 0.05557758\n",
      "Iteration 5971, loss = 0.05556413\n",
      "Iteration 5972, loss = 0.05555069\n",
      "Iteration 5973, loss = 0.05553726\n",
      "Iteration 5974, loss = 0.05552384\n",
      "Iteration 5975, loss = 0.05551042\n",
      "Iteration 5976, loss = 0.05549701\n",
      "Iteration 5977, loss = 0.05548360\n",
      "Iteration 5978, loss = 0.05547021\n",
      "Iteration 5979, loss = 0.05545682\n",
      "Iteration 5980, loss = 0.05544343\n",
      "Iteration 5981, loss = 0.05543005\n",
      "Iteration 5982, loss = 0.05541668\n",
      "Iteration 5983, loss = 0.05540332\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 5984, loss = 0.05538996\n",
      "Iteration 5985, loss = 0.05537660\n",
      "Iteration 5986, loss = 0.05536325\n",
      "Iteration 5987, loss = 0.05534991\n",
      "Iteration 5988, loss = 0.05533654\n",
      "Iteration 5989, loss = 0.05532316\n",
      "Iteration 5990, loss = 0.05530979\n",
      "Iteration 5991, loss = 0.05529642\n",
      "Iteration 5992, loss = 0.05528307\n",
      "Iteration 5993, loss = 0.05526972\n",
      "Iteration 5994, loss = 0.05525638\n",
      "Iteration 5995, loss = 0.05524303\n",
      "Iteration 5996, loss = 0.05522970\n",
      "Iteration 5997, loss = 0.05521636\n",
      "Iteration 5998, loss = 0.05520304\n",
      "Iteration 5999, loss = 0.05518972\n",
      "Iteration 6000, loss = 0.05517641\n",
      "Iteration 6001, loss = 0.05516316\n",
      "Iteration 6002, loss = 0.05514997\n",
      "Iteration 6003, loss = 0.05513679\n",
      "Iteration 6004, loss = 0.05512361\n",
      "Iteration 6005, loss = 0.05511044\n",
      "Iteration 6006, loss = 0.05509729\n",
      "Iteration 6007, loss = 0.05508415\n",
      "Iteration 6008, loss = 0.05507101\n",
      "Iteration 6009, loss = 0.05505786\n",
      "Iteration 6010, loss = 0.05504470\n",
      "Iteration 6011, loss = 0.05503155\n",
      "Iteration 6012, loss = 0.05501840\n",
      "Iteration 6013, loss = 0.05500526\n",
      "Iteration 6014, loss = 0.05499212\n",
      "Iteration 6015, loss = 0.05497899\n",
      "Iteration 6016, loss = 0.05496587\n",
      "Iteration 6017, loss = 0.05495275\n",
      "Iteration 6018, loss = 0.05493963\n",
      "Iteration 6019, loss = 0.05492651\n",
      "Iteration 6020, loss = 0.05491340\n",
      "Iteration 6021, loss = 0.05490029\n",
      "Iteration 6022, loss = 0.05488716\n",
      "Iteration 6023, loss = 0.05487403\n",
      "Iteration 6024, loss = 0.05486091\n",
      "Iteration 6025, loss = 0.05484784\n",
      "Iteration 6026, loss = 0.05483485\n",
      "Iteration 6027, loss = 0.05482188\n",
      "Iteration 6028, loss = 0.05480892\n",
      "Iteration 6029, loss = 0.05479597\n",
      "Iteration 6030, loss = 0.05478304\n",
      "Iteration 6031, loss = 0.05477012\n",
      "Iteration 6032, loss = 0.05475722\n",
      "Iteration 6033, loss = 0.05474432\n",
      "Iteration 6034, loss = 0.05473142\n",
      "Iteration 6035, loss = 0.05471854\n",
      "Iteration 6036, loss = 0.05470567\n",
      "Iteration 6037, loss = 0.05469279\n",
      "Iteration 6038, loss = 0.05467992\n",
      "Iteration 6039, loss = 0.05466706\n",
      "Iteration 6040, loss = 0.05465420\n",
      "Iteration 6041, loss = 0.05464134\n",
      "Iteration 6042, loss = 0.05462849\n",
      "Iteration 6043, loss = 0.05461564\n",
      "Iteration 6044, loss = 0.05460280\n",
      "Iteration 6045, loss = 0.05458998\n",
      "Iteration 6046, loss = 0.05457717\n",
      "Iteration 6047, loss = 0.05456437\n",
      "Iteration 6048, loss = 0.05455158\n",
      "Iteration 6049, loss = 0.05453879\n",
      "Iteration 6050, loss = 0.05452601\n",
      "Iteration 6051, loss = 0.05451323\n",
      "Iteration 6052, loss = 0.05450047\n",
      "Iteration 6053, loss = 0.05448771\n",
      "Iteration 6054, loss = 0.05447496\n",
      "Iteration 6055, loss = 0.05446221\n",
      "Iteration 6056, loss = 0.05444947\n",
      "Iteration 6057, loss = 0.05443674\n",
      "Iteration 6058, loss = 0.05442401\n",
      "Iteration 6059, loss = 0.05441129\n",
      "Iteration 6060, loss = 0.05439858\n",
      "Iteration 6061, loss = 0.05438587\n",
      "Iteration 6062, loss = 0.05437317\n",
      "Iteration 6063, loss = 0.05436047\n",
      "Iteration 6064, loss = 0.05434779\n",
      "Iteration 6065, loss = 0.05433510\n",
      "Iteration 6066, loss = 0.05432243\n",
      "Iteration 6067, loss = 0.05430976\n",
      "Iteration 6068, loss = 0.05429709\n",
      "Iteration 6069, loss = 0.05428443\n",
      "Iteration 6070, loss = 0.05427178\n",
      "Iteration 6071, loss = 0.05425913\n",
      "Iteration 6072, loss = 0.05424647\n",
      "Iteration 6073, loss = 0.05423381\n",
      "Iteration 6074, loss = 0.05422116\n",
      "Iteration 6075, loss = 0.05420851\n",
      "Iteration 6076, loss = 0.05419587\n",
      "Iteration 6077, loss = 0.05418323\n",
      "Iteration 6078, loss = 0.05417060\n",
      "Iteration 6079, loss = 0.05415797\n",
      "Iteration 6080, loss = 0.05414531\n",
      "Iteration 6081, loss = 0.05413265\n",
      "Iteration 6082, loss = 0.05412000\n",
      "Iteration 6083, loss = 0.05410734\n",
      "Iteration 6084, loss = 0.05409469\n",
      "Iteration 6085, loss = 0.05408204\n",
      "Iteration 6086, loss = 0.05406940\n",
      "Iteration 6087, loss = 0.05405675\n",
      "Iteration 6088, loss = 0.05404411\n",
      "Iteration 6089, loss = 0.05403147\n",
      "Iteration 6090, loss = 0.05401878\n",
      "Iteration 6091, loss = 0.05400609\n",
      "Iteration 6092, loss = 0.05399340\n",
      "Iteration 6093, loss = 0.05398071\n",
      "Iteration 6094, loss = 0.05396801\n",
      "Iteration 6095, loss = 0.05395532\n",
      "Iteration 6096, loss = 0.05394263\n",
      "Iteration 6097, loss = 0.05392994\n",
      "Iteration 6098, loss = 0.05391725\n",
      "Iteration 6099, loss = 0.05390457\n",
      "Iteration 6100, loss = 0.05389192\n",
      "Iteration 6101, loss = 0.05387927\n",
      "Iteration 6102, loss = 0.05386662\n",
      "Iteration 6103, loss = 0.05385398\n",
      "Iteration 6104, loss = 0.05384135\n",
      "Iteration 6105, loss = 0.05382866\n",
      "Iteration 6106, loss = 0.05381598\n",
      "Iteration 6107, loss = 0.05380335\n",
      "Iteration 6108, loss = 0.05379072\n",
      "Iteration 6109, loss = 0.05377810\n",
      "Iteration 6110, loss = 0.05376548\n",
      "Iteration 6111, loss = 0.05375286\n",
      "Iteration 6112, loss = 0.05374024\n",
      "Iteration 6113, loss = 0.05372763\n",
      "Iteration 6114, loss = 0.05371502\n",
      "Iteration 6115, loss = 0.05370242\n",
      "Iteration 6116, loss = 0.05368982\n",
      "Iteration 6117, loss = 0.05367723\n",
      "Iteration 6118, loss = 0.05366464\n",
      "Iteration 6119, loss = 0.05365205\n",
      "Iteration 6120, loss = 0.05363948\n",
      "Iteration 6121, loss = 0.05362690\n",
      "Iteration 6122, loss = 0.05361434\n",
      "Iteration 6123, loss = 0.05360177\n",
      "Iteration 6124, loss = 0.05358922\n",
      "Iteration 6125, loss = 0.05357667\n",
      "Iteration 6126, loss = 0.05356411\n",
      "Iteration 6127, loss = 0.05355155\n",
      "Iteration 6128, loss = 0.05353898\n",
      "Iteration 6129, loss = 0.05352643\n",
      "Iteration 6130, loss = 0.05351388\n",
      "Iteration 6131, loss = 0.05350134\n",
      "Iteration 6132, loss = 0.05348880\n",
      "Iteration 6133, loss = 0.05347626\n",
      "Iteration 6134, loss = 0.05346372\n",
      "Iteration 6135, loss = 0.05345119\n",
      "Iteration 6136, loss = 0.05343866\n",
      "Iteration 6137, loss = 0.05342614\n",
      "Iteration 6138, loss = 0.05341363\n",
      "Iteration 6139, loss = 0.05340112\n",
      "Iteration 6140, loss = 0.05338862\n",
      "Iteration 6141, loss = 0.05337613\n",
      "Iteration 6142, loss = 0.05336363\n",
      "Iteration 6143, loss = 0.05335115\n",
      "Iteration 6144, loss = 0.05333863\n",
      "Iteration 6145, loss = 0.05332612\n",
      "Iteration 6146, loss = 0.05331360\n",
      "Iteration 6147, loss = 0.05330110\n",
      "Iteration 6148, loss = 0.05328859\n",
      "Iteration 6149, loss = 0.05327610\n",
      "Iteration 6150, loss = 0.05326361\n",
      "Iteration 6151, loss = 0.05325112\n",
      "Iteration 6152, loss = 0.05323863\n",
      "Iteration 6153, loss = 0.05322615\n",
      "Iteration 6154, loss = 0.05321368\n",
      "Iteration 6155, loss = 0.05320121\n",
      "Iteration 6156, loss = 0.05318874\n",
      "Iteration 6157, loss = 0.05317626\n",
      "Iteration 6158, loss = 0.05316379\n",
      "Iteration 6159, loss = 0.05315131\n",
      "Iteration 6160, loss = 0.05313884\n",
      "Iteration 6161, loss = 0.05312638\n",
      "Iteration 6162, loss = 0.05311392\n",
      "Iteration 6163, loss = 0.05310146\n",
      "Iteration 6164, loss = 0.05308901\n",
      "Iteration 6165, loss = 0.05307656\n",
      "Iteration 6166, loss = 0.05306412\n",
      "Iteration 6167, loss = 0.05305168\n",
      "Iteration 6168, loss = 0.05303926\n",
      "Iteration 6169, loss = 0.05302685\n",
      "Iteration 6170, loss = 0.05301445\n",
      "Iteration 6171, loss = 0.05300204\n",
      "Iteration 6172, loss = 0.05298965\n",
      "Iteration 6173, loss = 0.05297726\n",
      "Iteration 6174, loss = 0.05296488\n",
      "Iteration 6175, loss = 0.05295250\n",
      "Iteration 6176, loss = 0.05294014\n",
      "Iteration 6177, loss = 0.05292777\n",
      "Iteration 6178, loss = 0.05291542\n",
      "Iteration 6179, loss = 0.05290306\n",
      "Iteration 6180, loss = 0.05289067\n",
      "Iteration 6181, loss = 0.05287836\n",
      "Iteration 6182, loss = 0.05286622\n",
      "Iteration 6183, loss = 0.05285414\n",
      "Iteration 6184, loss = 0.05284206\n",
      "Iteration 6185, loss = 0.05283000\n",
      "Iteration 6186, loss = 0.05281795\n",
      "Iteration 6187, loss = 0.05280593\n",
      "Iteration 6188, loss = 0.05279393\n",
      "Iteration 6189, loss = 0.05278195\n",
      "Iteration 6190, loss = 0.05276997\n",
      "Iteration 6191, loss = 0.05275801\n",
      "Iteration 6192, loss = 0.05274607\n",
      "Iteration 6193, loss = 0.05273413\n",
      "Iteration 6194, loss = 0.05272221\n",
      "Iteration 6195, loss = 0.05271030\n",
      "Iteration 6196, loss = 0.05269839\n",
      "Iteration 6197, loss = 0.05268651\n",
      "Iteration 6198, loss = 0.05267464\n",
      "Iteration 6199, loss = 0.05266277\n",
      "Iteration 6200, loss = 0.05265092\n",
      "Iteration 6201, loss = 0.05263908\n",
      "Iteration 6202, loss = 0.05262724\n",
      "Iteration 6203, loss = 0.05261541\n",
      "Iteration 6204, loss = 0.05260359\n",
      "Iteration 6205, loss = 0.05259178\n",
      "Iteration 6206, loss = 0.05257998\n",
      "Iteration 6207, loss = 0.05256819\n",
      "Iteration 6208, loss = 0.05255640\n",
      "Iteration 6209, loss = 0.05254462\n",
      "Iteration 6210, loss = 0.05253285\n",
      "Iteration 6211, loss = 0.05252108\n",
      "Iteration 6212, loss = 0.05250933\n",
      "Iteration 6213, loss = 0.05249754\n",
      "Iteration 6214, loss = 0.05248575\n",
      "Iteration 6215, loss = 0.05247391\n",
      "Iteration 6216, loss = 0.05246194\n",
      "Iteration 6217, loss = 0.05244996\n",
      "Iteration 6218, loss = 0.05243797\n",
      "Iteration 6219, loss = 0.05242597\n",
      "Iteration 6220, loss = 0.05241396\n",
      "Iteration 6221, loss = 0.05240195\n",
      "Iteration 6222, loss = 0.05238994\n",
      "Iteration 6223, loss = 0.05237794\n",
      "Iteration 6224, loss = 0.05236594\n",
      "Iteration 6225, loss = 0.05235395\n",
      "Iteration 6226, loss = 0.05234195\n",
      "Iteration 6227, loss = 0.05232996\n",
      "Iteration 6228, loss = 0.05231797\n",
      "Iteration 6229, loss = 0.05230598\n",
      "Iteration 6230, loss = 0.05229400\n",
      "Iteration 6231, loss = 0.05228202\n",
      "Iteration 6232, loss = 0.05227004\n",
      "Iteration 6233, loss = 0.05225806\n",
      "Iteration 6234, loss = 0.05224609\n",
      "Iteration 6235, loss = 0.05223412\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 6236, loss = 0.05222216\n",
      "Iteration 6237, loss = 0.05221020\n",
      "Iteration 6238, loss = 0.05219824\n",
      "Iteration 6239, loss = 0.05218629\n",
      "Iteration 6240, loss = 0.05217433\n",
      "Iteration 6241, loss = 0.05216239\n",
      "Iteration 6242, loss = 0.05215045\n",
      "Iteration 6243, loss = 0.05213850\n",
      "Iteration 6244, loss = 0.05212653\n",
      "Iteration 6245, loss = 0.05211455\n",
      "Iteration 6246, loss = 0.05210258\n",
      "Iteration 6247, loss = 0.05209061\n",
      "Iteration 6248, loss = 0.05207864\n",
      "Iteration 6249, loss = 0.05206667\n",
      "Iteration 6250, loss = 0.05205471\n",
      "Iteration 6251, loss = 0.05204275\n",
      "Iteration 6252, loss = 0.05203080\n",
      "Iteration 6253, loss = 0.05201884\n",
      "Iteration 6254, loss = 0.05200690\n",
      "Iteration 6255, loss = 0.05199495\n",
      "Iteration 6256, loss = 0.05198302\n",
      "Iteration 6257, loss = 0.05197108\n",
      "Iteration 6258, loss = 0.05195916\n",
      "Iteration 6259, loss = 0.05194723\n",
      "Iteration 6260, loss = 0.05193531\n",
      "Iteration 6261, loss = 0.05192339\n",
      "Iteration 6262, loss = 0.05191147\n",
      "Iteration 6263, loss = 0.05189955\n",
      "Iteration 6264, loss = 0.05188766\n",
      "Iteration 6265, loss = 0.05187576\n",
      "Iteration 6266, loss = 0.05186388\n",
      "Iteration 6267, loss = 0.05185198\n",
      "Iteration 6268, loss = 0.05184000\n",
      "Iteration 6269, loss = 0.05182801\n",
      "Iteration 6270, loss = 0.05181602\n",
      "Iteration 6271, loss = 0.05180403\n",
      "Iteration 6272, loss = 0.05179203\n",
      "Iteration 6273, loss = 0.05178004\n",
      "Iteration 6274, loss = 0.05176804\n",
      "Iteration 6275, loss = 0.05175605\n",
      "Iteration 6276, loss = 0.05174406\n",
      "Iteration 6277, loss = 0.05173207\n",
      "Iteration 6278, loss = 0.05172008\n",
      "Iteration 6279, loss = 0.05170810\n",
      "Iteration 6280, loss = 0.05169611\n",
      "Iteration 6281, loss = 0.05168414\n",
      "Iteration 6282, loss = 0.05167218\n",
      "Iteration 6283, loss = 0.05166021\n",
      "Iteration 6284, loss = 0.05164826\n",
      "Iteration 6285, loss = 0.05163631\n",
      "Iteration 6286, loss = 0.05162436\n",
      "Iteration 6287, loss = 0.05161242\n",
      "Iteration 6288, loss = 0.05160049\n",
      "Iteration 6289, loss = 0.05158856\n",
      "Iteration 6290, loss = 0.05157664\n",
      "Iteration 6291, loss = 0.05156474\n",
      "Iteration 6292, loss = 0.05155289\n",
      "Iteration 6293, loss = 0.05154105\n",
      "Iteration 6294, loss = 0.05152923\n",
      "Iteration 6295, loss = 0.05151740\n",
      "Iteration 6296, loss = 0.05150559\n",
      "Iteration 6297, loss = 0.05149378\n",
      "Iteration 6298, loss = 0.05148199\n",
      "Iteration 6299, loss = 0.05147020\n",
      "Iteration 6300, loss = 0.05145845\n",
      "Iteration 6301, loss = 0.05144676\n",
      "Iteration 6302, loss = 0.05143509\n",
      "Iteration 6303, loss = 0.05142344\n",
      "Iteration 6304, loss = 0.05141179\n",
      "Iteration 6305, loss = 0.05140016\n",
      "Iteration 6306, loss = 0.05138854\n",
      "Iteration 6307, loss = 0.05137693\n",
      "Iteration 6308, loss = 0.05136533\n",
      "Iteration 6309, loss = 0.05135375\n",
      "Iteration 6310, loss = 0.05134215\n",
      "Iteration 6311, loss = 0.05133045\n",
      "Iteration 6312, loss = 0.05131874\n",
      "Iteration 6313, loss = 0.05130703\n",
      "Iteration 6314, loss = 0.05129532\n",
      "Iteration 6315, loss = 0.05128361\n",
      "Iteration 6316, loss = 0.05127190\n",
      "Iteration 6317, loss = 0.05126019\n",
      "Iteration 6318, loss = 0.05124849\n",
      "Iteration 6319, loss = 0.05123679\n",
      "Iteration 6320, loss = 0.05122509\n",
      "Iteration 6321, loss = 0.05121339\n",
      "Iteration 6322, loss = 0.05120169\n",
      "Iteration 6323, loss = 0.05119003\n",
      "Iteration 6324, loss = 0.05117837\n",
      "Iteration 6325, loss = 0.05116672\n",
      "Iteration 6326, loss = 0.05115507\n",
      "Iteration 6327, loss = 0.05114343\n",
      "Iteration 6328, loss = 0.05113180\n",
      "Iteration 6329, loss = 0.05112017\n",
      "Iteration 6330, loss = 0.05110855\n",
      "Iteration 6331, loss = 0.05109694\n",
      "Iteration 6332, loss = 0.05108533\n",
      "Iteration 6333, loss = 0.05107373\n",
      "Iteration 6334, loss = 0.05106213\n",
      "Iteration 6335, loss = 0.05105054\n",
      "Iteration 6336, loss = 0.05103896\n",
      "Iteration 6337, loss = 0.05102743\n",
      "Iteration 6338, loss = 0.05101598\n",
      "Iteration 6339, loss = 0.05100454\n",
      "Iteration 6340, loss = 0.05099311\n",
      "Iteration 6341, loss = 0.05098170\n",
      "Iteration 6342, loss = 0.05097030\n",
      "Iteration 6343, loss = 0.05095891\n",
      "Iteration 6344, loss = 0.05094753\n",
      "Iteration 6345, loss = 0.05093618\n",
      "Iteration 6346, loss = 0.05092484\n",
      "Iteration 6347, loss = 0.05091351\n",
      "Iteration 6348, loss = 0.05090219\n",
      "Iteration 6349, loss = 0.05089088\n",
      "Iteration 6350, loss = 0.05087958\n",
      "Iteration 6351, loss = 0.05086830\n",
      "Iteration 6352, loss = 0.05085702\n",
      "Iteration 6353, loss = 0.05084575\n",
      "Iteration 6354, loss = 0.05083449\n",
      "Iteration 6355, loss = 0.05082323\n",
      "Iteration 6356, loss = 0.05081199\n",
      "Iteration 6357, loss = 0.05080075\n",
      "Iteration 6358, loss = 0.05078953\n",
      "Iteration 6359, loss = 0.05077831\n",
      "Iteration 6360, loss = 0.05076710\n",
      "Iteration 6361, loss = 0.05075589\n",
      "Iteration 6362, loss = 0.05074470\n",
      "Iteration 6363, loss = 0.05073351\n",
      "Iteration 6364, loss = 0.05072232\n",
      "Iteration 6365, loss = 0.05071115\n",
      "Iteration 6366, loss = 0.05069998\n",
      "Iteration 6367, loss = 0.05068882\n",
      "Iteration 6368, loss = 0.05067767\n",
      "Iteration 6369, loss = 0.05066652\n",
      "Iteration 6370, loss = 0.05065538\n",
      "Iteration 6371, loss = 0.05064425\n",
      "Iteration 6372, loss = 0.05063313\n",
      "Iteration 6373, loss = 0.05062201\n",
      "Iteration 6374, loss = 0.05061090\n",
      "Iteration 6375, loss = 0.05059979\n",
      "Iteration 6376, loss = 0.05058870\n",
      "Iteration 6377, loss = 0.05057760\n",
      "Iteration 6378, loss = 0.05056652\n",
      "Iteration 6379, loss = 0.05055544\n",
      "Iteration 6380, loss = 0.05054437\n",
      "Iteration 6381, loss = 0.05053331\n",
      "Iteration 6382, loss = 0.05052225\n",
      "Iteration 6383, loss = 0.05051120\n",
      "Iteration 6384, loss = 0.05050015\n",
      "Iteration 6385, loss = 0.05048912\n",
      "Iteration 6386, loss = 0.05047809\n",
      "Iteration 6387, loss = 0.05046706\n",
      "Iteration 6388, loss = 0.05045604\n",
      "Iteration 6389, loss = 0.05044503\n",
      "Iteration 6390, loss = 0.05043403\n",
      "Iteration 6391, loss = 0.05042303\n",
      "Iteration 6392, loss = 0.05041204\n",
      "Iteration 6393, loss = 0.05040105\n",
      "Iteration 6394, loss = 0.05039008\n",
      "Iteration 6395, loss = 0.05037910\n",
      "Iteration 6396, loss = 0.05036813\n",
      "Iteration 6397, loss = 0.05035716\n",
      "Iteration 6398, loss = 0.05034620\n",
      "Iteration 6399, loss = 0.05033525\n",
      "Iteration 6400, loss = 0.05032430\n",
      "Iteration 6401, loss = 0.05031336\n",
      "Iteration 6402, loss = 0.05030242\n",
      "Iteration 6403, loss = 0.05029149\n",
      "Iteration 6404, loss = 0.05028057\n",
      "Iteration 6405, loss = 0.05026966\n",
      "Iteration 6406, loss = 0.05025875\n",
      "Iteration 6407, loss = 0.05024784\n",
      "Iteration 6408, loss = 0.05023695\n",
      "Iteration 6409, loss = 0.05022606\n",
      "Iteration 6410, loss = 0.05021517\n",
      "Iteration 6411, loss = 0.05020429\n",
      "Iteration 6412, loss = 0.05019342\n",
      "Iteration 6413, loss = 0.05018256\n",
      "Iteration 6414, loss = 0.05017170\n",
      "Iteration 6415, loss = 0.05016085\n",
      "Iteration 6416, loss = 0.05015000\n",
      "Iteration 6417, loss = 0.05013916\n",
      "Iteration 6418, loss = 0.05012833\n",
      "Iteration 6419, loss = 0.05011750\n",
      "Iteration 6420, loss = 0.05010668\n",
      "Iteration 6421, loss = 0.05009587\n",
      "Iteration 6422, loss = 0.05008506\n",
      "Iteration 6423, loss = 0.05007426\n",
      "Iteration 6424, loss = 0.05006347\n",
      "Iteration 6425, loss = 0.05005268\n",
      "Iteration 6426, loss = 0.05004190\n",
      "Iteration 6427, loss = 0.05003113\n",
      "Iteration 6428, loss = 0.05002036\n",
      "Iteration 6429, loss = 0.05000960\n",
      "Iteration 6430, loss = 0.04999885\n",
      "Iteration 6431, loss = 0.04998810\n",
      "Iteration 6432, loss = 0.04997736\n",
      "Iteration 6433, loss = 0.04996662\n",
      "Iteration 6434, loss = 0.04995589\n",
      "Iteration 6435, loss = 0.04994517\n",
      "Iteration 6436, loss = 0.04993446\n",
      "Iteration 6437, loss = 0.04992375\n",
      "Iteration 6438, loss = 0.04991304\n",
      "Iteration 6439, loss = 0.04990235\n",
      "Iteration 6440, loss = 0.04989166\n",
      "Iteration 6441, loss = 0.04988097\n",
      "Iteration 6442, loss = 0.04987030\n",
      "Iteration 6443, loss = 0.04985963\n",
      "Iteration 6444, loss = 0.04984896\n",
      "Iteration 6445, loss = 0.04983831\n",
      "Iteration 6446, loss = 0.04982766\n",
      "Iteration 6447, loss = 0.04981701\n",
      "Iteration 6448, loss = 0.04980637\n",
      "Iteration 6449, loss = 0.04979574\n",
      "Iteration 6450, loss = 0.04978512\n",
      "Iteration 6451, loss = 0.04977450\n",
      "Iteration 6452, loss = 0.04976388\n",
      "Iteration 6453, loss = 0.04975328\n",
      "Iteration 6454, loss = 0.04974267\n",
      "Iteration 6455, loss = 0.04973208\n",
      "Iteration 6456, loss = 0.04972149\n",
      "Iteration 6457, loss = 0.04971091\n",
      "Iteration 6458, loss = 0.04970033\n",
      "Iteration 6459, loss = 0.04968976\n",
      "Iteration 6460, loss = 0.04967920\n",
      "Iteration 6461, loss = 0.04966864\n",
      "Iteration 6462, loss = 0.04965809\n",
      "Iteration 6463, loss = 0.04964755\n",
      "Iteration 6464, loss = 0.04963701\n",
      "Iteration 6465, loss = 0.04962648\n",
      "Iteration 6466, loss = 0.04961595\n",
      "Iteration 6467, loss = 0.04960543\n",
      "Iteration 6468, loss = 0.04959492\n",
      "Iteration 6469, loss = 0.04958442\n",
      "Iteration 6470, loss = 0.04957392\n",
      "Iteration 6471, loss = 0.04956342\n",
      "Iteration 6472, loss = 0.04955294\n",
      "Iteration 6473, loss = 0.04954246\n",
      "Iteration 6474, loss = 0.04953198\n",
      "Iteration 6475, loss = 0.04952152\n",
      "Iteration 6476, loss = 0.04951106\n",
      "Iteration 6477, loss = 0.04950060\n",
      "Iteration 6478, loss = 0.04949015\n",
      "Iteration 6479, loss = 0.04947971\n",
      "Iteration 6480, loss = 0.04946928\n",
      "Iteration 6481, loss = 0.04945885\n",
      "Iteration 6482, loss = 0.04944843\n",
      "Iteration 6483, loss = 0.04943801\n",
      "Iteration 6484, loss = 0.04942760\n",
      "Iteration 6485, loss = 0.04941720\n",
      "Iteration 6486, loss = 0.04940680\n",
      "Iteration 6487, loss = 0.04939641\n",
      "Iteration 6488, loss = 0.04938603\n",
      "Iteration 6489, loss = 0.04937565\n",
      "Iteration 6490, loss = 0.04936527\n",
      "Iteration 6491, loss = 0.04935487\n",
      "Iteration 6492, loss = 0.04934446\n",
      "Iteration 6493, loss = 0.04933406\n",
      "Iteration 6494, loss = 0.04932367\n",
      "Iteration 6495, loss = 0.04931325\n",
      "Iteration 6496, loss = 0.04930281\n",
      "Iteration 6497, loss = 0.04929238\n",
      "Iteration 6498, loss = 0.04928195\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 6499, loss = 0.04927151\n",
      "Iteration 6500, loss = 0.04926106\n",
      "Iteration 6501, loss = 0.04925047\n",
      "Iteration 6502, loss = 0.04923983\n",
      "Iteration 6503, loss = 0.04922917\n",
      "Iteration 6504, loss = 0.04921849\n",
      "Iteration 6505, loss = 0.04920779\n",
      "Iteration 6506, loss = 0.04919708\n",
      "Iteration 6507, loss = 0.04918634\n",
      "Iteration 6508, loss = 0.04917558\n",
      "Iteration 6509, loss = 0.04916481\n",
      "Iteration 6510, loss = 0.04915404\n",
      "Iteration 6511, loss = 0.04914327\n",
      "Iteration 6512, loss = 0.04913249\n",
      "Iteration 6513, loss = 0.04912171\n",
      "Iteration 6514, loss = 0.04911092\n",
      "Iteration 6515, loss = 0.04910010\n",
      "Iteration 6516, loss = 0.04908926\n",
      "Iteration 6517, loss = 0.04907841\n",
      "Iteration 6518, loss = 0.04906756\n",
      "Iteration 6519, loss = 0.04905671\n",
      "Iteration 6520, loss = 0.04904586\n",
      "Iteration 6521, loss = 0.04903505\n",
      "Iteration 6522, loss = 0.04902425\n",
      "Iteration 6523, loss = 0.04901346\n",
      "Iteration 6524, loss = 0.04900267\n",
      "Iteration 6525, loss = 0.04899189\n",
      "Iteration 6526, loss = 0.04898111\n",
      "Iteration 6527, loss = 0.04897034\n",
      "Iteration 6528, loss = 0.04895956\n",
      "Iteration 6529, loss = 0.04894873\n",
      "Iteration 6530, loss = 0.04893791\n",
      "Iteration 6531, loss = 0.04892714\n",
      "Iteration 6532, loss = 0.04891636\n",
      "Iteration 6533, loss = 0.04890560\n",
      "Iteration 6534, loss = 0.04889486\n",
      "Iteration 6535, loss = 0.04888413\n",
      "Iteration 6536, loss = 0.04887340\n",
      "Iteration 6537, loss = 0.04886269\n",
      "Iteration 6538, loss = 0.04885198\n",
      "Iteration 6539, loss = 0.04884128\n",
      "Iteration 6540, loss = 0.04883058\n",
      "Iteration 6541, loss = 0.04881990\n",
      "Iteration 6542, loss = 0.04880922\n",
      "Iteration 6543, loss = 0.04879855\n",
      "Iteration 6544, loss = 0.04878788\n",
      "Iteration 6545, loss = 0.04877723\n",
      "Iteration 6546, loss = 0.04876658\n",
      "Iteration 6547, loss = 0.04875594\n",
      "Iteration 6548, loss = 0.04874530\n",
      "Iteration 6549, loss = 0.04873468\n",
      "Iteration 6550, loss = 0.04872406\n",
      "Iteration 6551, loss = 0.04871345\n",
      "Iteration 6552, loss = 0.04870285\n",
      "Iteration 6553, loss = 0.04869226\n",
      "Iteration 6554, loss = 0.04868168\n",
      "Iteration 6555, loss = 0.04867110\n",
      "Iteration 6556, loss = 0.04866053\n",
      "Iteration 6557, loss = 0.04864997\n",
      "Iteration 6558, loss = 0.04863942\n",
      "Iteration 6559, loss = 0.04862888\n",
      "Iteration 6560, loss = 0.04861834\n",
      "Iteration 6561, loss = 0.04860781\n",
      "Iteration 6562, loss = 0.04859729\n",
      "Iteration 6563, loss = 0.04858678\n",
      "Iteration 6564, loss = 0.04857627\n",
      "Iteration 6565, loss = 0.04856578\n",
      "Iteration 6566, loss = 0.04855529\n",
      "Iteration 6567, loss = 0.04854481\n",
      "Iteration 6568, loss = 0.04853433\n",
      "Iteration 6569, loss = 0.04852387\n",
      "Iteration 6570, loss = 0.04851341\n",
      "Iteration 6571, loss = 0.04850296\n",
      "Iteration 6572, loss = 0.04849251\n",
      "Iteration 6573, loss = 0.04848209\n",
      "Iteration 6574, loss = 0.04847171\n",
      "Iteration 6575, loss = 0.04846134\n",
      "Iteration 6576, loss = 0.04845098\n",
      "Iteration 6577, loss = 0.04844063\n",
      "Iteration 6578, loss = 0.04843029\n",
      "Iteration 6579, loss = 0.04841996\n",
      "Iteration 6580, loss = 0.04840964\n",
      "Iteration 6581, loss = 0.04839931\n",
      "Iteration 6582, loss = 0.04838899\n",
      "Iteration 6583, loss = 0.04837867\n",
      "Iteration 6584, loss = 0.04836837\n",
      "Iteration 6585, loss = 0.04835814\n",
      "Iteration 6586, loss = 0.04834792\n",
      "Iteration 6587, loss = 0.04833771\n",
      "Iteration 6588, loss = 0.04832751\n",
      "Iteration 6589, loss = 0.04831732\n",
      "Iteration 6590, loss = 0.04830714\n",
      "Iteration 6591, loss = 0.04829697\n",
      "Iteration 6592, loss = 0.04828681\n",
      "Iteration 6593, loss = 0.04827665\n",
      "Iteration 6594, loss = 0.04826645\n",
      "Iteration 6595, loss = 0.04825625\n",
      "Iteration 6596, loss = 0.04824605\n",
      "Iteration 6597, loss = 0.04823586\n",
      "Iteration 6598, loss = 0.04822567\n",
      "Iteration 6599, loss = 0.04821549\n",
      "Iteration 6600, loss = 0.04820531\n",
      "Iteration 6601, loss = 0.04819514\n",
      "Iteration 6602, loss = 0.04818497\n",
      "Iteration 6603, loss = 0.04817481\n",
      "Iteration 6604, loss = 0.04816465\n",
      "Iteration 6605, loss = 0.04815451\n",
      "Iteration 6606, loss = 0.04814436\n",
      "Iteration 6607, loss = 0.04813423\n",
      "Iteration 6608, loss = 0.04812410\n",
      "Iteration 6609, loss = 0.04811398\n",
      "Iteration 6610, loss = 0.04810387\n",
      "Iteration 6611, loss = 0.04809377\n",
      "Iteration 6612, loss = 0.04808367\n",
      "Iteration 6613, loss = 0.04807358\n",
      "Iteration 6614, loss = 0.04806350\n",
      "Iteration 6615, loss = 0.04805343\n",
      "Iteration 6616, loss = 0.04804336\n",
      "Iteration 6617, loss = 0.04803330\n",
      "Iteration 6618, loss = 0.04802324\n",
      "Iteration 6619, loss = 0.04801320\n",
      "Iteration 6620, loss = 0.04800316\n",
      "Iteration 6621, loss = 0.04799312\n",
      "Iteration 6622, loss = 0.04798310\n",
      "Iteration 6623, loss = 0.04797308\n",
      "Iteration 6624, loss = 0.04796307\n",
      "Iteration 6625, loss = 0.04795306\n",
      "Iteration 6626, loss = 0.04794306\n",
      "Iteration 6627, loss = 0.04793307\n",
      "Iteration 6628, loss = 0.04792308\n",
      "Iteration 6629, loss = 0.04791310\n",
      "Iteration 6630, loss = 0.04790313\n",
      "Iteration 6631, loss = 0.04789316\n",
      "Iteration 6632, loss = 0.04788320\n",
      "Iteration 6633, loss = 0.04787325\n",
      "Iteration 6634, loss = 0.04786331\n",
      "Iteration 6635, loss = 0.04785338\n",
      "Iteration 6636, loss = 0.04784345\n",
      "Iteration 6637, loss = 0.04783353\n",
      "Training loss did not improve more than tol=0.000010 for 10 consecutive epochs. Stopping.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLPRegressor(hidden_layer_sizes=(16, 32, 16), learning_rate_init=1e-05,\n",
       "             max_iter=35000, tol=1e-05, verbose=True)"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn = MLPRegressor((16,32,16), max_iter=35000, verbose=True, learning_rate_init=0.00001, tol=0.00001)\n",
    "nn.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7752145394478929"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn.score(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2371608853212933"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(55,)"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x504 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(12,7))\n",
    "plt.plot(np.concatenate((y_train/100, y_test/100)), label='Дійсне значення параметру')\n",
    "plt.plot(nn.predict(X_train)/100, label='Передбачення на тренувальному датасеті')\n",
    "plt.plot(range(len(np.concatenate((y_train, y_test)))-len(y_test), len(np.concatenate((y_train, y_test))), 1), nn.predict(X_test)/100, label='Передбачення на тестовому датасеті')\n",
    "plt.xlabel('День')\n",
    "plt.ylabel('Параметр '+r'$\\beta$')\n",
    "plt.grid(True)\n",
    "plt.legend(fontsize=14)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x254e41c9648>]"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(nn.predict(X_test), y_test)\n",
    "plt.plot([1,3],[1,3], '--')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x504 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(12,7))\n",
    "plt.title('Україна\\n01.05.2020 — 19.10.2020', fontsize=16)\n",
    "plt.scatter(range(1,len(beta)+1), beta, s=12)\n",
    "plt.xlabel('День', fontsize=12)\n",
    "plt.ylabel('Параметр '+r'$\\beta$', fontsize=12)\n",
    "plt.xticks(range(0,len(beta)+10, 10))\n",
    "plt.yticks(np.arange(0.01,0.054,0.002))\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
